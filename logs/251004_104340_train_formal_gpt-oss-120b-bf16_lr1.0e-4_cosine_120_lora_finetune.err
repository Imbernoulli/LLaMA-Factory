+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
++ head -n 1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=0 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=2 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=1 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=5 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
++ head -n 1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=4 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=7 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
++ head -n 1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=6 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=3 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type lora --lora_rank 8 --lora_target all --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_lora_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
W1004 12:45:03.827000 3446796 site-packages/torch/distributed/run.py:774] 
W1004 12:45:03.827000 3446796 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:03.827000 3446796 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:03.827000 3446796 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.121000 3291551 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.121000 3291551 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.121000 3291551 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.121000 3291551 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.122000 3530070 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.122000 3530070 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.122000 3530070 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.122000 3530070 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.122000 2471974 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.122000 2471974 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.122000 2471974 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.122000 2471974 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.123000 3425962 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.123000 3425962 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.123000 3425962 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.123000 3425962 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.126000 184869 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.126000 184869 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.126000 184869 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.126000 184869 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.138000 8870 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.138000 8870 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.138000 8870 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.138000 8870 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.142000 1648859 site-packages/torch/distributed/run.py:774] 
W1004 12:45:04.142000 1648859 site-packages/torch/distributed/run.py:774] *****************************************
W1004 12:45:04.142000 1648859 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 12:45:04.142000 1648859 site-packages/torch/distributed/run.py:774] *****************************************
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,645 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,645 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,645 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,645 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,645 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,645 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,647 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,648 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,660 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,660 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,660 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,660 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,660 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,660 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,663 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,663 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,663 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,663 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,663 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,663 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,672 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,672 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,672 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,672 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,672 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,672 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,680 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,680 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,680 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,680 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,680 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:33,680 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,320 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,321 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,322 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,323 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,325 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,326 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,329 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,330 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,330 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,330 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,330 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,330 >> loading file chat_template.jinja
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,332 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,333 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,333 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,333 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,333 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,333 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,333 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,336 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,337 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,339 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,339 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,340 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,340 >> loading file tokenizer.model
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,340 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,340 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,340 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,340 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,340 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,341 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,342 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,342 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,343 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,343 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,343 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,343 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,343 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,343 >> loading file chat_template.jinja
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,344 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,345 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,345 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,345 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,345 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,345 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,345 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:34,354 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 12:45:34,355 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 12:45:34,361 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,361 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,361 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,361 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,361 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,361 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 12:45:34,361 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,039 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,044 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,047 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,049 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,062 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,063 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,066 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 12:45:35,074 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187148 examples [00:01, 346.89 examples/s]            Converting format of dataset (num_proc=64): 212299 examples [00:01, 24760.19 examples/s]Converting format of dataset (num_proc=64): 231635 examples [00:01, 45214.19 examples/s]Converting format of dataset (num_proc=64): 260294 examples [00:01, 80939.95 examples/s]Converting format of dataset (num_proc=64): 285640 examples [00:01, 111009.76 examples/s]Converting format of dataset (num_proc=64): 308615 examples [00:01, 131900.63 examples/s]Converting format of dataset (num_proc=64): 331687 examples [00:01, 150781.37 examples/s]Converting format of dataset (num_proc=64): 353889 examples [00:02, 150509.50 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:03, 54736.93 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187222 examples [00:01, 390.08 examples/s]            Converting format of dataset (num_proc=64): 205172 examples [00:01, 17230.86 examples/s]Converting format of dataset (num_proc=64): 229593 examples [00:01, 43885.28 examples/s]Converting format of dataset (num_proc=64): 258711 examples [00:01, 79167.57 examples/s]Converting format of dataset (num_proc=64): 280160 examples [00:01, 102095.17 examples/s]Converting format of dataset (num_proc=64): 306247 examples [00:01, 132961.70 examples/s]Converting format of dataset (num_proc=64): 329087 examples [00:02, 144726.03 examples/s]Converting format of dataset (num_proc=64): 350235 examples [00:02, 150531.60 examples/s]Converting format of dataset (num_proc=64): 370028 examples [00:02, 109270.49 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44316.41 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187162 examples [00:01, 352.78 examples/s]            Converting format of dataset (num_proc=64): 219924 examples [00:01, 31738.68 examples/s]Converting format of dataset (num_proc=64): 240016 examples [00:01, 52115.91 examples/s]Converting format of dataset (num_proc=64): 266780 examples [00:01, 83740.79 examples/s]Converting format of dataset (num_proc=64): 291278 examples [00:01, 111441.97 examples/s]Converting format of dataset (num_proc=64): 314444 examples [00:01, 128448.12 examples/s]Converting format of dataset (num_proc=64): 336333 examples [00:01, 147341.07 examples/s]Converting format of dataset (num_proc=64): 358015 examples [00:02, 146545.69 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44178.18 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 186743 examples [00:01, 38.45 examples/s]             Converting format of dataset (num_proc=64): 191018 examples [00:01, 3913.06 examples/s]Converting format of dataset (num_proc=64): 203688 examples [00:01, 17968.39 examples/s]Converting format of dataset (num_proc=64): 236102 examples [00:01, 60998.61 examples/s]Converting format of dataset (num_proc=64): 257551 examples [00:01, 86616.37 examples/s]Converting format of dataset (num_proc=64): 281886 examples [00:01, 116447.56 examples/s]Converting format of dataset (num_proc=64): 302325 examples [00:02, 133618.80 examples/s]Converting format of dataset (num_proc=64): 322578 examples [00:02, 121514.02 examples/s]Converting format of dataset (num_proc=64): 357213 examples [00:02, 167727.59 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44122.66 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187192 examples [00:01, 364.32 examples/s]            Converting format of dataset (num_proc=64): 207266 examples [00:01, 19021.78 examples/s]Converting format of dataset (num_proc=64): 231255 examples [00:01, 44897.38 examples/s]Converting format of dataset (num_proc=64): 260650 examples [00:01, 80008.77 examples/s]Converting format of dataset (num_proc=64): 281933 examples [00:01, 101059.53 examples/s]Converting format of dataset (num_proc=64): 308012 examples [00:01, 131641.13 examples/s]Converting format of dataset (num_proc=64): 330727 examples [00:02, 146449.18 examples/s]Converting format of dataset (num_proc=64): 352335 examples [00:02, 149045.74 examples/s]Converting format of dataset (num_proc=64): 371954 examples [00:02, 99414.94 examples/s] Converting format of dataset (num_proc=64): 373376 examples [00:04, 43844.96 examples/s]
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187194 examples [00:01, 356.76 examples/s]            Converting format of dataset (num_proc=64): 189924 examples [00:01, 2809.75 examples/s]Converting format of dataset (num_proc=64): 210733 examples [00:01, 26408.10 examples/s]Converting format of dataset (num_proc=64): 237898 examples [00:01, 61007.04 examples/s]Converting format of dataset (num_proc=64): 258313 examples [00:01, 84273.38 examples/s]Converting format of dataset (num_proc=64): 285213 examples [00:01, 119720.70 examples/s]Converting format of dataset (num_proc=64): 306392 examples [00:02, 136351.90 examples/s]Converting format of dataset (num_proc=64): 326930 examples [00:02, 145932.60 examples/s]Converting format of dataset (num_proc=64): 349973 examples [00:02, 163847.66 examples/s]Converting format of dataset (num_proc=64): 370112 examples [00:02, 123186.81 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 43773.54 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187057 examples [00:01, 256.65 examples/s]            Converting format of dataset (num_proc=64): 195394 examples [00:01, 7767.59 examples/s]Converting format of dataset (num_proc=64): 221498 examples [00:01, 36714.66 examples/s]Converting format of dataset (num_proc=64): 244836 examples [00:01, 64293.11 examples/s]Converting format of dataset (num_proc=64): 262837 examples [00:01, 82370.57 examples/s]Converting format of dataset (num_proc=64): 287543 examples [00:01, 113420.13 examples/s]Converting format of dataset (num_proc=64): 307424 examples [00:02, 123946.87 examples/s]Converting format of dataset (num_proc=64): 331977 examples [00:02, 150817.39 examples/s]Converting format of dataset (num_proc=64): 352306 examples [00:02, 158510.37 examples/s]Converting format of dataset (num_proc=64): 371947 examples [00:02, 97910.68 examples/s] Converting format of dataset (num_proc=64): 373376 examples [00:04, 43214.79 examples/s]
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187159 examples [00:01, 310.64 examples/s]            Converting format of dataset (num_proc=64): 214256 examples [00:01, 23613.38 examples/s]Converting format of dataset (num_proc=64): 234053 examples [00:01, 42696.00 examples/s]Converting format of dataset (num_proc=64): 257924 examples [00:01, 69139.53 examples/s]Converting format of dataset (num_proc=64): 282580 examples [00:01, 97653.94 examples/s]Converting format of dataset (num_proc=64): 304340 examples [00:02, 119155.86 examples/s]Converting format of dataset (num_proc=64): 325753 examples [00:02, 135552.84 examples/s]Converting format of dataset (num_proc=64): 346643 examples [00:02, 151585.26 examples/s]Converting format of dataset (num_proc=64): 367516 examples [00:02, 115855.70 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 43152.02 examples/s] 
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:13<40:45, 75.92 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 2000/186688 [00:13<17:47, 173.06 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 3000/186688 [00:14<10:23, 294.80 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 5000/186688 [00:14<04:57, 611.53 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:15<03:19, 899.45 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 8000/186688 [00:16<02:49, 1053.34 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▍         | 9000/186688 [00:16<02:17, 1296.14 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▌         | 10000/186688 [00:16<01:52, 1576.56 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▋         | 120Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:13<40:36, 76.22 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 2000/186688 [00:14<18:23, 167.37 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 3000/186688 [00:15<11:21, 269.43 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:15<07:27, 408.63 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:15<02:53, 1033.53 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 8000/186688 [00:16<02:32, 1169.82 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▌         | 10000/186688 [00:16<01:49, 1611.23 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 13000/186688 [00:17<01:12, 2398.98 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 1Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:13<42:04, 73.54 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 3000/186688 [00:14<11:21, 269.60 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:14<08:17, 367.37 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 5000/186688 [00:15<06:01, 502.39 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:15<03:25, 873.96 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 8000/186688 [00:16<02:55, 1019.62 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▌         | 10000/186688 [00:16<01:58, 1497.09 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▋         | 12000/186688 [00:17<01:28, 1965.82 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:13<42:07, 73.46 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 2000/186688 [00:14<18:13, 168.94 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 3000/186688 [00:15<11:20, 269.78 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:15<07:29, 406.48 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:16<03:04, 976.56 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 8000/186688 [00:16<02:45, 1082.86 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▋         | 12000/186688 [00:17<01:22, 2112.77 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 13000/186688 [00:17<01:17, 2231.02 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 15Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:14<45:22, 68.19 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 3000/186688 [00:15<12:13, 250.47 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:15<08:28, 359.03 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 8000/186688 [00:16<03:02, 978.66 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 13000/186688 [00:16<01:30, 1922.99 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 15000/186688 [00:17<01:18, 2191.73 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▉         | 17000/186688 [00:17<01:08, 2465.57 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 18000/186688 [00:18<01:10, 2386.47 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█        Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:13<41:57, 73.77 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 3000/186688 [00:14<11:21, 269.58 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:15<09:03, 336.34 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 6000/186688 [00:16<05:16, 571.21 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:17<04:17, 696.63 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 14000/186688 [00:17<01:17, 2221.11 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 15000/186688 [00:18<01:15, 2284.13 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▊         | 16000/186688 [00:18<01:15, 2249.40 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         |Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:15<46:53, 66.00 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:15<09:10, 331.78 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:16<04:27, 672.06 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▌         | 10000/186688 [00:16<02:41, 1093.63 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 13000/186688 [00:17<01:48, 1594.38 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▊         | 16000/186688 [00:17<01:19, 2143.17 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▉         | 17000/186688 [00:18<01:18, 2158.87 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 18000/186688 [00:18<01:19, 2123.16 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█      Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 1000/186688 [00:15<49:06, 63.02 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 4000/186688 [00:16<09:34, 318.02 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 7000/186688 [00:16<04:38, 644.56 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 11000/186688 [00:17<02:26, 1199.30 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 13000/186688 [00:17<01:57, 1477.51 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▊         | 16000/186688 [00:18<01:24, 2015.30 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 18000/186688 [00:19<01:13, 2285.35 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 21000/186688 [00:19<00:57, 2886.93 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏   14000/186688 [00:17<01:12, 2383.41 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▉         | 17000/186688 [00:18<00:53, 3171.47 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 20000/186688 [00:19<00:53, 3089.77 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 21000/186688 [00:20<00:58, 2836.80 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 22000/186688 [00:20<01:03, 2582.00 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 25000/186688 [00:21<00:47, 3417.93 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 30000/186688 [00:21<00:26, 5861.00 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 31000/186688 [00:21<00:33, 4631.37 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:21<00:31, 4906.93 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 33000/186688 [00:22<0000/186688 [00:17<01:15, 2316.35 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 14000/186688 [00:18<01:22, 2102.49 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 15000/186688 [00:19<01:36, 1772.77 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 18000/186688 [00:20<01:20, 2092.02 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█         | 19000/186688 [00:20<01:21, 2048.25 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 21000/186688 [00:21<01:09, 2367.45 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 22000/186688 [00:22<01:21, 2020.45 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 24000/186688 [00:22<00:59, 2714.45 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 26000/186688 [00:22<00:43, 3690.70 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 27000/186688 [00:22<00:39, 40 | 19000/186688 [00:18<01:12, 2298.63 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 20000/186688 [00:19<01:32, 1807.09 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 22000/186688 [00:20<01:13, 2249.56 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 25000/186688 [00:20<00:52, 3064.13 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 29000/186688 [00:21<00:41, 3831.72 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 30000/186688 [00:22<00:46, 3348.00 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 31000/186688 [00:22<00:52, 2944.03 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:23<00:57, 2667.44 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 33000/186688 [00:23<00:49, 3097.66 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [0000/186688 [00:18<01:04, 2678.96 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▉         | 17000/186688 [00:18<01:01, 2739.26 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 20000/186688 [00:19<00:49, 3355.80 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 24000/186688 [00:20<00:37, 4364.21 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 26000/186688 [00:20<00:38, 4120.72 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▍        | 28000/186688 [00:21<00:39, 4005.96 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 29000/186688 [00:21<00:46, 3423.40 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:22<00:37, 4094.69 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:23<00:49, 3055.35 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:24<01     | 23000/186688 [00:20<00:53, 3073.41 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 24000/186688 [00:20<00:58, 2796.89 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 26000/186688 [00:20<00:46, 3470.81 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 27000/186688 [00:21<00:52, 3048.28 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▍        | 28000/186688 [00:22<01:03, 2513.32 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 29000/186688 [00:22<01:05, 2416.06 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 30000/186688 [00:23<01:07, 2315.22 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 31000/186688 [00:23<01:10, 2198.32 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:25<02:21, 1092.38 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 33000/186   | 19000/186688 [00:19<01:20, 2076.99 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 21000/186688 [00:19<01:06, 2499.85 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 22000/186688 [00:20<01:08, 2393.78 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▍        | 28000/186688 [00:20<00:32, 4851.22 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 29000/186688 [00:21<00:39, 4025.05 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 31000/186688 [00:21<00:38, 3994.47 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 33000/186688 [00:22<00:38, 3963.20 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:23<01:15, 2022.80 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:24<01:29, 1692.66 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688  18000/186688 [00:19<01:06, 2553.32 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 21000/186688 [00:19<00:51, 3228.91 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 22000/186688 [00:20<00:56, 2914.09 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 26000/186688 [00:20<00:39, 4102.45 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 30000/186688 [00:21<00:31, 5035.18 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:21<00:32, 4800.30 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:22<00:33, 4621.14 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:24<01:27, 1726.87 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:27<02:20, 1073.24 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:15.79 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▍        | 28000/186688 [00:23<00:57, 2769.35 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 29000/186688 [00:24<01:09, 2278.63 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 30000/186688 [00:24<01:00, 2594.74 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 31000/186688 [00:24<00:58, 2665.75 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:24<00:49, 3156.55 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 33000/186688 [00:25<01:10, 2173.90 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:27<02:10, 1174.18 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:28<01:48, 1401.87 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:28<01:27, 1713.61 examples/s5000/186688 [00:17<01:02, 2746.07 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 18000/186688 [00:18<00:48, 3479.59 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█         | 19000/186688 [00:18<00:54, 3105.31 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 22000/186688 [00:19<00:42, 3872.94 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 24000/186688 [00:19<00:41, 3926.37 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 26000/186688 [00:20<00:40, 3994.79 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 30000/186688 [00:20<00:30, 5202.97 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 32000/186688 [00:21<00:32, 4828.94 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:22<00:53, 2855.36 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:29<0:29, 5165.18 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:23<01:01, 2488.81 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:24<01:21, 1869.68 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:24<01:07, 2218.73 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:25<01:34, 1582.97 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:27<02:03, 1200.56 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:27<01:49, 1353.77 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:30<03:30, 698.10 examples/s] Running tokenizer on dataset (num_proc=64):  22%|██▏       | 41000/186688 [00:31<03:11, 761.77 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:31<02:22, 1018.30:23<00:45, 3359.55 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:25<01:58, 1278.60 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:27<02:22, 1061.12 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:29<03:23, 735.45 examples/s] Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:29<02:40, 924.75 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:30<02:12, 1113.58 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:30<01:48, 1357.92 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 41000/186688 [00:31<01:40, 1453.56 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:31<01:15, 1921.10 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:32<01:0[00:26<01:59, 1257.84 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:26<01:39, 1501.26 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:27<01:24, 1768.07 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:27<01:18, 1869.58 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:28<01:48, 1349.66 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 41000/186688 [00:29<01:30, 1603.39 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:32<03:09, 762.78 examples/s] Running tokenizer on dataset (num_proc=64):  23%|██▎       | 43000/186688 [00:32<02:37, 909.59 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:32<01:59, 1195.70 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:3]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:28<01:12, 2076.82 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:28<00:55, 2693.16 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:28<00:50, 2906.90 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:29<00:53, 2745.23 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:30<01:15, 1913.63 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 43000/186688 [00:31<01:26, 1654.27 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:31<01:07, 2101.35 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:33<01:42, 1388.98 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:33<01:27, 1611.69 examples/s]Ru3:22, 749.90 examples/s] Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:29<02:47, 898.75 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:30<02:26, 1022.03 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:30<01:56, 1273.19 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:30<01:35, 1549.15 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:30<01:15, 1937.81 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 41000/186688 [00:32<01:49, 1334.33 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:32<01:34, 1527.81 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 43000/186688 [00:33<01:47, 1334.10 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:33<01:26, 1:23, 1825.86 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:25<01:19, 1885.73 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:29<03:09, 790.38 examples/s] Running tokenizer on dataset (num_proc=64):  20%|██        | 38000/186688 [00:30<03:18, 750.33 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:31<02:36, 941.32 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:31<02:05, 1164.41 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:31<01:16, 1891.29 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 43000/186688 [00:32<01:11, 2014.83 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:33<01:35, 1495.86 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:33<01:31, 15427<01:42, 1446.93 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:29<02:01, 1219.92 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:30<02:21, 1034.56 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 41000/186688 [00:31<02:05, 1158.49 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:31<01:44, 1381.99 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 43000/186688 [00:31<01:26, 1658.56 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:32<01:14, 1927.59 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:32<01:17, 1817.83 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:33<01:23, 1683.72 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:688 [00:25<01:49, 1402.81 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 34000/186688 [00:27<02:06, 1207.42 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 35000/186688 [00:27<01:38, 1545.87 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 36000/186688 [00:28<02:04, 1209.16 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 37000/186688 [00:30<02:37, 949.58 examples/s] Running tokenizer on dataset (num_proc=64):  21%|██        | 39000/186688 [00:30<01:33, 1587.21 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 40000/186688 [00:32<02:37, 934.27 examples/s] Running tokenizer on dataset (num_proc=64):  22%|██▏       | 42000/186688 [00:33<01:40, 1434.83 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:34<01:32, 1540.15 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:3 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 43000/186688 [00:32<01:58, 1209.82 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 44000/186688 [00:33<01:51, 1274.33 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:33<01:25, 1652.39 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:33<01:29, 1569.98 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:34<01:34, 1478.93 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:35<01:28, 1565.18 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 49000/186688 [00:35<01:28, 1551.81 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:36<01:07, 2036.04 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 51000/186688 [00:36<01:00, 2230644.37 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:33<01:10, 2007.17 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:34<01:01, 2274.21 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:34<00:53, 2625.09 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:34<00:51, 2692.30 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:35<00:35, 3876.08 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 51000/186688 [00:35<00:32, 4162.07 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:35<00:33, 4017.00 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 53000/186688 [00:35<00:36, 3673.29 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:36<00:52,8, 2077.58 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 45000/186688 [00:32<01:10, 2017.24 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:33<01:28, 1586.54 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:33<01:10, 1975.69 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:34<01:21, 1707.52 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 49000/186688 [00:35<01:30, 1523.27 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:36<01:22, 1647.71 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:36<01:00, 2223.18 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 53000/186688 [00:36<00:51, 2600.96 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:37<001.14 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:34<00:57, 2440.03 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:34<01:01, 2238.22 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 49000/186688 [00:34<00:56, 2426.02 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:35<00:46, 2964.31 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 51000/186688 [00:35<00:40, 3380.62 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:35<00:38, 3467.73 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:35<00:26, 5068.23 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 55000/186688 [00:36<00:57, 2285.60 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:37<00:59, 2nning tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:33<01:07, 2072.59 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:34<01:15, 1828.48 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 51000/186688 [00:35<01:00, 2227.27 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:35<00:56, 2400.59 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 53000/186688 [00:36<00:55, 2428.76 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:36<00:44, 2983.33 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 55000/186688 [00:36<00:43, 3060.28 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:36<00:46, 2802.44 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:37<00:44, 2892.47 examples/s]34<01:27, 1621.77 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:35<01:20, 1755.60 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:35<01:05, 2125.64 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:35<00:58, 2356.64 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 49000/186688 [00:35<00:52, 2607.52 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:36<00:44, 3066.26 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 51000/186688 [00:37<01:11, 1901.80 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 53000/186688 [00:37<00:41, 3188.81 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:37<00:37, 3581.61 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 55000/186688 [03<01:29, 1589.45 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 46000/186688 [00:34<01:54, 1228.28 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 47000/186688 [00:34<01:33, 1496.84 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:35<01:26, 1600.36 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 49000/186688 [00:35<01:15, 1830.54 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:36<01:54, 1194.86 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:37<01:07, 1991.68 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 53000/186688 [00:37<01:01, 2174.52 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:37<00:49, 2661.40 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 55000/186688 [0033<01:10, 1978.00 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 48000/186688 [00:34<01:07, 2041.42 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 49000/186688 [00:34<00:56, 2430.56 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 50000/186688 [00:35<01:08, 1988.71 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 51000/186688 [00:35<00:59, 2293.17 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:35<00:53, 2504.26 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 53000/186688 [00:35<00:41, 3207.26 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:36<00:34, 3842.34 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 55000/186688 [00:38<02:12, 990.53 examples/s] Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [0.54 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 52000/186688 [00:36<01:02, 2151.65 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 54000/186688 [00:37<00:49, 2699.75 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 55000/186688 [00:37<00:41, 3153.61 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:38<00:51, 2526.29 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57917/186688 [00:38<00:33, 3823.48 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59917/186688 [00:38<00:24, 5278.06 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 60917/186688 [00:38<00:30, 4183.97 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61917/186688 [00:39<00:29, 4267.92 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 62917/186688 [00:39<0203.15 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:37<00:52, 2490.95 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59000/186688 [00:37<00:31, 4014.31 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:37<00:27, 4557.15 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61000/186688 [00:39<01:00, 2090.78 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 62000/186688 [00:39<00:47, 2633.63 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 63000/186688 [00:39<00:39, 3153.27 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 64000/186688 [00:39<00:36, 3393.23 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 66000/186688 [00:39<00:24, 4972.91 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 67000/1866Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59000/186688 [00:37<00:27, 4630.45 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:37<00:29, 4292.92 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61000/186688 [00:37<00:26, 4749.79 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 62000/186688 [00:37<00:25, 4852.87 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 63000/186688 [00:38<00:45, 2707.51 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 64000/186688 [00:38<00:38, 3188.03 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 66000/186688 [00:39<00:24, 4926.37 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 67000/186688 [00:39<00:41, 2857.23 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▋      | 68000/186688 [00:40<00:37,  2513.36 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:36<00:32, 4013.11 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:37<00:35, 3634.29 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 58000/186688 [00:37<00:41, 3124.79 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59000/186688 [00:38<00:47, 2664.50 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:38<00:54, 2343.87 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61000/186688 [00:38<00:46, 2699.90 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 62000/186688 [00:39<00:52, 2390.23 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 63000/186688 [00:40<01:06, 1866.47 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 64000/1866880:37<00:33, 3879.47 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:37<00:28, 4537.83 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:38<00:38, 3340.63 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 58000/186688 [00:38<00:50, 2536.66 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59000/186688 [00:39<00:44, 2895.04 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:39<00:40, 3164.07 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61000/186688 [00:39<00:33, 3792.61 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 62000/186688 [00:40<00:46, 2697.19 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 63000/186688 [00:40<00:46, 2637.44 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 6:38<01:02, 2121.91 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 56000/186688 [00:38<00:50, 2590.14 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:38<00:49, 2612.61 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 58000/186688 [00:39<00:48, 2634.77 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:39<00:33, 3750.00 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61000/186688 [00:39<00:28, 4372.48 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 62000/186688 [00:39<00:30, 4109.26 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 63000/186688 [00:40<00:37, 3269.95 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▍      | 65000/186688 [00:40<00:24, 5057.88 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 660:38<01:39, 1314.84 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:39<01:13, 1754.21 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59000/186688 [00:39<00:52, 2428.22 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:40<00:54, 2311.40 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 61000/186688 [00:40<00:45, 2781.29 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 62000/186688 [00:40<00:48, 2584.95 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 64000/186688 [00:40<00:34, 3602.65 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▍      | 64917/186688 [00:41<00:30, 3957.18 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 65917/186688 [00:41<00:27, 4375.23 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌     :33, 3927.23 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 57000/186688 [00:37<00:36, 3561.01 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 59000/186688 [00:37<00:25, 4922.70 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 60000/186688 [00:37<00:25, 4978.30 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 63000/186688 [00:38<00:21, 5814.75 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 64000/186688 [00:39<00:34, 3576.59 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▍      | 65000/186688 [00:40<01:06, 1820.50 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 66000/186688 [00:41<01:10, 1717.09 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69000/186688 [00:41<00:40, 2904.38 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 70000:27, 4423.73 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 65917/186688 [00:39<00:18, 6484.61 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 66917/186688 [00:40<00:24, 4793.49 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 68917/186688 [00:40<00:20, 5881.36 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69917/186688 [00:40<00:28, 4048.69 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 71834/186688 [00:41<00:26, 4325.45 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 73834/186688 [00:41<00:24, 4595.05 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 74834/186688 [00:41<00:29, 3851.47 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 75834/186688 [00:42<00:25, 4396.45 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 74000/186688 [00:40<00:37, 3299.36 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▍      | 65000/186688 [00:40<00:33, 3665.32 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 67000/186688 [00:41<00:25, 4614.28 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▋      | 68000/186688 [00:41<00:23, 5076.26 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69000/186688 [00:41<00:23, 4942.72 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 70000/186688 [00:41<00:25, 4539.06 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 72000/186688 [00:41<00:19, 5862.37 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 73000/186688 [00:41<00:17, 6370.96 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 74000/186688 [00:42<00:27, 4094.10 examples/s]Running tokenizer on dataset (num_proc=64):  40%| [00:40<00:51, 2363.90 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▍      | 65000/186688 [00:40<00:53, 2265.92 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 67000/186688 [00:41<00:36, 3294.17 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▋      | 68000/186688 [00:41<00:49, 2405.42 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69000/186688 [00:42<00:40, 2878.36 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 71000/186688 [00:42<00:34, 3368.77 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 72000/186688 [00:42<00:34, 3294.83 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 74000/186688 [00:43<00:25, 4507.26 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 76000/186688 [00:43<00:22, 4892.34 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████ | 66917/186688 [00:41<00:32, 3717.11 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▋      | 67917/186688 [00:41<00:33, 3566.62 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 68917/186688 [00:42<00:26, 4363.00 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69834/186688 [00:42<00:44, 2628.12 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 70834/186688 [00:42<00:36, 3160.69 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 71834/186688 [00:43<00:31, 3658.13 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 73751/186688 [00:43<00:19, 5666.47 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 75751/186688 [00:43<00:14, 7891.51 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 77751/186688 [00:43<00:21, 4972.45 examples/s]Running tokenizer on dataset (num_proc=64): 000/186688 [00:40<00:28, 4276.92 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 67000/186688 [00:41<00:24, 4986.29 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▋      | 68000/186688 [00:41<00:20, 5681.05 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69000/186688 [00:41<00:26, 4519.42 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 70000/186688 [00:41<00:24, 4809.49 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 72000/186688 [00:42<00:28, 4044.87 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 73000/186688 [00:42<00:34, 3298.76 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 75000/186688 [00:42<00:22, 4929.55 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 78000/186688 [00:43<00:20, 5317.26 examples/s]Running tokenizer on dataset (num_proc=64):  43%|3173.92 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 71000/186688 [00:40<00:23, 4872.60 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 72000/186688 [00:40<00:24, 4633.69 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 74000/186688 [00:40<00:18, 6188.41 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 75000/186688 [00:41<00:31, 3593.92 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 76000/186688 [00:41<00:29, 3791.15 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 77000/186688 [00:43<00:57, 1902.16 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 79000/186688 [00:44<00:55, 1940.58 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 80000/186688 [00:44<00:50, 2097.33 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 888 [00:39<00:25, 4613.58 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▋      | 68000/186688 [00:40<00:28, 4213.26 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 69000/186688 [00:40<00:35, 3360.41 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 70000/186688 [00:40<00:29, 3910.53 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 72000/186688 [00:41<00:25, 4469.25 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 73000/186688 [00:42<00:58, 1938.85 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 74000/186688 [00:43<00:53, 2109.06 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 76000/186688 [00:43<00:44, 2506.24 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 77917/186688 [00:44<00:43, 2477.75 examples/s]Running tokenizer on dataset (num_proc=64):  42%|██0/186688 [00:41<00:36, 3240.76 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 72000/186688 [00:42<00:29, 3825.22 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 73000/186688 [00:42<00:32, 3509.36 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 74000/186688 [00:42<00:32, 3478.35 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 76000/186688 [00:43<00:37, 2988.77 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 77000/186688 [00:43<00:35, 3102.14 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 78000/186688 [00:44<00:35, 3027.29 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 79000/186688 [00:44<00:35, 3054.98 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 80000/186688 [00:45<01:05, 1634.10 examples/s]Running tokenizer on dataset (num_proc=64):  436834/186688 [00:42<00:29, 3716.48 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 77751/186688 [00:42<00:33, 3221.75 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 78751/186688 [00:43<00:48, 2220.26 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 79668/186688 [00:43<00:39, 2702.14 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 80668/186688 [00:44<00:39, 2710.41 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▎     | 81668/186688 [00:45<00:51, 2035.38 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82668/186688 [00:45<00:57, 1810.36 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 83668/186688 [00:46<00:50, 2056.20 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▌     | 84668/186688 [00:46<00:45, 2218.28 examples/s]Running tokenizer on dataset (num_      | 77000/186688 [00:43<00:26, 4143.57 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 78000/186688 [00:44<00:28, 3863.95 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 79000/186688 [00:44<00:33, 3234.35 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 81000/186688 [00:45<00:32, 3242.89 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82000/186688 [00:45<00:31, 3340.69 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 83000/186688 [00:45<00:26, 3877.93 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 84000/186688 [00:45<00:26, 3857.56 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 85000/186688 [00:46<00:29, 3417.05 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 85917/186688 [00:46<00:31, 3177.39 examples/s]Running tokenizer on data███      | 75000/186688 [00:42<00:23, 4854.12 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 76000/186688 [00:42<00:21, 5222.92 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 77000/186688 [00:43<00:38, 2847.33 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 78000/186688 [00:43<00:35, 3052.21 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 78917/186688 [00:44<00:52, 2059.16 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 80917/186688 [00:44<00:32, 3292.76 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 81917/186688 [00:45<00:30, 3466.59 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82917/186688 [00:45<00:41, 2491.78 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 83917/186688 [00:46<00:47, 2149.88 examples/s]Running tokenizer █▏     | 78917/186688 [00:45<00:54, 1973.81 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 79834/186688 [00:45<00:46, 2319.87 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 81834/186688 [00:46<00:40, 2596.32 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82751/186688 [00:46<00:40, 2595.19 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▌     | 84751/186688 [00:46<00:32, 3143.88 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 85751/186688 [00:47<00:29, 3469.94 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▋     | 86751/186688 [00:47<00:24, 4023.72 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87668/186688 [00:47<00:23, 4213.94 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 88668/186688 [00:47<00:24, 4026.57 examples/s]Running tokenizer o 42%|████▏     | 78751/186688 [00:44<00:26, 4128.65 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 79751/186688 [00:44<00:22, 4730.23 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 81751/186688 [00:44<00:15, 6696.17 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 83751/186688 [00:45<00:24, 4218.13 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▌     | 84751/186688 [00:45<00:21, 4697.76 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 85751/186688 [00:46<00:46, 2184.51 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87751/186688 [00:46<00:31, 3183.63 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 88751/186688 [00:47<00:28, 3427.02 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 89668/186688 [00:48<00:42, 2273.38 examples/s]Runnin████▎     | 80000/186688 [00:44<00:36, 2949.31 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 81000/186688 [00:45<00:41, 2542.34 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82000/186688 [00:45<00:35, 2952.83 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82917/186688 [00:45<00:36, 2867.72 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 83917/186688 [00:46<00:38, 2671.56 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▌     | 84917/186688 [00:46<00:39, 2588.32 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 85917/186688 [00:46<00:36, 2755.78 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 86917/186688 [00:47<00:48, 2075.36 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87834/186688 [00:48<00:50, 1960.23 examples/s]Running tokproc=64):  46%|████▌     | 85668/186688 [00:46<00:35, 2869.32 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▋     | 86668/186688 [00:46<00:31, 3201.00 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87668/186688 [00:47<00:31, 3171.21 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 89585/186688 [00:47<00:26, 3654.74 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 91502/186688 [00:48<00:26, 3555.42 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 92502/186688 [00:48<00:27, 3397.85 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 93502/186688 [00:48<00:24, 3793.73 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94502/186688 [00:48<00:24, 3827.42 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 95419/186688 [00:49<00:33, 2707.68 examplesset (num_proc=64):  47%|████▋     | 86834/186688 [00:47<00:36, 2701.44 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87834/186688 [00:47<00:36, 2696.42 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 88834/186688 [00:47<00:30, 3193.13 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 89751/186688 [00:47<00:25, 3792.70 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 91751/186688 [00:47<00:16, 5909.07 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 92751/186688 [00:48<00:37, 2524.68 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 93668/186688 [00:49<00:44, 2113.01 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94585/186688 [00:49<00:36, 2533.68 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96502/186688 [00:50<00:26, 3409.1000/186688 [00:44<00:45, 2310.68 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 82000/186688 [00:45<00:41, 2524.83 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 83000/186688 [00:45<00:40, 2549.08 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 84000/186688 [00:47<01:20, 1272.50 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 86000/186688 [00:48<01:12, 1388.33 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 88000/186688 [00:49<00:57, 1710.90 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 90000/186688 [00:49<00:44, 2170.48 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▊     | 91000/186688 [00:49<00:37, 2527.43 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 92000/186688 [00:50<00:35, 2683.21 examples/s]Running tokenizer on dataset (num_%|████▎     | 81000/186688 [00:46<00:52, 2004.49 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 83000/186688 [00:46<00:41, 2524.20 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 86000/186688 [00:47<00:34, 2893.53 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 86917/186688 [00:47<00:31, 3143.18 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87917/186688 [00:48<00:42, 2316.23 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 89834/186688 [00:50<00:58, 1646.64 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▊     | 90751/186688 [00:50<00:52, 1837.79 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 91668/186688 [00:51<00:53, 1783.01 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 92668/186688 [00:51<00:50, 1861.25 examples/s]Running tenizer on dataset (num_proc=64):  48%|████▊     | 88834/186688 [00:49<01:05, 1488.11 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 89834/186688 [00:49<01:03, 1525.52 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▊     | 90834/186688 [00:50<00:50, 1910.50 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 91834/186688 [00:50<00:52, 1796.86 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 92751/186688 [00:51<00:49, 1880.84 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94668/186688 [00:51<00:36, 2524.63 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 95585/186688 [00:51<00:30, 2947.52 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96585/186688 [00:51<00:24, 3619.11 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 97585/186688 [00n dataset (num_proc=64):  49%|████▊     | 90585/186688 [00:47<00:19, 5038.52 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 92502/186688 [00:48<00:14, 6498.38 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 93502/186688 [00:49<00:35, 2635.29 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94502/186688 [00:49<00:37, 2479.77 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 95502/186688 [00:50<00:48, 1865.91 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96419/186688 [00:51<01:04, 1396.99 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98336/186688 [00:52<00:41, 2119.29 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 99336/186688 [00:52<00:47, 1824.66 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▎    | 100253/186688 [00:52g tokenizer on dataset (num_proc=64):  49%|████▊     | 90585/186688 [00:49<00:58, 1632.21 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 91502/186688 [00:49<00:48, 1980.26 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 92502/186688 [00:50<01:17, 1216.29 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 93419/186688 [00:51<01:14, 1253.03 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94336/186688 [00:51<01:02, 1481.88 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 95253/186688 [00:52<00:51, 1791.82 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96253/186688 [00:52<00:43, 2082.13 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98170/186688 [00:52<00:26, 3348.25 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 99087/186/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96336/186688 [00:49<00:31, 2878.37 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98170/186688 [00:50<00:37, 2391.15 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 99087/186688 [00:50<00:31, 2781.27 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▎    | 100004/186688 [00:51<00:34, 2539.49 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 100921/186688 [00:51<00:30, 2777.79 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 101921/186688 [00:52<00:43, 1948.04 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 102921/186688 [00:52<00:41, 2014.40 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 103921/186688 [00:53<00:35, 2314.50 examples/s]Running tokenizer on dataset (num_proc=64):  56%|██on dataset (num_proc=64):  46%|████▌     | 85917/186688 [00:47<00:43, 2334.64 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 87917/186688 [00:49<01:10, 1408.05 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 88834/186688 [00:49<01:00, 1615.49 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 89834/186688 [00:50<00:54, 1780.20 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▊     | 90834/186688 [00:51<01:09, 1382.79 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 93668/186688 [00:52<00:45, 2024.42 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94585/186688 [00:52<00:45, 2008.89 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 95502/186688 [00:52<00:40, 2240.54 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96502/186688 [00:53<00:56:52<00:25, 3485.75 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98502/186688 [00:52<00:32, 2689.87 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 100419/186688 [00:53<00:31, 2781.67 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 101336/186688 [00:53<00:26, 3211.17 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 102336/186688 [00:53<00:23, 3575.33 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104170/186688 [00:54<00:19, 4314.32 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▋    | 105170/186688 [00:54<00:25, 3206.66 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106087/186688 [00:54<00:22, 3622.70 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 107087/186688 [00:54<00:19, 4108.74 examples/s]Running tokenizer on datasproc=64):  50%|█████     | 94000/186688 [00:50<00:23, 3918.55 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████▏    | 95917/186688 [00:50<00:19, 4736.74 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96834/186688 [00:50<00:20, 4458.57 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98751/186688 [00:52<00:44, 1972.07 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 100668/186688 [00:52<00:32, 2657.14 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 102502/186688 [00:53<00:25, 3271.63 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 103419/186688 [00:53<00:24, 3342.78 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104419/186688 [00:54<00:45, 1789.22 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▋    | 105336/186688 [00:55<00okenizer on dataset (num_proc=64):  50%|█████     | 93668/186688 [00:51<00:39, 2377.54 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 94668/186688 [00:53<01:01, 1506.58 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 95585/186688 [00:53<00:50, 1790.53 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 96585/186688 [00:53<00:44, 2036.00 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 97585/186688 [00:54<00:56, 1573.50 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98585/186688 [00:55<00:53, 1648.93 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 99502/186688 [00:55<00:48, 1807.42 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 101419/186688 [00:56<00:35, 2414.98 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 1023321 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 97502/186688 [00:50<00:39, 2236.32 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98502/186688 [00:53<01:26, 1013.71 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 99419/186688 [00:53<01:10, 1230.63 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 100419/186688 [00:54<01:12, 1197.47 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 101336/186688 [00:55<01:06, 1278.88 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 102253/186688 [00:55<00:53, 1578.40 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 103170/186688 [00:55<00:50, 1661.41 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104087/186688 [00:56<00:41, 2004.31 examples/s]Running tokenizer on dataset (num_proc=64): , 1603.80 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 97502/186688 [00:54<00:51, 1736.68 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 98502/186688 [00:54<00:41, 2126.39 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 99419/186688 [00:55<00:45, 1931.10 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▎    | 100336/186688 [00:55<00:35, 2432.58 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 101253/186688 [00:55<00:27, 3051.33 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 102170/186688 [00:55<00:29, 2841.81 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 103170/186688 [00:55<00:23, 3512.72 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104087/186688 [00:56<00:29, 2794.53 examples/s]Running tokenizer on dataset (num_pro688 [00:53<00:32, 2705.48 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▎    | 100004/186688 [00:53<00:36, 2356.96 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 100921/186688 [00:54<00:47, 1819.06 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 101921/186688 [00:54<00:41, 2047.86 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 103838/186688 [00:55<00:26, 3167.97 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104838/186688 [00:55<00:31, 2613.83 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 105755/186688 [00:55<00:29, 2720.60 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106755/186688 [00:56<00:27, 2877.00 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 107672/186688 [00:56<00:29, 2650.41 examples/s]Running tokenizer ███▌    | 104838/186688 [00:53<00:31, 2607.40 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106755/186688 [00:54<00:31, 2548.99 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 107755/186688 [00:55<00:46, 1685.83 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108755/186688 [00:55<00:40, 1909.33 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▊    | 109672/186688 [00:56<00:43, 1774.69 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110672/186688 [00:56<00:34, 2230.79 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 111672/186688 [00:56<00:30, 2458.57 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 113506/186688 [00:56<00:18, 3894.09 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 114423/186688 [00:57<00:24, 2948.38 <00:38, 2222.49 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 101170/186688 [00:53<00:33, 2559.80 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 102170/186688 [00:53<00:39, 2142.34 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 103087/186688 [00:55<00:58, 1419.94 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104004/186688 [00:55<00:50, 1646.92 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 105004/186688 [00:55<00:37, 2201.68 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 105921/186688 [00:56<00:57, 1403.43 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106921/186688 [00:56<00:44, 1782.03 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108755/186688 [00:57<00:28, 2687.80 examples/s]Running tokenizer on dataset:38, 2097.68 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106253/186688 [00:55<00:36, 2190.67 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 107170/186688 [00:55<00:30, 2608.54 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108087/186688 [00:56<00:32, 2383.40 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 109004/186688 [00:56<00:43, 1766.30 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110004/186688 [00:57<00:35, 2182.62 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110921/186688 [00:57<00:27, 2708.57 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 112838/186688 [00:57<00:19, 3886.26 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 114672/186688 [00:57<00:13, 5223.95 examples/s]Running tokenizer on dataset 6/186688 [00:56<00:30, 2799.38 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 104170/186688 [00:56<00:23, 3473.47 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▋    | 105170/186688 [00:57<00:28, 2811.68 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106087/186688 [00:57<00:30, 2680.35 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 107004/186688 [00:57<00:25, 3078.67 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108921/186688 [00:58<00:22, 3434.42 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110838/186688 [00:58<00:15, 4937.61 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 111838/186688 [00:58<00:16, 4581.04 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 112838/186688 [00:58<00:15, 4733.47 examples/s]Running tokenet (num_proc=64):  58%|█████▊    | 108004/186688 [00:55<00:17, 4504.97 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108921/186688 [00:57<00:59, 1314.09 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 109838/186688 [00:57<00:47, 1626.10 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110755/186688 [00:57<00:38, 1985.86 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 111672/186688 [00:57<00:31, 2394.86 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 112589/186688 [00:58<00:37, 1977.58 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 113506/186688 [00:58<00:33, 2185.94 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 114506/186688 [00:59<00:28, 2496.80 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 11542on dataset (num_proc=64):  58%|█████▊    | 108672/186688 [00:57<00:30, 2552.69 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▊    | 109589/186688 [00:57<00:27, 2853.93 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110589/186688 [00:57<00:27, 2803.70 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 111589/186688 [00:58<00:27, 2768.06 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 112506/186688 [00:58<00:29, 2485.67 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 114423/186688 [00:58<00:17, 4030.77 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 115423/186688 [00:58<00:16, 4215.63 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 116340/186688 [00:59<00:21, 3201.28 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████ 56%|█████▌    | 105004/186688 [00:56<00:39, 2065.18 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106921/186688 [00:56<00:26, 3032.99 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 107838/186688 [00:57<00:33, 2357.23 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108838/186688 [00:58<00:42, 1835.44 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 109755/186688 [00:58<00:38, 1990.01 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 110672/186688 [00:59<00:34, 2201.03 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 111589/186688 [00:59<00:30, 2447.88 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 113423/186688 [00:59<00:22, 3258.84 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 114340/186688 [00:59<00:21,(num_proc=64):  62%|██████▏   | 115672/186688 [00:57<00:14, 4989.19 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 117589/186688 [00:58<00:14, 4788.05 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▎   | 118589/186688 [00:58<00:15, 4302.74 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 119506/186688 [00:58<00:14, 4524.05 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 120423/186688 [00:59<00:13, 4738.95 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 122340/186688 [00:59<00:17, 3650.88 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 124174/186688 [01:00<00:15, 3913.90 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 125091/186688 [01:00<00:13, 4441.40 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████c=64):  56%|█████▌    | 105004/186688 [00:56<00:31, 2599.20 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106004/186688 [00:56<00:24, 3262.23 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 106921/186688 [00:57<00:26, 2983.40 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 107921/186688 [00:57<00:25, 3123.00 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 108838/186688 [00:58<00:34, 2270.25 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 109755/186688 [00:58<00:38, 1985.29 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 111672/186688 [00:59<00:23, 3208.92 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 113506/186688 [01:00<00:31, 2319.83 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 114423/186688 [01: (num_proc=64):  60%|█████▉    | 111589/186688 [00:57<00:18, 3960.83 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 112506/186688 [00:57<00:19, 3870.33 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 114423/186688 [00:58<00:21, 3298.80 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 115340/186688 [00:59<00:24, 2925.20 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 118091/186688 [00:59<00:15, 4296.20 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 120008/186688 [00:59<00:14, 4635.30 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 120925/186688 [01:00<00:19, 3367.22 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 121925/186688 [01:00<00:18, 3503.71 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌  examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 116257/186688 [00:57<00:20, 3493.33 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 117257/186688 [00:58<00:19, 3593.17 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 118174/186688 [00:58<00:28, 2400.18 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 119174/186688 [00:59<00:25, 2625.91 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 120091/186688 [00:59<00:28, 2314.32 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 122842/186688 [01:00<00:17, 3658.57 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 124759/186688 [01:00<00:20, 3033.45 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126676/186688 [01:01<00:16, 3641.68 examples/s]Running tokenizer on datasetizer on dataset (num_proc=64):  61%|██████    | 113838/186688 [00:59<00:28, 2593.79 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 115755/186688 [00:59<00:18, 3867.62 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 116672/186688 [01:00<00:20, 3418.45 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 117589/186688 [01:00<00:17, 3876.08 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 118506/186688 [01:00<00:18, 3715.16 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 120340/186688 [01:01<00:19, 3351.81 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 121340/186688 [01:01<00:19, 3289.82 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 123174/186688 [01:01<00:17, 3728.89 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██3/186688 [00:59<00:34, 2055.52 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 119174/186688 [01:00<00:20, 3278.15 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 120174/186688 [01:00<00:19, 3356.02 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 121174/186688 [01:00<00:16, 3915.83 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 122091/186688 [01:01<00:19, 3325.52 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▋   | 124008/186688 [01:01<00:16, 3720.38 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 124925/186688 [01:01<00:15, 3918.14 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 125842/186688 [01:02<00:15, 3894.33 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126759/186688 [01:02<00:13, 4500.93 examples/ 3427.95 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 117257/186688 [01:00<00:13, 4981.63 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 119091/186688 [01:00<00:10, 6379.71 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 121842/186688 [01:00<00:11, 5778.41 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 122759/186688 [01:01<00:11, 5470.15 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 123676/186688 [01:01<00:12, 4887.80 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 124676/186688 [01:01<00:12, 4918.77 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126593/186688 [01:01<00:09, 6354.18 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127593/186688 [01:01<00:09, 6188.88 examples/s]Running tokenizer o   | 126008/186688 [01:00<00:14, 4170.61 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126925/186688 [01:00<00:13, 4364.53 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127842/186688 [01:00<00:11, 4908.53 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 128759/186688 [01:01<00:13, 4400.22 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 129676/186688 [01:01<00:14, 3977.20 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 131593/186688 [01:01<00:13, 3997.27 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 133427/186688 [01:01<00:09, 5435.50 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 134344/186688 [01:02<00:13, 3812.12 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 135261/186688 [01:02<00:12, 00<00:33, 2157.17 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 115340/186688 [01:00<00:28, 2493.23 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 116340/186688 [01:01<00:23, 3037.40 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 117340/186688 [01:01<00:19, 3605.92 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 118257/186688 [01:01<00:21, 3175.43 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 119174/186688 [01:01<00:22, 2998.77 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 121008/186688 [01:02<00:16, 3962.98 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 122008/186688 [01:02<00:15, 4121.66 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 122925/186688 [01:02<00:17, 3680.46 examples/s]Running to | 122842/186688 [01:00<00:17, 3628.04 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▋   | 123759/186688 [01:01<00:17, 3629.87 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 125676/186688 [01:01<00:12, 4758.51 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127676/186688 [01:01<00:12, 4740.66 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 128676/186688 [01:01<00:12, 4687.12 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 130510/186688 [01:02<00:12, 4354.03 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 132427/186688 [01:02<00:09, 5831.62 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 133344/186688 [01:03<00:15, 3549.74 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 136095/186688 [01:03<00:09, 5313.   | 117257/186688 [00:59<00:25, 2726.74 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 119091/186688 [01:00<00:17, 3918.15 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 120008/186688 [01:00<00:16, 4137.16 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 120925/186688 [01:00<00:19, 3434.30 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 121842/186688 [01:00<00:19, 3315.41 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 124676/186688 [01:01<00:11, 5472.14 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126593/186688 [01:01<00:14, 4208.01 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127510/186688 [01:02<00:25, 2288.50 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 129427/186688 [01:03<00:23, 2434.████▋   | 124174/186688 [01:02<00:15, 4149.37 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 125174/186688 [01:02<00:13, 4677.89 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126091/186688 [01:02<00:13, 4378.78 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127008/186688 [01:02<00:12, 4869.25 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 128925/186688 [01:02<00:08, 7113.18 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 130759/186688 [01:03<00:12, 4419.10 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 132593/186688 [01:03<00:11, 4656.90 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 134427/186688 [01:03<00:10, 4967.03 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 135344/186688 [0n dataset (num_proc=64):  69%|██████▉   | 128510/186688 [01:02<00:12, 4611.42 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 129510/186688 [01:02<00:11, 4814.71 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 130427/186688 [01:02<00:11, 4942.30 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 131344/186688 [01:02<00:14, 3808.50 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 133261/186688 [01:03<00:13, 4034.00 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 134178/186688 [01:03<00:12, 4144.81 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 136012/186688 [01:04<00:14, 3593.42 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 137846/186688 [01:04<00:10, 4445.47 examples/s]Running tokenizer on dataset (num_proc=64):  74%| (num_proc=64):  68%|██████▊   | 127593/186688 [01:01<00:20, 2875.42 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 128510/186688 [01:01<00:18, 3110.25 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 130427/186688 [01:02<00:17, 3132.89 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 131344/186688 [01:02<00:18, 2974.66 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 133261/186688 [01:03<00:17, 3021.85 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 135095/186688 [01:03<00:13, 3796.18 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 136929/186688 [01:04<00:11, 4238.48 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 137846/186688 [01:04<00:10, 4626.17 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127676/186688 [01:02<00:15, 3754.39 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 130427/186688 [01:02<00:08, 6736.57 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 132261/186688 [01:03<00:10, 5041.32 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 133178/186688 [01:03<00:10, 5188.50 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 134178/186688 [01:03<00:09, 5735.51 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 135095/186688 [01:03<00:08, 6088.87 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 136012/186688 [01:04<00:12, 4084.45 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 137846/186688 [01:04<00:14, 3466.77 examples/s]Running tokenizer on datasekenizer on dataset (num_proc=64):  67%|██████▋   | 124842/186688 [01:03<00:14, 4353.91 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 125759/186688 [01:03<00:18, 3207.08 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 126676/186688 [01:03<00:16, 3731.16 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 127593/186688 [01:04<00:17, 3338.84 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 128510/186688 [01:04<00:14, 3967.86 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 130510/186688 [01:04<00:09, 5908.06 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 132344/186688 [01:04<00:07, 6980.20 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 134261/186688 [01:04<00:07, 6621.28 examples/s]Running tokenizer on dataset (num_proc=64):  72%4169.39 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 137095/186688 [01:02<00:08, 5783.00 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 138012/186688 [01:02<00:08, 5525.12 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 138929/186688 [01:03<00:09, 4800.70 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 140763/186688 [01:03<00:10, 4228.52 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141763/186688 [01:04<00:17, 2597.76 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▋  | 142680/186688 [01:05<00:18, 2394.99 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 144514/186688 [01:05<00:14, 3011.50 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 145514/186688 [01:05<00:13, 3088.03 examples/s]Runn36 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 130344/186688 [01:03<00:20, 2754.07 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 131261/186688 [01:03<00:17, 3182.14 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 133178/186688 [01:04<00:11, 4611.61 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 134095/186688 [01:04<00:12, 4232.30 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 135095/186688 [01:04<00:10, 4818.04 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 137929/186688 [01:05<00:13, 3495.11 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 138846/186688 [01:06<00:17, 2748.88 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▍  | 139846/186688 [01:06<00:17, 2677.55 examples/s]Running token1:04<00:14, 3489.10 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 138178/186688 [01:05<00:11, 4243.10 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▍  | 139095/186688 [01:05<00:11, 4224.69 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141012/186688 [01:05<00:09, 4614.53 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 142012/186688 [01:06<00:11, 3925.73 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 142929/186688 [01:06<00:14, 2934.17 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 144763/186688 [01:06<00:10, 3943.25 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 145680/186688 [01:07<00:10, 3907.91 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▊  | 146597/186688 [01:07<00:09, 4377.16 exam89 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 137012/186688 [01:04<00:14, 3390.18 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 137929/186688 [01:04<00:14, 3428.95 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 138846/186688 [01:05<00:19, 2436.39 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▍  | 139763/186688 [01:05<00:17, 2643.04 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 140680/186688 [01:05<00:17, 2643.13 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141680/186688 [01:05<00:15, 2893.37 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▋  | 142597/186688 [01:06<00:21, 2019.65 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 143597/186688 [01:07<00:23, 1810.52 examples/s]Running tt (num_proc=64):  75%|███████▍  | 139680/186688 [01:04<00:09, 4777.41 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 140597/186688 [01:04<00:09, 4799.95 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141514/186688 [01:05<00:11, 3925.71 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▋  | 142514/186688 [01:06<00:18, 2449.56 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 143431/186688 [01:06<00:15, 2712.58 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 144431/186688 [01:07<00:18, 2251.81 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 145348/186688 [01:07<00:15, 2735.49 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 147348/186688 [01:08<00:16, 2425.18 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▍  | 138763/186688 [01:04<00:11, 4229.21 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141680/186688 [01:04<00:06, 7086.34 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 143597/186688 [01:05<00:11, 3828.69 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 144514/186688 [01:06<00:11, 3818.10 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 145514/186688 [01:06<00:15, 2718.97 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 146514/186688 [01:07<00:15, 2631.65 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 147431/186688 [01:07<00:16, 2393.94 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 148431/186688 [01:07<00:12, 2990.78 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  |███████▏  | 135178/186688 [01:05<00:13, 3839.32 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 136095/186688 [01:05<00:12, 4010.88 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 138846/186688 [01:05<00:06, 6838.51 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 140763/186688 [01:06<00:09, 5048.30 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141763/186688 [01:06<00:11, 3763.15 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▋  | 142680/186688 [01:07<00:14, 3124.08 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 143597/186688 [01:07<00:16, 2540.58 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 144597/186688 [01:08<00:16, 2573.28 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████ing tokenizer on dataset (num_proc=64):  78%|███████▊  | 146514/186688 [01:05<00:10, 3667.00 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 147431/186688 [01:05<00:09, 4053.02 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 149265/186688 [01:06<00:11, 3232.36 examples/s]Running tokenizer on dataset (num_proc=64):  80%|████████  | 150265/186688 [01:06<00:10, 3405.93 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151265/186688 [01:07<00:14, 2400.56 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 152265/186688 [01:07<00:11, 2869.94 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153265/186688 [01:08<00:11, 2938.10 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 154182/186688 [01:08<00:09, 3362.61 examples/s]Running tokenizer on d███▍  | 138846/186688 [01:04<00:13, 3584.14 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 140763/186688 [01:05<00:10, 4211.05 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 141680/186688 [01:05<00:09, 4568.36 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 143597/186688 [01:05<00:11, 3881.20 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 144514/186688 [01:06<00:13, 3132.87 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 145431/186688 [01:07<00:21, 1959.05 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 148182/186688 [01:07<00:11, 3423.85 examples/s]Running tokenizer on dataset (num_proc=64):  80%|████████  | 150182/186688 [01:08<00:14, 2438.90 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151099/izer on dataset (num_proc=64):  75%|███████▌  | 140846/186688 [01:06<00:14, 3234.78 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▋  | 142680/186688 [01:06<00:10, 4364.13 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 143597/186688 [01:07<00:09, 4544.86 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 144514/186688 [01:08<00:22, 1878.08 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 145431/186688 [01:08<00:18, 2274.80 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 147348/186688 [01:09<00:16, 2345.96 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 148265/186688 [01:09<00:14, 2689.62 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 149265/186688 [01:09<00:12, 3061.65 examples/s]Running tokenizer on dataset (num_prookenizer on dataset (num_proc=64):  77%|███████▋  | 144514/186688 [01:07<00:21, 1951.18 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 146431/186688 [01:08<00:18, 2123.57 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 148265/186688 [01:09<00:18, 2126.80 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 149265/186688 [01:09<00:17, 2142.94 examples/s]Running tokenizer on dataset (num_proc=64):  80%|████████  | 150182/186688 [01:10<00:19, 1886.61 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151182/186688 [01:11<00:17, 2057.10 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████▏ | 152099/186688 [01:11<00:17, 1992.02 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153016/186688 [01:11<00:13, 2491.82 examples/s]Running tokenizer on dataset ██████▉  | 149265/186688 [01:08<00:10, 3444.18 examples/s]Running tokenizer on dataset (num_proc=64):  80%|████████  | 150265/186688 [01:08<00:09, 3990.46 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151265/186688 [01:09<00:13, 2682.56 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 152182/186688 [01:10<00:19, 1742.49 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153182/186688 [01:10<00:18, 1771.25 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 154182/186688 [01:11<00:14, 2171.35 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 155099/186688 [01:11<00:17, 1774.82 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▎ | 156016/186688 [01:12<00:14, 2051.20 examples/s]Running tokenizer on dataset (num_proc=64):  84%|█████  | 145514/186688 [01:08<00:14, 2913.25 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 146514/186688 [01:08<00:13, 3050.14 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 147514/186688 [01:09<00:21, 1810.12 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 149348/186688 [01:10<00:17, 2107.17 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 150348/186688 [01:10<00:14, 2443.21 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151265/186688 [01:10<00:12, 2890.36 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 152265/186688 [01:11<00:10, 3183.85 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153182/186688 [01:11<00:10, 3125.87 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 155016/186688ples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 147514/186688 [01:08<00:17, 2271.55 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 148431/186688 [01:08<00:13, 2739.43 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 149348/186688 [01:09<00:21, 1724.56 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 150348/186688 [01:09<00:19, 1902.69 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151265/186688 [01:10<00:15, 2217.64 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153099/186688 [01:10<00:10, 3063.03 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 154016/186688 [01:10<00:13, 2415.39 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 154933/186688 [01:11<00:14, 2173.04 examples/s]Running to| 149348/186688 [01:08<00:14, 2576.77 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 150348/186688 [01:09<00:25, 1427.18 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 151265/186688 [01:10<00:21, 1660.41 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 152182/186688 [01:10<00:20, 1681.67 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153182/186688 [01:11<00:24, 1349.52 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 154099/186688 [01:12<00:20, 1601.43 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▎ | 156016/186688 [01:12<00:13, 2191.52 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156933/186688 [01:12<00:13, 2238.57 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157933/186c=64):  81%|████████  | 151265/186688 [01:10<00:08, 4149.62 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 152182/186688 [01:10<00:09, 3622.39 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153182/186688 [01:10<00:09, 3468.39 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 154099/186688 [01:11<00:15, 2050.85 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▎ | 155933/186688 [01:13<00:21, 1438.72 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156850/186688 [01:14<00:24, 1195.36 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157850/186688 [01:16<00:28, 1015.97 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 158850/186688 [01:16<00:20, 1325.86 examples/s]Running tokenizer on dataset (num_proc=64):  86186688 [01:09<00:16, 2162.39 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████▏ | 152099/186688 [01:10<00:16, 2131.01 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 153016/186688 [01:10<00:13, 2554.26 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 154016/186688 [01:10<00:13, 2510.35 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 155016/186688 [01:10<00:12, 2466.57 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▎ | 155933/186688 [01:11<00:11, 2740.09 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156933/186688 [01:11<00:09, 3010.55 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 158850/186688 [01:12<00:10, 2568.58 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [(num_proc=64):  82%|████████▏ | 153933/186688 [01:11<00:11, 2892.20 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 154850/186688 [01:12<00:18, 1711.33 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 155850/186688 [01:13<00:15, 2029.25 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156850/186688 [01:14<00:20, 1455.99 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157850/186688 [01:14<00:14, 1958.10 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 158850/186688 [01:14<00:13, 2083.43 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [01:15<00:14, 1860.46 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:16<00:18, 1422.59 examples/s]Running tokenizer on dataset (num_proataset (num_proc=64):  83%|████████▎ | 155099/186688 [01:08<00:09, 3374.68 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▎ | 156016/186688 [01:08<00:08, 3832.91 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156933/186688 [01:09<00:07, 3906.09 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157850/186688 [01:09<00:13, 2214.15 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 158850/186688 [01:11<00:19, 1460.87 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [01:12<00:22, 1170.70 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:15<00:40, 637.59 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161850/186688 [01:17<00:42, 587.21 examples/s]Running tokenizer on dataset (n [01:12<00:10, 2914.16 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▎ | 156016/186688 [01:12<00:11, 2679.73 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156933/186688 [01:14<00:21, 1360.54 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157850/186688 [01:15<00:22, 1287.59 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 158850/186688 [01:16<00:27, 1007.47 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [01:18<00:31, 859.41 examples/s] Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:19<00:27, 942.62 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161850/186688 [01:28<01:28, 279.49 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162850/186688 [01:30<01kenizer on dataset (num_proc=64):  84%|████████▎ | 155933/186688 [01:12<00:18, 1699.89 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 156933/186688 [01:13<00:19, 1515.42 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157933/186688 [01:14<00:27, 1042.38 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [01:16<00:25, 1049.14 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:17<00:21, 1189.05 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161767/186688 [01:23<00:55, 445.50 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162767/186688 [01:27<01:07, 352.64 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:29<00:56, 405.78 examples/s]Running tokenizer on██▍ | 156933/186688 [01:12<00:11, 2609.17 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 157850/186688 [01:13<00:19, 1444.39 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 158850/186688 [01:15<00:31, 895.04 examples/s] Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [01:16<00:24, 1090.79 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:18<00:38, 676.36 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161850/186688 [01:21<00:45, 543.78 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162850/186688 [01:25<01:01, 388.70 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:31<01:22, 276.72 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊um_proc=64):  87%|████████▋ | 162767/186688 [01:20<00:52, 454.13 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:22<00:48, 473.22 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:22<00:34, 633.19 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:31<01:14, 280.34 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:31<00:50, 394.16 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 167767/186688 [01:32<00:41, 458.06 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:33<00:29, 602.69 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:34<00:26, 650.70 examples/s]Running tokenizer on dataset (num_proc=64):  91688 [01:14<00:24, 1171.57 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 159850/186688 [01:16<00:25, 1053.91 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:19<00:33, 777.69 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161767/186688 [01:23<00:49, 500.60 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162767/186688 [01:27<01:01, 387.61 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:29<00:55, 411.51 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:30<00:43, 501.75 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:33<00:48, 427.10 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:37<00%|████████▌ | 159850/186688 [01:16<00:16, 1620.91 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 160850/186688 [01:19<00:35, 723.93 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161767/186688 [01:25<01:05, 380.91 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162767/186688 [01:30<01:18, 305.81 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:30<00:55, 411.70 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:32<00:52, 419.20 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:35<00:49, 418.46 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:37<00:47, 416.60 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████01:17<00:43, 616.81 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 161767/186688 [01:22<00:47, 522.73 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162767/186688 [01:29<01:13, 325.18 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:33<01:16, 298.58 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:34<01:03, 347.73 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:36<00:51, 406.56 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:36<00:38, 523.75 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 167767/186688 [01:37<00:28, 663.16 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:38<00:26, 66c=64):  87%|████████▋ | 161850/186688 [01:19<00:36, 680.45 examples/s] Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 162850/186688 [01:27<01:16, 312.41 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163767/186688 [01:29<01:08, 336.38 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:36<01:31, 240.73 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:36<01:02, 336.00 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:37<00:46, 432.14 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 167767/186688 [01:38<00:38, 487.89 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168684/186688 [01:39<00:30, 597.29 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█:11, 332.89 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 163850/186688 [01:31<00:56, 404.44 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:33<00:50, 438.41 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:36<00:56, 372.31 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:38<00:48, 407.28 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:39<00:28, 629.76 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:41<00:26, 633.91 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 170767/186688 [01:42<00:24, 658.80 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:44<00:23, 632.97  | 164767/186688 [01:31<00:56, 391.39 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:34<00:58, 356.46 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:38<01:00, 331.18 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 167767/186688 [01:39<00:47, 394.19 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:40<00:34, 526.16 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:40<00:24, 700.30 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:40<00:11, 1251.47 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 172684/186688 [01:45<00:23, 588.57 examples/s] Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 17368 dataset (num_proc=64):  88%|████████▊ | 164767/186688 [01:30<00:45, 482.39 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 165767/186688 [01:33<00:52, 400.40 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 166767/186688 [01:35<00:42, 468.03 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:36<00:27, 648.54 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:38<00:26, 632.37 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 170767/186688 [01:39<00:21, 753.61 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:44<00:36, 403.47 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 172767/186688 [01:46<00:31, 442.94 examples/s]Running tokenizer on dataset (%|█████████▏| 170767/186688 [01:34<00:17, 889.49 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:34<00:13, 1142.57 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 172684/186688 [01:37<00:20, 673.13 examples/s] Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 173684/186688 [01:39<00:21, 602.77 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174684/186688 [01:40<00:15, 757.13 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175601/186688 [01:43<00:23, 476.46 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:44<00:15, 652.91 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [01:48<00:23, 384.69 examples/s]Running tokenizer on dataset (num_proc=64):  :59, 337.35 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 167767/186688 [01:38<00:43, 438.71 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:38<00:30, 593.16 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:39<00:23, 711.63 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 170767/186688 [01:40<00:21, 744.50 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:43<00:24, 599.13 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 172767/186688 [01:48<00:37, 368.91 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174767/186688 [01:49<00:19, 606.81 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175684/186688 [01:50<00:18, 6████▉ | 167767/186688 [01:38<00:34, 541.22 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 168767/186688 [01:41<00:42, 418.32 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:42<00:31, 543.00 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 170767/186688 [01:43<00:23, 673.62 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:43<00:16, 931.26 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 172767/186688 [01:46<00:24, 569.30 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 173767/186688 [01:49<00:26, 485.05 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174767/186688 [01:51<00:26, 454.37 examples/s]Running tokenizer on dataset (num_proc=64):  94%|██████7.22 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 169767/186688 [01:38<00:19, 866.37 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 170767/186688 [01:40<00:20, 769.08 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171767/186688 [01:40<00:14, 1032.50 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 172767/186688 [01:44<00:25, 554.57 examples/s] Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 173767/186688 [01:47<00:28, 455.64 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174767/186688 [01:48<00:22, 530.94 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175684/186688 [01:52<00:26, 421.58 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:56<00:31, 32████████ | 169684/186688 [01:42<00:34, 486.94 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 170684/186688 [01:43<00:28, 554.17 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 171684/186688 [01:43<00:21, 713.25 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 172684/186688 [01:44<00:14, 987.29 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 173684/186688 [01:45<00:15, 855.02 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174684/186688 [01:47<00:17, 698.53 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175684/186688 [01:51<00:23, 458.77 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:55<00:29, 341.98 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█96%|█████████▌| 178435/186688 [01:49<00:15, 529.30 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [01:57<00:29, 246.33 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [01:58<00:19, 334.02 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [01:58<00:11, 466.43 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 182103/186688 [01:58<00:07, 581.07 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [01:59<00:04, 763.35 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:03<00:06, 455.67 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:03<00:03, 547.85 examples/s]Running tokenizer on dataset (num_proc=64): 1examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 172767/186688 [01:46<00:24, 566.28 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 173767/186688 [01:48<00:23, 560.38 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174767/186688 [01:48<00:15, 767.32 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175684/186688 [01:53<00:27, 402.73 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:55<00:22, 442.13 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [01:58<00:24, 370.28 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [02:05<00:33, 247.13 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:06<00:23, 313.90 num_proc=64):  94%|█████████▎| 174767/186688 [01:48<00:19, 604.83 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175684/186688 [01:50<00:21, 510.73 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:51<00:16, 604.90 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [01:52<00:12, 721.68 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [02:03<00:34, 236.71 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:03<00:23, 310.32 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [02:05<00:19, 333.46 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:06<00:13, 407.20 examples/s]Running tokenizer on dataset (4/186688 [01:47<00:23, 549.78 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 174601/186688 [01:48<00:20, 585.60 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 175601/186688 [01:48<00:14, 776.83 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:49<00:10, 953.26 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [01:55<00:24, 367.65 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [02:01<00:30, 274.16 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:07<00:32, 225.69 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:08<00:15, 353.20 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 1821008.62 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:52<00:18, 548.60 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [01:59<00:29, 315.46 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [01:59<00:19, 427.99 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:01<00:17, 427.50 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [02:06<00:21, 297.24 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:09<00:16, 328.40 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 182103/186688 [02:09<00:10, 441.99 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [02:10<00:06, 500%|█████████▉| 185771/186688 [02:06<00:01, 508.04 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:09<00:00, 403.96 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:10<00:00, 1435.71 examples/s]
███▍| 175684/186688 [01:52<00:19, 550.69 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 176601/186688 [01:56<00:26, 376.68 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [02:02<00:33, 270.96 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [02:03<00:24, 337.38 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:05<00:19, 380.64 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [02:06<00:13, 485.30 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:09<00:13, 408.07 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 182103/186688 [02:09<00:08, 524.15 examples/s]Running tokenizer on dataset (num_proc=64):  98%|██████0.21 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 177518/186688 [01:57<00:23, 398.53 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [02:04<00:31, 259.21 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:05<00:23, 316.59 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [02:06<00:15, 413.49 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:07<00:12, 456.56 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 182103/186688 [02:08<00:07, 605.21 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [02:09<00:05, 617.75 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:11<00:05, 53███████▌| 177518/186688 [01:59<00:29, 308.85 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 178435/186688 [02:02<00:27, 302.62 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 179352/186688 [02:06<00:24, 295.90 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [02:08<00:20, 308.03 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:09<00:14, 388.72 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 182103/186688 [02:10<00:09, 487.79 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [02:11<00:06, 539.68 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:12<00:04, 673.24 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█num_proc=64):  98%|█████████▊| 182103/186688 [02:07<00:09, 502.58 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [02:09<00:07, 467.78 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:10<00:04, 570.80 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:12<00:03, 580.27 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:13<00:01, 603.70 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:14<00:00, 675.54 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:15<00:00, 1379.31 examples/s]
examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 180269/186688 [02:07<00:16, 383.02 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 181186/186688 [02:08<00:10, 511.20 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 182103/186688 [02:10<00:09, 474.21 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [02:11<00:06, 561.48 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:11<00:03, 730.11 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:12<00:02, 720.38 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:14<00:01, 632.57 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:16<00:00, 602.20 1.58 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:13<00:03, 557.32 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:14<00:01, 591.87 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:15<00:00, 619.54 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:16<00:00, 1366.10 examples/s]
50.31 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:10<00:03, 708.19 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:14<00:03, 464.12 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:16<00:01, 460.88 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:16<00:00, 1363.73 examples/s]
3/186688 [02:09<00:10, 420.10 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 183020/186688 [02:10<00:07, 523.53 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:11<00:05, 547.42 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:13<00:03, 536.71 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:16<00:01, 459.24 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:16<00:00, 618.41 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:17<00:00, 1361.52 examples/s]
examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:17<00:00, 1359.51 examples/s]
███████▉| 184854/186688 [02:13<00:02, 724.37 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:14<00:01, 655.42 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:17<00:00, 538.69 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:18<00:00, 1350.62 examples/s]
███▊| 183020/186688 [02:10<00:05, 677.21 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 183937/186688 [02:12<00:05, 529.66 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 184854/186688 [02:15<00:03, 487.38 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 185771/186688 [02:16<00:01, 498.51 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:17<00:00, 610.69 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [02:18<00:00, 1350.29 examples/s]
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,838 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,839 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:763] 2025-10-04 12:47:58,849 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 12:47:58,850 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,452 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,453 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,460 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,461 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,462 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,463 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,466 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,467 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,469 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,470 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,471 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,473 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,477 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,477 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,477 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,477 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 12:47:59,479 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 12:47:59,479 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,489 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,490 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,492 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,496 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,496 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 12:47:59,501 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:30,  1.26s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:30,  1.26s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:30,  1.26s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:30,  1.26s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:27,  2.92s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:27,  2.92s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:27,  2.92s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:27,  2.92s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:36,  3.09s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:36,  3.09s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.90s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.18s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:31,  1.27s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:31,  1.27s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:25,  1.19s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:33,  1.30s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:26,  2.91s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:26,  2.91s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:25,  2.89s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:29,  2.95s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:36,  3.10s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:36,  3.10s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:36,  3.09s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:36,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:57,  3.44s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:57,  3.44s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:57,  3.44s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:57,  3.44s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:35,  3.08s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:08<03:37,  3.10s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:56,  3.43s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:12<03:57,  3.44s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.94s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.94s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.93s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:14<03:19,  2.94s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.49s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:14,  3.04s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:14,  3.04s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.49s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.49s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.49s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.49s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.27s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.27s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03         | 6/73 [00:18<03:39,  3.28s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:21<03:35,  3.26s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:25<03:46,  3.48s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:27<03:13,  3.03s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.93s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.93s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:16,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:16,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:14,  3.24s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:31<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:01,  2.92s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:17,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:14,  3.24s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:41<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.44s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.44s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.39s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.39s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.55s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.55s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:40<03:13,  3.23s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:44<03:23,  3.45s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:48<03:16,  3.38s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shard73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:52<03:22,  3.56s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.47s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:55<03:14,  3.48s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:59<03:19,  3.63s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.16s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.16s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.39s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27ss:  26%|██▌       | 19/73 [01:01<02:50,  3.15s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:05<02:59,  3.38s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:07<02:35,  2.99s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:11<02:46,  3.27s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:46,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:46,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:52,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:52,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:48,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:48,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:48,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:48,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:14<02:45,  3.32s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:18<02:53,  3.53s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:22<02:47,  3.50s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:25,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:25,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.38s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.38s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:26<02:50,  3.63s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:28<02:24,  3.15s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:32<02:32,  3.39s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.99s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.99s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.26s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.26s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:02,  2.91s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:02,  2.91s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:1 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:34<02:11,  2.98s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:38<02:20,  3.27s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:01,  2.90s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:13,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:13,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  4,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:44<02:14,  3.27s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:47<02:11,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:51<02:15,  3.48s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.34s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.34s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:02,  3.3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.05s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<01:55,  3.04s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:02,  3.31s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  51%|█████     | 37/73 [02:00<02:00,  3.33s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:02,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.64s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:04<02:03,  3.51s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:08<01:58,  3.48s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:12<02:00,  3.65s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:45,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:45,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.01s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.01s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:14<01:42,  3.20s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:18<01:46,  3.42s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:20<01:30,  3.00s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loa███    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:24<01:35,  3.28s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:27<01:32,  3.31s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:31<01:34,  3.50s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.44s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.44s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:34<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:38<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Load▋   | 49/73 [02:40<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:44<01:17,  3.36s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:48<01:13,  3.34s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.14s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.14s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.38s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.38s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.36s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:52<01:14,  3.55s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:02,  3.13s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:04,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.36s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.52s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.52s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:49,  3.33s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:01<01:00,  3.35s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:05<00:59,  3.53s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:49,  3.08s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:49,  3.33s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:47,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:47,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:50,  3.34s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:46,  3.36s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.54s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:20<00:37,  3.12s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:37,  3.12s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.38s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.38s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:24<00:37,  3.39s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:37,  3.39s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:29,  2.99s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:29,  2.99s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:26<00:29,  2.98s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.26s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.26s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.29s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.29s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.29s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.47s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.47s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:26<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:26<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:26<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:26<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:26<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:26<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:29,  2.98s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:30<00:29,  3.27s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:34<00:26,  3.28s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.05s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.05s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.33s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|██████03:38<00:24,  3.48s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:38<00:24,  3.48s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:40<00:18,  3.04s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:16,  3.31s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.33s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:47<00:13,  3.32s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:51<00:10,  3.54s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:53<00:06,  3.11s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]


Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,100 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,101 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,100 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,101 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,103 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,103 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,103 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,103 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,104 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,104 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,105 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it][INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,105 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,109 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,110 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,112 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,112 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:57<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]

Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,113 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,113 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,113 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,114 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,113 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,114 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,115 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,116 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,116 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,116 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,117 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,117 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:01<00:00,  3.31s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 12:52:07,140 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 12:52:07,141 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1008] 2025-10-04 12:52:07,143 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 12:52:07,143 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|trainer.py:757] 2025-10-04 12:52:10,375 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 12:52:10,376 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 12:52:10,382 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 12:52:10,383 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 12:52:10,392 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 12:52:10,393 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 12:52:10,404 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 12:52:10,405 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 12:52:10,409 >> Using auto half precision backend
[INFO|trainer.py:757] 2025-10-04 12:52:10,410 >> Using auto half precision backend
[WARNING|trainer.py:985] 2025-10-04 12:52:10,410 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 12:52:10,411 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 12:52:10,414 >> Using auto half precision backend
[WARNING|trainer.py:985] 2025-10-04 12:52:10,416 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 12:52:10,416 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 12:52:10,417 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,670 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,689 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,703 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,708 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,716 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 4. Using DeepSpeed's value.
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,724 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,725 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 12:52:10,823 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
[rank15]:W1004 12:52:11.444000 184921 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank15]:W1004 12:52:11.444000 184921 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank23]:W1004 12:52:11.498000 1648916 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank23]:W1004 12:52:11.498000 1648916 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank13]:W1004 12:52:11.530000 184919 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank13]:W1004 12:52:11.530000 184919 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank16]:W1004 12:52:11.544000 2472024 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank16]:W1004 12:52:11.544000 2472024 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank26]:W1004 12:52:11.564000 3446846 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank26]:W1004 12:52:11.564000 3446846 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank4]:W1004 12:52:11.599000 3530119 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank4]:W1004 12:52:11.599000 3530119 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[INFO|trainer.py:2523] 2025-10-04 12:52:13,644 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 12:52:13,644 >>   Num examples = 186,688
[INFO|trainer.py:2525] 2025-10-04 12:52:13,644 >>   Num Epochs = 1
[INFO|trainer.py:2523] 2025-10-04 12:52:13,644 >> ***** Running training *****
[INFO|trainer.py:2526] 2025-10-04 12:52:13,644 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,644 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,644 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2524] 2025-10-04 12:52:13,644 >>   Num examples = 186,688
[INFO|trainer.py:2531] 2025-10-04 12:52:13,644 >>   Total optimization steps = 1,459
[INFO|trainer.py:2525] 2025-10-04 12:52:13,644 >>   Num Epochs = 1
[INFO|trainer.py:2523] 2025-10-04 12:52:13,644 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 12:52:13,644 >>   Num examples = 186,688
[INFO|trainer.py:2523] 2025-10-04 12:52:13,644 >> ***** Running training *****
[INFO|trainer.py:2525] 2025-10-04 12:52:13,644 >>   Num Epochs = 1
[INFO|trainer.py:2526] 2025-10-04 12:52:13,644 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,644 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2524] 2025-10-04 12:52:13,644 >>   Num examples = 186,688
[INFO|trainer.py:2530] 2025-10-04 12:52:13,644 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2525] 2025-10-04 12:52:13,644 >>   Num Epochs = 1
[INFO|trainer.py:2531] 2025-10-04 12:52:13,644 >>   Total optimization steps = 1,459
[INFO|trainer.py:2526] 2025-10-04 12:52:13,644 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,644 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,644 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 12:52:13,644 >>   Total optimization steps = 1,459
[INFO|trainer.py:2526] 2025-10-04 12:52:13,644 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,644 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,644 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 12:52:13,644 >>   Total optimization steps = 1,459
[INFO|trainer.py:2523] 2025-10-04 12:52:13,645 >> ***** Running training *****
[INFO|trainer.py:2523] 2025-10-04 12:52:13,645 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 12:52:13,645 >>   Num examples = 186,688
[INFO|trainer.py:2524] 2025-10-04 12:52:13,645 >>   Num examples = 186,688
[INFO|trainer.py:2525] 2025-10-04 12:52:13,645 >>   Num Epochs = 1
[INFO|trainer.py:2525] 2025-10-04 12:52:13,645 >>   Num Epochs = 1
[INFO|trainer.py:2526] 2025-10-04 12:52:13,645 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,645 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,645 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 12:52:13,645 >>   Total optimization steps = 1,459
[INFO|trainer.py:2526] 2025-10-04 12:52:13,645 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,645 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,645 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 12:52:13,645 >>   Total optimization steps = 1,459
[INFO|trainer.py:2523] 2025-10-04 12:52:13,645 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 12:52:13,645 >>   Num examples = 186,688
[INFO|trainer.py:2525] 2025-10-04 12:52:13,645 >>   Num Epochs = 1
[INFO|trainer.py:2526] 2025-10-04 12:52:13,645 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,645 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,645 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 12:52:13,645 >>   Total optimization steps = 1,459
[INFO|trainer.py:2532] 2025-10-04 12:52:13,646 >>   Number of trainable parameters = 5,971,968
[INFO|trainer.py:2532] 2025-10-04 12:52:13,646 >>   Number of trainable parameters = 5,971,968
[INFO|trainer.py:2532] 2025-10-04 12:52:13,646 >>   Number of trainable parameters = 5,971,968
[INFO|trainer.py:2532] 2025-10-04 12:52:13,647 >>   Number of trainable parameters = 5,971,968
[INFO|trainer.py:2532] 2025-10-04 12:52:13,648 >>   Number of trainable parameters = 5,971,968
[INFO|trainer.py:2532] 2025-10-04 12:52:13,648 >>   Number of trainable parameters = 5,971,968
[INFO|trainer.py:2532] 2025-10-04 12:52:13,648 >>   Number of trainable parameters = 5,971,968
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|trainer.py:2523] 2025-10-04 12:52:13,857 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 12:52:13,857 >>   Num examples = 186,688
[INFO|trainer.py:2525] 2025-10-04 12:52:13,857 >>   Num Epochs = 1
[INFO|trainer.py:2526] 2025-10-04 12:52:13,857 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 12:52:13,857 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 12:52:13,857 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 12:52:13,857 >>   Total optimization steps = 1,459
[INFO|trainer.py:2532] 2025-10-04 12:52:13,860 >>   Number of trainable parameters = 5,971,968
srun: Job step aborted: Waiting up to 47 seconds for job step to finish.
slurmstepd: error: *** JOB 1176584 ON della-j16g1 CANCELLED AT 2025-10-04T12:57:03 ***
  0%|          | 0/1459 [00:00<?, ?it/s]  0%|          | 1/1459 [01:31<37:02:40, 91.47s/it]  0%|          | 2/1459 [02:43<32:22:15, 79.98s/it]  0%|          | 3/1459 [03:56<31:03:12, 76.78s/it]slurmstepd: error: *** STEP 1176584.0 ON della-j16g1 CANCELLED AT 2025-10-04T12:57:03 ***
W1004 12:57:03.906000 8870 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.906000 3446796 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.906000 184869 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.906000 3530070 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.906000 3291551 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.906000 2471974 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.906000 3425962 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.907000 8870 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 8925 closing signal SIGTERM
W1004 12:57:03.907000 3446796 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3446844 closing signal SIGTERM
W1004 12:57:03.907000 184869 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 184918 closing signal SIGTERM
W1004 12:57:03.907000 2471974 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2472024 closing signal SIGTERM
W1004 12:57:03.907000 3425962 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3426010 closing signal SIGTERM
W1004 12:57:03.907000 3291551 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3291601 closing signal SIGTERM
W1004 12:57:03.907000 1648859 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1004 12:57:03.907000 3530070 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3530119 closing signal SIGTERM
W1004 12:57:03.907000 1648859 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1648913 closing signal SIGTERM
W1004 12:57:03.908000 8870 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 8926 closing signal SIGTERM
W1004 12:57:03.909000 3530070 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3530120 closing signal SIGTERM
W1004 12:57:03.914000 1648859 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1648914 closing signal SIGTERM
W1004 12:57:03.920000 3446796 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3446845 closing signal SIGTERM
W1004 12:57:03.910000 3291551 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3291602 closing signal SIGTERM
W1004 12:57:03.913000 184869 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 184919 closing signal SIGTERM
W1004 12:57:03.913000 3425962 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3426011 closing signal SIGTERM
W1004 12:57:03.914000 2471974 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2472025 closing signal SIGTERM
W1004 12:57:03.937000 1648859 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1648915 closing signal SIGTERM
W1004 12:57:03.937000 3291551 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3291603 closing signal SIGTERM
W1004 12:57:03.936000 3530070 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3530121 closing signal SIGTERM
W1004 12:57:03.955000 8870 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 8927 closing signal SIGTERM
W1004 12:57:03.955000 3530070 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3530122 closing signal SIGTERM
W1004 12:57:03.956000 184869 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 184920 closing signal SIGTERM
