+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
++ head -n 1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=5 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
++ head -n 1
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=6 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=0 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
++ head -n 1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=4 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=3 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=1 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
++ head -n 1
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=7 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
++ scontrol show hostnames 'della-j12g2,della-j15g[1-3],della-j16g[1,3],della-j17g1,della-k11g1'
++ head -n 1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=2 --master_addr=della-j12g2 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-20b-bf16_lr3.0e-5_cosine_dxy_full_finetune --logging_steps 10 --save_steps 100 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3.0e-5 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --val_size 0.01 --per_device_eval_batch_size 1 --eval_strategy steps --eval_steps 500 --flash_attn fa2 --enable_liger_kernel true
W1003 11:35:04.287000 1177146 site-packages/torch/distributed/run.py:774] 
W1003 11:35:04.287000 1177146 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:04.287000 1177146 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:04.287000 1177146 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:04.294000 3710044 site-packages/torch/distributed/run.py:774] 
W1003 11:35:04.294000 3710044 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:04.294000 3710044 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:04.294000 3710044 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:04.328000 1593089 site-packages/torch/distributed/run.py:774] 
W1003 11:35:04.328000 1593089 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:04.328000 1593089 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:04.328000 1593089 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.531000 2395334 site-packages/torch/distributed/run.py:774] 
W1003 11:35:07.531000 2395334 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.531000 2395334 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:07.531000 2395334 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.619000 3121958 site-packages/torch/distributed/run.py:774] 
W1003 11:35:07.619000 3121958 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.619000 3121958 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:07.619000 3121958 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.631000 3227167 site-packages/torch/distributed/run.py:774] 
W1003 11:35:07.631000 3227167 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.631000 3227167 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:07.631000 3227167 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.634000 2326342 site-packages/torch/distributed/run.py:774] 
W1003 11:35:07.634000 2326342 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.634000 2326342 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:07.634000 2326342 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.647000 2877021 site-packages/torch/distributed/run.py:774] 
W1003 11:35:07.647000 2877021 site-packages/torch/distributed/run.py:774] *****************************************
W1003 11:35:07.647000 2877021 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1003 11:35:07.647000 2877021 site-packages/torch/distributed/run.py:774] *****************************************
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,252 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,252 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,252 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,252 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,252 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,252 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,253 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,253 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,253 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,253 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,253 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,253 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,254 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,255 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,255 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,255 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,255 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,255 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,255 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,256 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,257 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,257 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,257 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,257 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,257 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,260 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,260 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,260 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,260 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,260 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,260 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,909 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,910 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,913 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,914 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,915 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,915 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,916 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,916 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,916 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,916 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,916 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,916 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,916 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,916 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,916 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,916 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,917 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,918 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,919 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,919 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer.json
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file added_tokens.json
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,919 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,922 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,922 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,922 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,922 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,923 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,923 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,923 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,923 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,923 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,923 >> loading file chat_template.jinja
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,923 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,924 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file chat_template.jinja
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,925 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,925 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,926 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,926 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,926 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,926 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,926 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:49,929 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-03 11:35:49,929 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-20b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-03 11:35:49,931 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 24,
  "num_key_value_heads": 8,
  "num_local_experts": 32,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,932 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,932 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,932 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,932 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,932 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-03 11:35:49,932 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,606 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,611 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,620 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,620 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,626 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,627 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,629 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-03 11:35:50,635 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Setting num_proc from 64 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 641 examples [00:00, 5369.30 examples/s]Generating train split: 1270 examples [00:00, 5749.54 examples/s]Generating train split: 1925 examples [00:00, 5770.76 examples/s]Generating train split: 2559 examples [00:00, 5204.36 examples/s]Generating train split: 3204 examples [00:00, 5307.43 examples/s]Generating train split: 3855 examples [00:00, 4937.69 examples/s]Generating train split: 4495 examples [00:00, 4710.08 examples/s]Generating train split: 5107 examples [00:01, 4540.46 examples/s]Generating train split: 5741 examples [00:01, 4849.60 examples/s]Generating train split: 7023 examples [00:01, 6085.73 examples/s]Generating train split: 8303 examples [00:01, 7075.17 examples/s]Generating train split: 9564 examples [00:01, 6626.12 examples/s]Generating train split: 10859 examples [00:01, 5959.46 examples/s]Generating train split: 11480 examples [00:02, 5748.74 examples/s]Generating train split: 12117 examples [0Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 641 examples [00:00, 5709.87 examples/s]Generating train split: 1270 examples [00:00, 5922.60 examples/s]Generating train split: 2559 examples [00:00, 5649.30 examples/s]Generating train split: 3204 examples [00:00, 5400.10 examples/s]Generating train split: 3855 examples [00:00, 5043.92 examples/s]Generating train split: 4495 examples [00:00, 4795.29 examples/s]Generating train split: 5107 examples [00:01, 4248.09 examples/s]Generating train split: 5741 examples [00:01, 4672.79 examples/s]Generating train split: 7023 examples [00:01, 5925.45 examples/s]Generating train split: 8303 examples [00:01, 6951.91 examples/s]Generating train split: 9564 examples [00:01, 6444.34 examples/s]Generating train split: 10859 examples [00:01, 5866.74 examples/s]Generating train split: 11480 examples [00:02, 5677.01 examples/s]Generating train split: 12117 examples [00:02, 5697.17 examples/s]Generating train split: 13402 examples [Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 641 examples [00:00, 5008.39 examples/s]Generating train split: 1270 examples [00:00, 5059.02 examples/s]Generating train split: 1925 examples [00:00, 5295.84 examples/s]Generating train split: 2559 examples [00:00, 5049.56 examples/s]Generating train split: 3204 examples [00:00, 4889.60 examples/s]Generating train split: 3855 examples [00:00, 4685.73 examples/s]Generating train split: 4495 examples [00:00, 4500.25 examples/s]Generating train split: 5107 examples [00:01, 4494.28 examples/s]Generating train split: 6380 examples [00:01, 5572.97 examples/s]Generating train split: 7658 examples [00:01, 6583.01 examples/s]Generating train split: 8933 examples [00:01, 7259.78 examples/s]Generating train split: 10223 examples [00:01, 6081.82 examples/s]Generating train split: 11480 examples [00:02, 5671.03 examples/s]Generating train split: 12117 examples [00:02, 5726.66 examples/s]Generating train split: 13402 examples [Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1270 examples [00:00, 7662.81 examples/s]Generating train split: 2559 examples [00:00, 7313.68 examples/s]Generating train split: 3855 examples [00:00, 5709.35 examples/s]Generating train split: 4495 examples [00:00, 5286.10 examples/s]Generating train split: 5107 examples [00:00, 4890.93 examples/s]Generating train split: 5741 examples [00:01, 5117.85 examples/s]Generating train split: 7658 examples [00:01, 7173.25 examples/s]Generating train split: 10223 examples [00:01, 9578.98 examples/s]Generating train split: 12117 examples [00:01, 10489.68 examples/s]Generating train split: 14670 examples [00:01, 11989.82 examples/s]Generating train split: 17252 examples [00:01, 13352.13 examples/s]Generating train split: 19827 examples [00:02, 14851.14 examples/s]Generating train split: 22357 examples [00:02, 16032.87 examples/s]Generating train split: 24916 examples [00:02, 17063.20 examples/s]Generating train split: 27489Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1270 examples [00:00, 6560.66 examples/s]Generating train split: 2559 examples [00:00, 5925.87 examples/s]Generating train split: 3204 examples [00:00, 5562.87 examples/s]Generating train split: 3855 examples [00:00, 5175.50 examples/s]Generating train split: 4495 examples [00:00, 4884.61 examples/s]Generating train split: 5107 examples [00:01, 4596.44 examples/s]Generating train split: 5741 examples [00:01, 4684.08 examples/s]Generating train split: 7023 examples [00:01, 5892.07 examples/s]Generating train split: 8303 examples [00:01, 6883.69 examples/s]Generating train split: 9564 examples [00:01, 6641.91 examples/s]Generating train split: 10859 examples [00:01, 5979.62 examples/s]Generating train split: 11480 examples [00:02, 5739.11 examples/s]Generating train split: 12117 examples [00:02, 5696.64 examples/s]Generating train split: 13402 examples [00:02, 6523.28 examples/s]Generating train split: 14670 examplesGenerating train split: 0 examples [00:00, ? examples/s]Generating train split: 1270 examples [00:00, 7504.13 examples/s]Generating train split: 2559 examples [00:00, 6854.02 examples/s]Generating train split: 3855 examples [00:00, 5704.44 examples/s]Generating train split: 4495 examples [00:00, 5289.49 examples/s]Generating train split: 5107 examples [00:00, 4879.18 examples/s]Generating train split: 5741 examples [00:01, 4817.59 examples/s]Generating train split: 6380 examples [00:01, 5160.38 examples/s]Generating train split: 7658 examples [00:01, 6298.40 examples/s]Generating train split: 8933 examples [00:01, 7194.16 examples/s]Generating train split: 10223 examples [00:01, 6244.90 examples/s]Generating train split: 11480 examples [00:01, 5836.61 examples/s]Generating train split: 12117 examples [00:02, 5700.48 examples/s]Generating train split: 12764 examples [00:02, 5801.42 examples/s]Generating train split: 14027 examples [00:02, 6940.11 examples/s]Generating train split: 16600 exampleGenerating train split: 0 examples [00:00, ? examples/s]Generating train split: 1270 examples [00:00, 7264.55 examples/s]Generating train split: 2559 examples [00:00, 6304.50 examples/s]Generating train split: 3204 examples [00:00, 5768.77 examples/s]Generating train split: 3855 examples [00:00, 5338.81 examples/s]Generating train split: 4495 examples [00:00, 4967.88 examples/s]Generating train split: 5107 examples [00:00, 4654.85 examples/s]Generating train split: 5741 examples [00:01, 4684.13 examples/s]Generating train split: 7023 examples [00:01, 5750.72 examples/s]Generating train split: 8303 examples [00:01, 6747.04 examples/s]Generating train split: 9564 examples [00:01, 6891.76 examples/s]Generating train split: 10859 examples [00:01, 6035.50 examples/s]Generating train split: 12117 examples [00:02, 5693.29 examples/s]Generating train split: 13402 examples [00:02, 6243.00 examples/s]Generating train split: 14670 examples [00:02, 6948.10 examples/s]Generating train split: 15937 examplesGenerating train split: 0 examples [00:00, ? examples/s]Generating train split: 1270 examples [00:00, 6832.75 examples/s]Generating train split: 2559 examples [00:00, 6083.24 examples/s]Generating train split: 3204 examples [00:00, 5652.62 examples/s]Generating train split: 3855 examples [00:00, 5258.44 examples/s]Generating train split: 4495 examples [00:00, 4899.98 examples/s]Generating train split: 5107 examples [00:00, 4630.21 examples/s]Generating train split: 5741 examples [00:01, 4656.36 examples/s]Generating train split: 7023 examples [00:01, 5834.85 examples/s]Generating train split: 8303 examples [00:01, 6829.75 examples/s]Generating train split: 9564 examples [00:01, 6770.08 examples/s]Generating train split: 10859 examples [00:01, 6016.38 examples/s]Generating train split: 12117 examples [00:02, 5705.68 examples/s]Generating train split: 13402 examples [00:02, 6307.86 examples/s]Generating train split: 14670 examples [00:02, 7039.84 examples/s]Generating train split: 15937 examples examples [00:02, 17787.45 examples/s]Generating train split: 30071 examples [00:02, 18337.78 examples/s]Generating train split: 32637 examples [00:02, 18549.93 examples/s]Generating train split: 34580 examples [00:02, 17206.48 examples/s]Generating train split: 37130 examples [00:02, 17953.13 examples/s]Generating train split: 39717 examples [00:03, 18542.36 examples/s]Generating train split: 42260 examples [00:03, 18908.62 examples/s]Generating train split: 44839 examples [00:03, 19189.51 examples/s]Generating train split: 47393 examples [00:03, 19287.59 examples/s]Generating train split: 49970 examples [00:03, 19113.89 examples/s]Generating train split: 52512 examples [00:03, 19187.86 examples/s]Generating train split: 55057 examples [00:03, 19216.55 examples/s]Generating train split: 57598 examples [00:03, 19389.10 examples/s]Generating train split: 60125 examples [00:04, 19280.75 examples/s]Generating train split: 62639 examples [00:04, 19219.45 examples/s]Generating train split: 65172 exa0:02, 5708.92 examples/s]Generating train split: 13402 examples [00:02, 6621.45 examples/s]Generating train split: 14670 examples [00:02, 7457.43 examples/s]Generating train split: 15937 examples [00:02, 8131.06 examples/s]Generating train split: 17252 examples [00:02, 7691.14 examples/s]Generating train split: 18542 examples [00:02, 7167.33 examples/s]Generating train split: 19827 examples [00:03, 7224.04 examples/s]Generating train split: 21100 examples [00:03, 7964.27 examples/s]Generating train split: 22357 examples [00:03, 8578.12 examples/s]Generating train split: 23651 examples [00:03, 7732.13 examples/s]Generating train split: 24916 examples [00:03, 7242.67 examples/s]Generating train split: 26199 examples [00:03, 7542.44 examples/s]Generating train split: 27489 examples [00:04, 8443.15 examples/s]Generating train split: 28775 examples [00:04, 9069.82 examples/s]Generating train split: 30071 examples [00:04, 8499.94 examples/s]Generating train split: 31341 examples [00:04, 7987.68 examps [00:02, 9758.10 examples/s]Generating train split: 19205 examples [00:02, 12261.09 examples/s]Generating train split: 21724 examples [00:02, 12949.33 examples/s]Generating train split: 24289 examples [00:02, 14403.78 examples/s]Generating train split: 26851 examples [00:03, 15702.58 examples/s]Generating train split: 29414 examples [00:03, 16037.26 examples/s]Generating train split: 32004 examples [00:03, 16855.62 examples/s]Generating train split: 34580 examples [00:03, 17112.12 examples/s]Generating train split: 37130 examples [00:03, 17382.49 examples/s]Generating train split: 39717 examples [00:03, 17606.77 examples/s]Generating train split: 42260 examples [00:03, 17743.59 examples/s]Generating train split: 44839 examples [00:04, 17969.13 examples/s]Generating train split: 47393 examples [00:04, 18126.52 examples/s]Generating train split: 49970 examples [00:04, 18228.95 examples/s]Generating train split: 52512 examples [00:04, 18229.80 examples/s]Generating train split: 55057 examples [0000:02, 6688.00 examples/s]Generating train split: 14670 examples [00:02, 7476.61 examples/s]Generating train split: 15937 examples [00:02, 8524.02 examples/s]Generating train split: 17252 examples [00:02, 8116.40 examples/s]Generating train split: 18542 examples [00:02, 7384.25 examples/s]Generating train split: 19827 examples [00:03, 7325.36 examples/s]Generating train split: 21100 examples [00:03, 8193.06 examples/s]Generating train split: 22357 examples [00:03, 8573.23 examples/s]Generating train split: 23651 examples [00:03, 8149.49 examples/s]Generating train split: 24916 examples [00:03, 7191.54 examples/s]Generating train split: 26199 examples [00:03, 7409.09 examples/s]Generating train split: 27489 examples [00:04, 8326.02 examples/s]Generating train split: 28775 examples [00:04, 8965.71 examples/s]Generating train split: 30071 examples [00:04, 8924.00 examples/s]Generating train split: 31341 examples [00:04, 8309.76 examples/s]Generating train split: 32637 examples [00:04, 8240.37 exam00:02, 6652.42 examples/s]Generating train split: 14670 examples [00:02, 7446.18 examples/s]Generating train split: 15937 examples [00:02, 8004.66 examples/s]Generating train split: 17252 examples [00:02, 7430.55 examples/s]Generating train split: 18542 examples [00:02, 6921.09 examples/s]Generating train split: 19827 examples [00:03, 7394.29 examples/s]Generating train split: 21100 examples [00:03, 8100.90 examples/s]Generating train split: 22357 examples [00:03, 8556.44 examples/s]Generating train split: 23651 examples [00:03, 7826.17 examples/s]Generating train split: 24916 examples [00:03, 7172.48 examples/s]Generating train split: 26199 examples [00:03, 7619.67 examples/s]Generating train split: 27489 examples [00:04, 8498.60 examples/s]Generating train split: 28775 examples [00:04, 9101.70 examples/s]Generating train split: 30071 examples [00:04, 8606.21 examples/s]Generating train split: 31341 examples [00:04, 8050.80 examples/s]Generating train split: 32637 examples [00:04, 8273.17 exam [00:02, 7366.21 examples/s]Generating train split: 15937 examples [00:02, 8195.29 examples/s]Generating train split: 17252 examples [00:02, 7268.31 examples/s]Generating train split: 18542 examples [00:02, 6846.84 examples/s]Generating train split: 19827 examples [00:03, 7095.46 examples/s]Generating train split: 21100 examples [00:03, 7860.56 examples/s]Generating train split: 22357 examples [00:03, 8480.67 examples/s]Generating train split: 23651 examples [00:03, 8156.96 examples/s]Generating train split: 24916 examples [00:03, 7711.14 examples/s]Generating train split: 26199 examples [00:03, 7702.88 examples/s]Generating train split: 27489 examples [00:04, 8568.47 examples/s]Generating train split: 28775 examples [00:04, 9184.44 examples/s]Generating train split: 30071 examples [00:04, 9161.35 examples/s]Generating train split: 31341 examples [00:04, 7883.48 examples/s]Generating train split: 32637 examples [00:04, 8000.08 examples/s]Generating train split: 34580 examples [00:04, 9298.37 ex [00:02, 7966.69 examples/s]Generating train split: 17252 examples [00:02, 7581.02 examples/s]Generating train split: 18542 examples [00:02, 7192.61 examples/s]Generating train split: 19827 examples [00:03, 7096.87 examples/s]Generating train split: 21100 examples [00:03, 7667.81 examples/s]Generating train split: 22357 examples [00:03, 8581.52 examples/s]Generating train split: 23651 examples [00:03, 8262.65 examples/s]Generating train split: 24916 examples [00:03, 7498.65 examples/s]Generating train split: 26199 examples [00:03, 7581.57 examples/s]Generating train split: 27489 examples [00:03, 8423.01 examples/s]Generating train split: 28775 examples [00:04, 9105.13 examples/s]Generating train split: 30071 examples [00:04, 9283.21 examples/s]Generating train split: 32004 examples [00:04, 10453.26 examples/s]Generating train split: 34580 examples [00:04, 12461.06 examples/s]Generating train split: 37130 examples [00:04, 14420.78 examples/s]Generating train split: 39717 examples [00:04, 15143.1 [00:02, 7912.05 examples/s]Generating train split: 17252 examples [00:02, 7829.90 examples/s]Generating train split: 18542 examples [00:02, 7211.91 examples/s]Generating train split: 19827 examples [00:03, 7368.40 examples/s]Generating train split: 21724 examples [00:03, 9108.05 examples/s]Generating train split: 23651 examples [00:03, 10587.32 examples/s]Generating train split: 26199 examples [00:03, 12498.86 examples/s]Generating train split: 28775 examples [00:03, 14040.65 examples/s]Generating train split: 31341 examples [00:03, 14961.88 examples/s]Generating train split: 33945 examples [00:03, 15117.30 examples/s]Generating train split: 35858 examples [00:04, 15169.39 examples/s]Generating train split: 38416 examples [00:04, 15657.27 examples/s]Generating train split: 40986 examples [00:04, 16274.63 examples/s]Generating train split: 43527 examples [00:04, 16637.76 examples/s]Generating train split: 46107 examples [00:04, 16574.96 examples/s]Generating train split: 48699 examples [00:04, mples [00:04, 19382.78 examples/s]Generating train split: 67748 examples [00:04, 19362.81 examples/s]Generating train split: 70250 examples [00:04, 18912.58 examples/s]Generating train split: 72809 examples [00:04, 18951.75 examples/s]Generating train split: 75341 examples [00:04, 18896.42 examples/s]Generating train split: 77924 examples [00:05, 19210.89 examples/s]Generating train split: 80491 examples [00:05, 19297.77 examples/s]Generating train split: 83064 examples [00:05, 19555.02 examples/s]Generating train split: 85650 examples [00:05, 19560.07 examples/s]Generating train split: 88221 examples [00:05, 19760.70 examples/s]Generating train split: 90803 examples [00:05, 19759.17 examples/s]Generating train split: 93352 examples [00:05, 19539.94 examples/s]Generating train split: 95918 examples [00:05, 19466.93 examples/s]Generating train split: 98481 examples [00:06, 19691.44 examples/s]Generating train split: 101043 examples [00:06, 19835.85 examples/s]Generating train split: 103626 examp:04, 18169.39 examples/s]Generating train split: 57598 examples [00:04, 18345.01 examples/s]Generating train split: 59491 examples [00:04, 17198.77 examples/s]Generating train split: 62000 examples [00:05, 17395.64 examples/s]Generating train split: 64526 examples [00:05, 17879.31 examples/s]Generating train split: 67106 examples [00:05, 18430.11 examples/s]Generating train split: 69606 examples [00:05, 18079.36 examples/s]Generating train split: 72169 examples [00:05, 18587.49 examples/s]Generating train split: 74699 examples [00:05, 18940.13 examples/s]Generating train split: 77284 examples [00:05, 19204.71 examples/s]Generating train split: 79858 examples [00:05, 19249.84 examples/s]Generating train split: 82426 examples [00:06, 18943.24 examples/s]Generating train split: 84997 examples [00:06, 18834.65 examples/s]Generating train split: 87569 examples [00:06, 18651.48 examples/s]Generating train split: 90167 examples [00:06, 19028.57 examples/s]Generating train split: 92712 examples [00:06,9 examples/s]Generating train split: 42260 examples [00:04, 16307.33 examples/s]Generating train split: 44839 examples [00:05, 17269.00 examples/s]Generating train split: 47393 examples [00:05, 17981.92 examples/s]Generating train split: 49970 examples [00:05, 18351.07 examples/s]Generating train split: 52512 examples [00:05, 18799.90 examples/s]Generating train split: 55057 examples [00:05, 18792.70 examples/s]Generating train split: 57598 examples [00:05, 19116.93 examples/s]Generating train split: 60125 examples [00:05, 19153.06 examples/s]Generating train split: 62639 examples [00:06, 19280.06 examples/s]Generating train split: 65172 examples [00:06, 19478.53 examples/s]Generating train split: 67748 examples [00:06, 19474.44 examples/s]Generating train split: 70888 examples [00:06, 18657.45 examples/s]Generating train split: 73449 examples [00:06, 19115.22 examples/s]Generating train split: 75998 examples [00:06, 19090.75 examples/s]Generating train split: 78569 examples [00:06, 19140.92 exles/s]Generating train split: 32637 examples [00:04, 8163.95 examples/s]Generating train split: 34580 examples [00:04, 9145.49 examples/s]Generating train split: 36508 examples [00:04, 10304.62 examples/s]Generating train split: 37764 examples [00:05, 10655.99 examples/s]Generating train split: 39717 examples [00:05, 11413.01 examples/s]Generating train split: 42260 examples [00:05, 12492.05 examples/s]Generating train split: 44195 examples [00:05, 12711.45 examples/s]Generating train split: 45479 examples [00:05, 12484.06 examples/s]Generating train split: 48047 examples [00:05, 13511.00 examples/s]Generating train split: 49970 examples [00:05, 13408.48 examples/s]Generating train split: 51874 examples [00:06, 12742.10 examples/s]Generating train split: 54407 examples [00:06, 13312.79 examples/s]Generating train split: 56968 examples [00:06, 13325.16 examples/s]Generating train split: 58886 examples [00:06, 12403.23 examples/s]Generating train split: 61369 examples [00:06, 12736.88 examples/s]16098.56 examples/s]Generating train split: 51248 examples [00:04, 16838.36 examples/s]Generating train split: 53798 examples [00:05, 17495.13 examples/s]Generating train split: 56324 examples [00:05, 17988.67 examples/s]Generating train split: 58886 examples [00:05, 18139.42 examples/s]Generating train split: 61369 examples [00:05, 18534.73 examples/s]Generating train split: 63905 examples [00:05, 18788.30 examples/s]Generating train split: 66455 examples [00:05, 19165.96 examples/s]Generating train split: 69606 examples [00:05, 18111.02 examples/s]Generating train split: 72169 examples [00:06, 18570.30 examples/s]Generating train split: 74699 examples [00:06, 18944.99 examples/s]Generating train split: 77284 examples [00:06, 18515.96 examples/s]Generating train split: 79858 examples [00:06, 18839.15 examples/s]Generating train split: 82426 examples [00:06, 18592.18 examples/s]Generating train split: 84997 examples [00:06, 18949.30 examples/s]Generating train split: 87569 examples [00:06, 1885ples/s]Generating train split: 34580 examples [00:04, 9201.81 examples/s]Generating train split: 36508 examples [00:04, 10246.78 examples/s]Generating train split: 37764 examples [00:05, 10601.34 examples/s]Generating train split: 39717 examples [00:05, 11649.38 examples/s]Generating train split: 42260 examples [00:05, 12586.08 examples/s]Generating train split: 44195 examples [00:05, 12702.88 examples/s]Generating train split: 46107 examples [00:05, 12738.13 examples/s]Generating train split: 48699 examples [00:05, 13673.72 examples/s]Generating train split: 50620 examples [00:06, 12916.33 examples/s]Generating train split: 53159 examples [00:06, 13054.90 examples/s]Generating train split: 55677 examples [00:06, 13424.56 examples/s]Generating train split: 57598 examples [00:06, 12808.50 examples/s]Generating train split: 58886 examples [00:06, 12400.41 examples/s]Generating train split: 61369 examples [00:06, 12879.63 examples/s]Generating train split: 63277 examples [00:07, 12701.59 examples/ples/s]Generating train split: 34580 examples [00:04, 9349.12 examples/s]Generating train split: 37130 examples [00:04, 11535.54 examples/s]Generating train split: 39717 examples [00:05, 12634.64 examples/s]Generating train split: 41619 examples [00:05, 12808.45 examples/s]Generating train split: 44195 examples [00:05, 13395.41 examples/s]Generating train split: 46752 examples [00:05, 13632.26 examples/s]Generating train split: 49331 examples [00:05, 14103.93 examples/s]Generating train split: 51874 examples [00:05, 13891.82 examples/s]Generating train split: 53798 examples [00:06, 13843.55 examples/s]Generating train split: 56324 examples [00:06, 14245.71 examples/s]Generating train split: 58886 examples [00:06, 14251.48 examples/s]Generating train split: 61369 examples [00:06, 14604.04 examples/s]Generating train split: 63277 examples [00:06, 14233.48 examples/s]Generating train split: 65816 examples [00:06, 14126.86 examples/s]Generating train split: 67748 examples [00:07, 14551.11 examples/amples/s]Generating train split: 36508 examples [00:04, 10105.69 examples/s]Generating train split: 37764 examples [00:05, 10540.08 examples/s]Generating train split: 39070 examples [00:05, 10832.44 examples/s]Generating train split: 41619 examples [00:05, 12344.91 examples/s]Generating train split: 43527 examples [00:05, 12659.08 examples/s]Generating train split: 44839 examples [00:05, 12726.51 examples/s]Generating train split: 46752 examples [00:05, 12968.96 examples/s]Generating train split: 49331 examples [00:05, 13627.50 examples/s]Generating train split: 51248 examples [00:06, 12984.78 examples/s]Generating train split: 53798 examples [00:06, 13082.94 examples/s]Generating train split: 56324 examples [00:06, 13470.89 examples/s]Generating train split: 58245 examples [00:06, 12878.15 examples/s]Generating train split: 60764 examples [00:06, 12758.15 examples/s]Generating train split: 63277 examples [00:07, 12680.35 examples/s]Generating train split: 65172 examples [00:07, 12181.14 examplles [00:06, 19312.35 examples/s]Generating train split: 106118 examples [00:06, 19371.56 examples/s]Generating train split: 108662 examples [00:06, 19526.31 examples/s]Generating train split: 111263 examples [00:06, 19645.39 examples/s]Generating train split: 113851 examples [00:06, 19766.17 examples/s]Generating train split: 116394 examples [00:07, 19612.56 examples/s]Generating train split: 118952 examples [00:07, 19798.57 examples/s]Generating train split: 121559 examples [00:07, 19912.17 examples/s]Generating train split: 124087 examples [00:07, 19885.74 examples/s]Generating train split: 126599 examples [00:07, 19753.15 examples/s]Generating train split: 129111 examples [00:07, 19554.59 examples/s]Generating train split: 131675 examples [00:07, 19643.39 examples/s]Generating train split: 134189 examples [00:07, 19705.64 examples/s]Generating train split: 136760 examples [00:08, 19484.77 examples/s]Generating train split: 139345 examples [00:08, 19223.45 examples/s]Generating train split: 1 19319.80 examples/s]Generating train split: 95257 examples [00:06, 19036.46 examples/s]Generating train split: 97847 examples [00:06, 19214.74 examples/s]Generating train split: 100399 examples [00:07, 19266.22 examples/s]Generating train split: 102343 examples [00:07, 18122.84 examples/s]Generating train split: 104860 examples [00:07, 18370.91 examples/s]Generating train split: 107382 examples [00:07, 18656.09 examples/s]Generating train split: 109983 examples [00:07, 19281.32 examples/s]Generating train split: 112563 examples [00:07, 19239.47 examples/s]Generating train split: 115128 examples [00:07, 19324.28 examples/s]Generating train split: 117655 examples [00:07, 19497.22 examples/s]Generating train split: 120230 examples [00:08, 18728.84 examples/s]Generating train split: 122840 examples [00:08, 19194.22 examples/s]Generating train split: 125339 examples [00:08, 19134.38 examples/s]Generating train split: 127848 examples [00:08, 19353.78 examples/s]Generating train split: 130391 exampleamples/s]Generating train split: 81143 examples [00:06, 19265.87 examples/s]Generating train split: 83711 examples [00:07, 18541.67 examples/s]Generating train split: 86294 examples [00:07, 18730.98 examples/s]Generating train split: 88859 examples [00:07, 19117.13 examples/s]Generating train split: 91445 examples [00:07, 18721.77 examples/s]Generating train split: 93988 examples [00:07, 18848.25 examples/s]Generating train split: 96579 examples [00:07, 19181.92 examples/s]Generating train split: 99109 examples [00:07, 19049.21 examples/s]Generating train split: 101685 examples [00:08, 19377.71 examples/s]Generating train split: 104249 examples [00:08, 18772.10 examples/s]Generating train split: 106753 examples [00:08, 18926.34 examples/s]Generating train split: 109322 examples [00:08, 19350.27 examples/s]Generating train split: 111909 examples [00:08, 19412.09 examples/s]Generating train split: 114500 examples [00:08, 19617.71 examples/s]Generating train split: 117029 examples [00:08, 18892.616.83 examples/s]Generating train split: 90167 examples [00:07, 19123.92 examples/s]Generating train split: 92712 examples [00:07, 18818.20 examples/s]Generating train split: 95257 examples [00:07, 18969.06 examples/s]Generating train split: 97847 examples [00:07, 18616.52 examples/s]Generating train split: 100399 examples [00:07, 18948.65 examples/s]Generating train split: 102343 examples [00:07, 18024.93 examples/s]Generating train split: 104860 examples [00:07, 18340.22 examples/s]Generating train split: 107382 examples [00:07, 18581.92 examples/s]Generating train split: 109983 examples [00:08, 19111.32 examples/s]Generating train split: 112563 examples [00:08, 19239.49 examples/s]Generating train split: 115128 examples [00:08, 19363.42 examples/s]Generating train split: 117655 examples [00:08, 19066.44 examples/s]Generating train split: 120230 examples [00:08, 19091.82 examples/s]Generating train split: 122840 examples [00:08, 19445.97 examples/s]Generating train split: 125339 examples [00:0s]Generating train split: 70250 examples [00:07, 15335.57 examples/s]Generating train split: 72809 examples [00:07, 16516.13 examples/s]Generating train split: 75341 examples [00:07, 16560.87 examples/s]Generating train split: 77924 examples [00:07, 17451.04 examples/s]Generating train split: 80491 examples [00:07, 17924.98 examples/s]Generating train split: 83064 examples [00:07, 18299.85 examples/s]Generating train split: 85650 examples [00:08, 18634.82 examples/s]Generating train split: 88221 examples [00:08, 19046.33 examples/s]Generating train split: 90803 examples [00:08, 19021.70 examples/s]Generating train split: 93352 examples [00:08, 19138.15 examples/s]Generating train split: 95918 examples [00:08, 19376.50 examples/s]Generating train split: 98481 examples [00:08, 19410.18 examples/s]Generating train split: 101043 examples [00:08, 19424.80 examples/s]Generating train split: 103626 examples [00:08, 18597.71 examples/s]Generating train split: 106118 examples [00:09, 18653.06 examples/sGenerating train split: 63277 examples [00:07, 12759.50 examples/s]Generating train split: 65172 examples [00:07, 12195.69 examples/s]Generating train split: 67748 examples [00:07, 13373.78 examples/s]Generating train split: 70250 examples [00:07, 13947.03 examples/s]Generating train split: 72169 examples [00:07, 13370.69 examples/s]Generating train split: 74699 examples [00:07, 14003.20 examples/s]Generating train split: 77284 examples [00:08, 13785.18 examples/s]Generating train split: 79214 examples [00:08, 13134.54 examples/s]Generating train split: 81143 examples [00:08, 13310.59 examples/s]Generating train split: 83711 examples [00:08, 13481.00 examples/s]Generating train split: 85650 examples [00:08, 12548.48 examples/s]Generating train split: 87569 examples [00:08, 12777.27 examples/s]Generating train split: 90167 examples [00:09, 13378.15 examples/s]Generating train split: 92712 examples [00:09, 13364.52 examples/s]Generating train split: 94622 examples [00:09, 13489.70 examples/s]Gens]Generating train split: 65172 examples [00:07, 12102.07 examples/s]Generating train split: 67748 examples [00:07, 13327.12 examples/s]Generating train split: 69606 examples [00:07, 13390.89 examples/s]Generating train split: 72169 examples [00:07, 13293.35 examples/s]Generating train split: 74699 examples [00:07, 14011.54 examples/s]Generating train split: 76634 examples [00:08, 13842.54 examples/s]Generating train split: 78569 examples [00:08, 12949.51 examples/s]Generating train split: 80491 examples [00:08, 13025.49 examples/s]Generating train split: 83064 examples [00:08, 13482.87 examples/s]Generating train split: 84997 examples [00:08, 12526.47 examples/s]Generating train split: 86294 examples [00:08, 12450.88 examples/s]Generating train split: 88859 examples [00:08, 13152.47 examples/s]Generating train split: 91445 examples [00:09, 13768.96 examples/s]Generating train split: 93988 examples [00:09, 13474.02 examples/s]Generating train split: 96579 examples [00:09, 14032.00 examples/s]Ges/s]Generating train split: 67106 examples [00:07, 12772.08 examples/s]Generating train split: 69606 examples [00:07, 12937.96 examples/s]Generating train split: 72169 examples [00:07, 12977.44 examples/s]Generating train split: 74699 examples [00:07, 13751.46 examples/s]Generating train split: 77284 examples [00:08, 13396.78 examples/s]Generating train split: 79214 examples [00:08, 12879.04 examples/s]Generating train split: 81790 examples [00:08, 13289.99 examples/s]Generating train split: 83711 examples [00:08, 13419.49 examples/s]Generating train split: 85650 examples [00:08, 12497.42 examples/s]Generating train split: 87569 examples [00:08, 12847.77 examples/s]Generating train split: 90167 examples [00:09, 13473.13 examples/s]Generating train split: 92712 examples [00:09, 13270.78 examples/s]Generating train split: 95257 examples [00:09, 13622.41 examples/s]Generating train split: 97847 examples [00:09, 13746.00 examples/s]Generating train split: 99748 examples [00:09, 13349.20 examples/s41901 examples [00:08, 19466.84 examples/s]Generating train split: 144434 examples [00:08, 19522.12 examples/s]Generating train split: 147039 examples [00:08, 19808.73 examples/s]Generating train split: 149217 examples [00:08, 16512.11 examples/s]Generating train split: 151285 examples [00:08, 14274.82 examples/s]Generating train split: 153054 examples [00:09, 12470.42 examples/s]Generating train split: 154420 examples [00:09, 10709.41 examples/s]Generating train split: 155961 examples [00:09, 9795.47 examples/s] Generating train split: 157347 examples [00:09, 8900.75 examples/s]Generating train split: 158384 examples [00:09, 8723.75 examples/s]Generating train split: 159623 examples [00:10, 8775.81 examples/s]Generating train split: 160586 examples [00:10, 8433.61 examples/s]Generating train split: 161536 examples [00:10, 8013.84 examples/s]Generating train split: 162488 examples [00:10, 7830.18 examples/s]Generating train split: 163516 examples [00:10, 7874.12 examples/s]Generating train spli]Generating train split: 108662 examples [00:09, 18791.60 examples/s]Generating train split: 111263 examples [00:09, 19097.90 examples/s]Generating train split: 113851 examples [00:09, 19405.95 examples/s]Generating train split: 116394 examples [00:09, 19108.86 examples/s]Generating train split: 118952 examples [00:09, 19341.69 examples/s]Generating train split: 121559 examples [00:09, 19575.84 examples/s]Generating train split: 124087 examples [00:10, 18760.18 examples/s]Generating train split: 126599 examples [00:10, 18950.39 examples/s]Generating train split: 129111 examples [00:10, 18980.54 examples/s]Generating train split: 131675 examples [00:10, 19271.00 examples/s]Generating train split: 134189 examples [00:10, 19261.82 examples/s]Generating train split: 136128 examples [00:10, 18389.81 examples/s]Generating train split: 138693 examples [00:10, 18767.54 examples/s]Generating train split: 141248 examples [00:10, 19122.41 examples/s]Generating train split: 143792 examples [00:11, 19278.70 examples/s]Generating train split: 119592 examples [00:09, 18297.29 examples/s]Generating train split: 122200 examples [00:09, 18770.63 examples/s]Generating train split: 124703 examples [00:09, 18849.03 examples/s]Generating train split: 127231 examples [00:09, 19119.44 examples/s]Generating train split: 129763 examples [00:09, 19168.65 examples/s]Generating train split: 132305 examples [00:09, 19409.65 examples/s]Generating train split: 134835 examples [00:09, 19454.72 examples/s]Generating train split: 137417 examples [00:09, 18961.24 examples/s]Generating train split: 139989 examples [00:10, 18971.18 examples/s]Generating train split: 142532 examples [00:10, 19189.95 examples/s]Generating train split: 145072 examples [00:10, 19188.99 examples/s]Generating train split: 147446 examples [00:10, 18880.54 examples/s]Generating train split: 149580 examples [00:10, 15630.13 examples/s]Generating train split: 151534 examples [00:10, 13268.54 examples/s]Generating train split: 153273 examples [00:1s [00:08, 19536.49 examples/s]Generating train split: 132926 examples [00:08, 19676.42 examples/s]Generating train split: 135481 examples [00:08, 19633.41 examples/s]Generating train split: 138693 examples [00:09, 18597.46 examples/s]Generating train split: 141248 examples [00:09, 18997.80 examples/s]Generating train split: 143792 examples [00:09, 19081.42 examples/s]Generating train split: 146392 examples [00:09, 19419.59 examples/s]Generating train split: 148863 examples [00:09, 16894.55 examples/s]Generating train split: 150947 examples [00:09, 14406.18 examples/s]Generating train split: 152790 examples [00:10, 12674.06 examples/s]Generating train split: 154186 examples [00:10, 10896.24 examples/s]Generating train split: 155721 examples [00:10, 9846.47 examples/s] Generating train split: 157107 examples [00:10, 9045.62 examples/s]Generating train split: 158384 examples [00:10, 8399.86 examples/s]Generating train split: 159623 examples [00:10, 8702.96 examples/s]Generating train split: 1605868, 19332.05 examples/s]Generating train split: 127848 examples [00:09, 18999.97 examples/s]Generating train split: 130391 examples [00:09, 19156.32 examples/s]Generating train split: 132926 examples [00:09, 19377.21 examples/s]Generating train split: 135481 examples [00:09, 19405.71 examples/s]Generating train split: 138058 examples [00:09, 18974.84 examples/s]Generating train split: 140625 examples [00:09, 19294.05 examples/s]Generating train split: 143168 examples [00:09, 19330.95 examples/s]Generating train split: 145735 examples [00:09, 19385.05 examples/s]Generating train split: 147814 examples [00:10, 18293.60 examples/s]Generating train split: 149929 examples [00:10, 15257.96 examples/s]Generating train split: 151876 examples [00:10, 13072.27 examples/s]Generating train split: 153500 examples [00:10, 11265.41 examples/s]Generating train split: 154938 examples [00:10, 9963.72 examples/s] Generating train split: 156433 examples [00:11, 9318.53 examples/s]Generating train split: 157859 examerating train split: 97218 examples [00:09, 13951.66 examples/s]Generating train split: 99109 examples [00:09, 13215.13 examples/s]Generating train split: 101043 examples [00:09, 13576.51 examples/s]Generating train split: 103626 examples [00:10, 13810.44 examples/s]Generating train split: 105499 examples [00:10, 13518.32 examples/s]Generating train split: 107382 examples [00:10, 13669.61 examples/s]Generating train split: 109983 examples [00:10, 14095.64 examples/s]Generating train split: 112563 examples [00:10, 13826.10 examples/s]Generating train split: 115128 examples [00:10, 14305.42 examples/s]Generating train split: 117655 examples [00:10, 14860.22 examples/s]Generating train split: 120230 examples [00:11, 15207.50 examples/s]Generating train split: 122840 examples [00:11, 15620.47 examples/s]Generating train split: 124703 examples [00:11, 14586.75 examples/s]Generating train split: 126599 examples [00:11, 14342.92 examples/s]Generating train split: 129111 examples [00:11, 14377.50 examplenerating train split: 98481 examples [00:09, 13178.26 examples/s]Generating train split: 100399 examples [00:09, 13470.44 examples/s]Generating train split: 102343 examples [00:09, 13707.48 examples/s]Generating train split: 104249 examples [00:10, 13837.46 examples/s]Generating train split: 106753 examples [00:10, 13553.86 examples/s]Generating train split: 109322 examples [00:10, 14098.68 examples/s]Generating train split: 111263 examples [00:10, 13939.75 examples/s]Generating train split: 113204 examples [00:10, 14029.54 examples/s]Generating train split: 115765 examples [00:10, 15127.62 examples/s]Generating train split: 118318 examples [00:11, 15155.44 examples/s]Generating train split: 120904 examples [00:11, 15800.90 examples/s]Generating train split: 122840 examples [00:11, 15659.28 examples/s]Generating train split: 124703 examples [00:11, 14409.70 examples/s]Generating train split: 127231 examples [00:11, 14275.01 examples/s]Generating train split: 129763 examples [00:11, 14146.29 exa]Generating train split: 102343 examples [00:09, 14100.76 examples/s]Generating train split: 104860 examples [00:10, 14237.47 examples/s]Generating train split: 107382 examples [00:10, 13887.96 examples/s]Generating train split: 109983 examples [00:10, 14275.23 examples/s]Generating train split: 112563 examples [00:10, 13966.29 examples/s]Generating train split: 115128 examples [00:10, 14515.95 examples/s]Generating train split: 117655 examples [00:10, 15121.68 examples/s]Generating train split: 120230 examples [00:11, 15295.60 examples/s]Generating train split: 122840 examples [00:11, 15641.80 examples/s]Generating train split: 124703 examples [00:11, 14921.22 examples/s]Generating train split: 126599 examples [00:11, 14299.34 examples/s]Generating train split: 129111 examples [00:11, 14466.04 examples/s]Generating train split: 131675 examples [00:11, 13765.40 examples/s]Generating train split: 134189 examples [00:12, 14036.82 examples/s]Generating train split: 136128 examples [00:12, 14487.51t: 164629 examples [00:10, 8101.78 examples/s]Generating train split: 165642 examples [00:10, 7938.04 examples/s]Generating train split: 166715 examples [00:10, 8073.57 examples/s]Generating train split: 167712 examples [00:11, 7995.40 examples/s]Generating train split: 168741 examples [00:11, 8024.87 examples/s]Generating train split: 169671 examples [00:11, 7716.55 examples/s]Generating train split: 170675 examples [00:11, 7717.37 examples/s]Generating train split: 171651 examples [00:11, 7515.09 examples/s]Generating train split: 172584 examples [00:11, 7321.86 examples/s]Generating train split: 173584 examples [00:11, 7419.14 examples/s]Generating train split: 174982 examples [00:11, 8487.95 examples/s]Generating train split: 176355 examples [00:12, 9152.90 examples/s]Generating train split: 177513 examples [00:12, 9024.44 examples/s]Generating train split: 178656 examples [00:12, 9011.20 examples/s]Generating train split: 179665 examples [00:12, 7823.40 examples/s]Generating train split: 1 examples [00:11, 8404.10 examples/s]Generating train split: 161536 examples [00:11, 7972.30 examples/s]Generating train split: 162488 examples [00:11, 7776.40 examples/s]Generating train split: 163516 examples [00:11, 7749.26 examples/s]Generating train split: 164629 examples [00:11, 7828.08 examples/s]Generating train split: 165642 examples [00:11, 7787.12 examples/s]Generating train split: 166715 examples [00:11, 7927.21 examples/s]Generating train split: 167712 examples [00:12, 7897.49 examples/s]Generating train split: 168741 examples [00:12, 7942.53 examples/s]Generating train split: 169671 examples [00:12, 7656.05 examples/s]Generating train split: 170675 examples [00:12, 7687.07 examples/s]Generating train split: 171651 examples [00:12, 7419.69 examples/s]Generating train split: 172584 examples [00:12, 7304.43 examples/s]Generating train split: 173584 examples [00:12, 7440.64 examples/s]Generating train split: 174982 examples [00:12, 8475.92 examples/s]Generating train split: 176355 exa1, 11835.20 examples/s]Generating train split: 154683 examples [00:11, 10455.36 examples/s]Generating train split: 156168 examples [00:11, 9646.72 examples/s] Generating train split: 157592 examples [00:11, 8751.02 examples/s]Generating train split: 158733 examples [00:11, 8778.50 examples/s]Generating train split: 159877 examples [00:11, 8818.14 examples/s]Generating train split: 160825 examples [00:12, 8449.07 examples/s]Generating train split: 161772 examples [00:12, 8100.69 examples/s]Generating train split: 162718 examples [00:12, 7837.69 examples/s]Generating train split: 163796 examples [00:12, 7881.17 examples/s]Generating train split: 164872 examples [00:12, 7989.25 examples/s]Generating train split: 165859 examples [00:12, 7885.98 examples/s]Generating train split: 166963 examples [00:12, 8053.92 examples/s]Generating train split: 167973 examples [00:12, 8020.10 examples/s]Generating train split: 168981 examples [00:13, 7939.46 examples/s]Generating train split: 169923 examples [00:13ples [00:11, 8466.46 examples/s]Generating train split: 159085 examples [00:11, 8723.11 examples/s]Generating train split: 160157 examples [00:11, 8643.19 examples/s]Generating train split: 161053 examples [00:11, 8209.45 examples/s]Generating train split: 162011 examples [00:11, 8017.35 examples/s]Generating train split: 162959 examples [00:11, 7764.67 examples/s]Generating train split: 164091 examples [00:12, 8089.01 examples/s]Generating train split: 165095 examples [00:12, 7922.01 examples/s]Generating train split: 166081 examples [00:12, 7796.93 examples/s]Generating train split: 167211 examples [00:12, 7933.64 examples/s]Generating train split: 168227 examples [00:12, 7893.22 examples/s]Generating train split: 169217 examples [00:12, 7758.70 examples/s]Generating train split: 170154 examples [00:12, 7599.21 examples/s]Generating train split: 171156 examples [00:13, 7359.99 examples/s]Generating train split: 172106 examples [00:13, 7389.04 examples/s]Generating train split: 173084 examples80670 examples [00:12, 7776.45 examples/s]Generating train split: 181607 examples [00:12, 7583.45 examples/s]Generating train split: 182531 examples [00:12, 7469.28 examples/s]Generating train split: 183527 examples [00:13, 7478.29 examples/s]Generating train split: 184706 examples [00:13, 7962.66 examples/s]Generating train split: 185767 examples [00:13, 7863.42 examples/s]Generating train split: 186654 examples [00:13, 7504.66 examples/s]Generating train split: 186688 examples [00:13, 13865.96 examples/s]
 examples/s]Generating train split: 146392 examples [00:11, 19559.15 examples/s]Generating train split: 148863 examples [00:11, 16794.01 examples/s]Generating train split: 150947 examples [00:11, 14593.80 examples/s]Generating train split: 152790 examples [00:11, 12836.82 examples/s]Generating train split: 154186 examples [00:11, 11022.86 examples/s]Generating train split: 155721 examples [00:12, 10028.74 examples/s]Generating train split: 157107 examples [00:12, 9035.80 examples/s] Generating train split: 158384 examples [00:12, 8284.23 examples/s]Generating train split: 159623 examples [00:12, 8542.00 examples/s]Generating train split: 160586 examples [00:12, 8277.76 examples/s]Generating train split: 161536 examples [00:12, 8044.19 examples/s]Generating train split: 162488 examples [00:13, 7880.36 examples/s]Generating train split: 163516 examples [00:13, 7880.56 examples/s]Generating train split: 164629 examples [00:13, 8088.57 examples/s]Generating train split: 165642 examples [00:13, 7959mples [00:13, 9051.92 examples/s]Generating train split: 177513 examples [00:13, 8930.60 examples/s]Generating train split: 178656 examples [00:13, 8726.91 examples/s]Generating train split: 179665 examples [00:13, 7569.74 examples/s]Generating train split: 180670 examples [00:13, 7548.65 examples/s]Generating train split: 181607 examples [00:13, 7387.09 examples/s]Generating train split: 182531 examples [00:13, 7302.42 examples/s]Generating train split: 183527 examples [00:14, 7317.93 examples/s]Generating train split: 184706 examples [00:14, 7797.36 examples/s]Generating train split: 185767 examples [00:14, 7664.30 examples/s]Generating train split: 186654 examples [00:14, 7386.38 examples/s]Generating train split: 186688 examples [00:14, 12901.24 examples/s]
mples/s]Generating train split: 132305 examples [00:12, 13526.94 examples/s]Generating train split: 134835 examples [00:12, 14595.45 examples/s]Generating train split: 137417 examples [00:12, 14759.51 examples/s]Generating train split: 139989 examples [00:12, 14690.88 examples/s]Generating train split: 142532 examples [00:12, 15451.29 examples/s]Generating train split: 145072 examples [00:12, 15623.72 examples/s]Generating train split: 147446 examples [00:12, 15257.76 examples/s]Generating train split: 149580 examples [00:13, 13149.75 examples/s]Generating train split: 150947 examples [00:13, 11415.70 examples/s]Generating train split: 152239 examples [00:13, 10758.40 examples/s]Generating train split: 153738 examples [00:13, 9062.32 examples/s] Generating train split: 155185 examples [00:14, 8122.39 examples/s]Generating train split: 156168 examples [00:14, 7286.48 examples/s]Generating train split: 157107 examples [00:14, 6582.75 examples/s]Generating train split: 157859 examples [00:14, 6331es/s]Generating train split: 131027 examples [00:11, 13757.63 examples/s]Generating train split: 133554 examples [00:12, 13928.25 examples/s]Generating train split: 136128 examples [00:12, 14489.21 examples/s]Generating train split: 138693 examples [00:12, 14777.25 examples/s]Generating train split: 141248 examples [00:12, 15063.08 examples/s]Generating train split: 143792 examples [00:12, 15213.40 examples/s]Generating train split: 146392 examples [00:12, 15684.32 examples/s]Generating train split: 148156 examples [00:13, 14340.20 examples/s]Generating train split: 150282 examples [00:13, 12495.87 examples/s]Generating train split: 152239 examples [00:13, 10846.77 examples/s]Generating train split: 153738 examples [00:13, 9227.89 examples/s] Generating train split: 155185 examples [00:14, 8216.93 examples/s]Generating train split: 156168 examples [00:14, 7547.63 examples/s]Generating train split: 157107 examples [00:14, 6783.99 examples/s]Generating train split: 158130 examples [00:14, 6561.08 [00:13, 7395.35 examples/s]Generating train split: 174280 examples [00:13, 7898.80 examples/s]Generating train split: 175670 examples [00:13, 8760.62 examples/s]Generating train split: 176950 examples [00:13, 9022.32 examples/s]Generating train split: 178099 examples [00:13, 8988.93 examples/s]Generating train split: 179160 examples [00:13, 8120.70 examples/s]Generating train split: 180157 examples [00:14, 7784.26 examples/s]Generating train split: 181141 examples [00:14, 7625.51 examples/s]Generating train split: 182067 examples [00:14, 7086.01 examples/s]Generating train split: 183016 examples [00:14, 7157.78 examples/s]Generating train split: 184099 examples [00:14, 7302.67 examples/s]Generating train split: 185338 examples [00:14, 7746.90 examples/s]Generating train split: 186192 examples [00:14, 7431.09 examples/s]Generating train split: 186688 examples [00:14, 12447.39 examples/s]
 examples/s]Generating train split: 138693 examples [00:12, 14861.63 examples/s]Generating train split: 141248 examples [00:12, 14855.46 examples/s]Generating train split: 143792 examples [00:12, 15549.02 examples/s]Generating train split: 146392 examples [00:12, 15711.14 examples/s]Generating train split: 148156 examples [00:13, 14313.10 examples/s]Generating train split: 150282 examples [00:13, 12501.51 examples/s]Generating train split: 151876 examples [00:13, 10736.99 examples/s]Generating train split: 153054 examples [00:13, 10086.42 examples/s]Generating train split: 154420 examples [00:13, 8404.60 examples/s] Generating train split: 155471 examples [00:14, 8061.39 examples/s]Generating train split: 156664 examples [00:14, 6719.04 examples/s]Generating train split: 157592 examples [00:14, 6392.78 examples/s]Generating train split: 158733 examples [00:14, 6316.12 examples/s]Generating train split: 159877 examples [00:14, 6344.62 examples/s]Generating train split: 160825 examples [00:14, 61, 7779.25 examples/s]Generating train split: 170898 examples [00:13, 7450.54 examples/s]Generating train split: 171873 examples [00:13, 7462.79 examples/s]Generating train split: 172824 examples [00:13, 7358.99 examples/s]Generating train split: 173931 examples [00:13, 7711.67 examples/s]Generating train split: 175322 examples [00:13, 8666.41 examples/s]Generating train split: 176708 examples [00:14, 9163.95 examples/s]Generating train split: 177871 examples [00:14, 9082.71 examples/s]Generating train split: 178921 examples [00:14, 8741.46 examples/s]Generating train split: 180157 examples [00:14, 7329.61 examples/s]Generating train split: 181141 examples [00:14, 6669.01 examples/s]Generating train split: 182067 examples [00:14, 6455.05 examples/s]Generating train split: 183016 examples [00:14, 6666.54 examples/s]Generating train split: 184099 examples [00:15, 7036.33 examples/s]Generating train split: 185338 examples [00:15, 7315.88 examples/s]Generating train split: 186192 examples [00:15, 7113.39 examples/s]Generating train split: 186688 examples [00:15, 12068.89 examples/s]
.82 examples/s]Generating train split: 166715 examples [00:13, 7432.36 examples/s]Generating train split: 167712 examples [00:13, 6977.12 examples/s]Generating train split: 168741 examples [00:13, 7135.15 examples/s]Generating train split: 169671 examples [00:14, 7084.44 examples/s]Generating train split: 170675 examples [00:14, 7264.83 examples/s]Generating train split: 171651 examples [00:14, 7103.44 examples/s]Generating train split: 172584 examples [00:14, 7147.97 examples/s]Generating train split: 173584 examples [00:14, 7336.48 examples/s]Generating train split: 174982 examples [00:14, 8372.13 examples/s]Generating train split: 176355 examples [00:14, 9082.19 examples/s]Generating train split: 177513 examples [00:14, 9003.83 examples/s]Generating train split: 178656 examples [00:15, 8987.49 examples/s]Generating train split: 179665 examples [00:15, 7981.67 examples/s]Generating train split: 180670 examples [00:15, 7898.62 examples/s]Generating train split: 181607 examples [00:15, 7653.44 Converting format of dataset (num_proc=64):   0%|          | 0/168718 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 448/168718 [00:01<08:13, 340.69 examples/s]Converting format of dataset (num_proc=64):  14%|        | 24222/168718 [00:01<00:06, 23599.84 examples/s]Converting format of dataset (num_proc=64):  31%|       | 51509/168718 [00:01<00:02, 54166.45 examples/s]Converting format of dataset (num_proc=64):  45%|     | 75628/168718 [00:01<00:01, 81974.96 examples/s]Converting format of dataset (num_proc=64):  58%|    | 98516/168718 [00:01<00:00, 107702.28 examples/s]Converting format of dataset (num_proc=64):  72%|  | 121542/168718 [00:01<00:00, 131284.18 examples/s]Converting format of dataset (num_proc=64):  85%| | 143711/168718 [00:01<00:00, 147864.65 examples/s]Converting format of dataset (num_proc=64):  98%|| 165188/168718 [00:examples/s]Generating train split: 182531 examples [00:15, 7496.34 examples/s]Generating train split: 183527 examples [00:15, 7507.22 examples/s]Generating train split: 184706 examples [00:15, 7995.64 examples/s]Generating train split: 184975 examples [00:16, 11556.09 examples/s]
29.82 examples/s]Generating train split: 161772 examples [00:15, 5658.51 examples/s]Generating train split: 162718 examples [00:15, 5634.02 examples/s]Generating train split: 163796 examples [00:15, 5840.30 examples/s]Generating train split: 164629 examples [00:15, 5647.06 examples/s]Generating train split: 165642 examples [00:15, 5833.17 examples/s]Generating train split: 166715 examples [00:16, 5881.33 examples/s]Generating train split: 167712 examples [00:16, 5744.11 examples/s]Generating train split: 168741 examples [00:16, 5760.91 examples/s]Generating train split: 169671 examples [00:16, 5518.83 examples/s]Generating train split: 170398 examples [00:16, 5508.28 examples/s]Generating train split: 170675 examples [00:16, 10159.38 examples/s]
 examples/s]Generating train split: 159360 examples [00:14, 6504.90 examples/s]Generating train split: 160359 examples [00:14, 6379.91 examples/s]Generating train split: 161290 examples [00:15, 5928.52 examples/s]Generating train split: 162011 examples [00:15, 5750.82 examples/s]Generating train split: 162959 examples [00:15, 5710.60 examples/s]Generating train split: 164091 examples [00:15, 5864.99 examples/s]Generating train split: 165095 examples [00:15, 5682.82 examples/s]Generating train split: 166081 examples [00:15, 5751.45 examples/s]Generating train split: 167211 examples [00:16, 5760.06 examples/s]Generating train split: 168227 examples [00:16, 5875.31 examples/s]Generating train split: 169217 examples [00:16, 5665.50 examples/s]Generating train split: 170154 examples [00:16, 5527.75 examples/s]Generating train split: 170675 examples [00:16, 10154.28 examples/s]
.97 examples/s]Generating train split: 159085 examples [00:14, 6340.91 examples/s]Generating train split: 160157 examples [00:14, 6346.08 examples/s]Generating train split: 161053 examples [00:15, 5889.07 examples/s]Generating train split: 162011 examples [00:15, 5650.67 examples/s]Generating train split: 162959 examples [00:15, 5642.09 examples/s]Generating train split: 164091 examples [00:15, 5783.89 examples/s]Generating train split: 165095 examples [00:15, 5683.25 examples/s]Generating train split: 166081 examples [00:15, 5724.24 examples/s]Generating train split: 167211 examples [00:16, 5754.38 examples/s]Generating train split: 168227 examples [00:16, 5853.77 examples/s]Generating train split: 169217 examples [00:16, 5691.38 examples/s]Generating train split: 170154 examples [00:16, 5501.02 examples/s]Generating train split: 170675 examples [00:16, 10136.35 examples/s]
02<00:00, 112779.52 examples/s]Converting format of dataset (num_proc=64): 182406 examples [00:03, 33400.47 examples/s]                      Converting format of dataset (num_proc=64): 186688 examples [00:04, 39152.18 examples/s]
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
[rank12]: Traceback (most recent call last):
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank12]:     main()
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank12]:     run_exp()
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank12]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank12]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank12]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank12]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank12]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank12]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank12]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank12]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank12]:     dataset = load_dataset(
[rank12]:               ^^^^^^^^^^^^^
[rank12]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank12]:     builder_instance.download_and_prepare(
[rank12]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank12]:     self._download_and_prepare(
[rank12]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 972, in _download_and_prepare
[rank12]:     raise OSError(
[rank12]: OSError: Cannot find data file. 
[rank12]: Original error:
[rank12]: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00000-of-NNNNN.arrow'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank0]:     main()
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank0]:     run_exp()
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank0]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank0]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank0]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank0]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank0]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank0]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank0]:     dataset = load_dataset(
[rank0]:               ^^^^^^^^^^^^^
[rank0]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank0]:     builder_instance.download_and_prepare(
[rank0]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank0]:     self._download_and_prepare(
[rank0]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 972, in _download_and_prepare
[rank0]:     raise OSError(
[rank0]: OSError: Cannot find data file. 
[rank0]: Original error:
[rank0]: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00000-of-NNNNN.arrow'
[rank24]: Traceback (most recent call last):
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank24]:     main()
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank24]:     run_exp()
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank24]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank24]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank24]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank24]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank24]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank24]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank24]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank24]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank24]:     dataset = load_dataset(
[rank24]:               ^^^^^^^^^^^^^
[rank24]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank24]:     builder_instance.download_and_prepare(
[rank24]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank24]:     self._download_and_prepare(
[rank24]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 972, in _download_and_prepare
[rank24]:     raise OSError(
[rank24]: OSError: Cannot find data file. 
[rank24]: Original error:
[rank24]: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00000-of-NNNNN.arrow'
[rank20]: Traceback (most recent call last):
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1823, in _prepare_split_single
[rank20]:     writer = writer_class(
[rank20]:              ^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 389, in __init__
[rank20]:     self.stream = self._fs.open(path, "wb")
[rank20]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/spec.py", line 1310, in open
[rank20]:     f = self._open(
[rank20]:         ^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 201, in _open
[rank20]:     return LocalFileOpener(path, mode, fs=self, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 365, in __init__
[rank20]:     self._open()
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 370, in _open
[rank20]:     self.f = open(self.path, mode=self.mode)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]: FileNotFoundError: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00006-of-NNNNN.arrow'

[rank20]: During handling of the above exception, another exception occurred:

[rank20]: Traceback (most recent call last):
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1847, in _prepare_split_single
[rank20]:     num_examples, num_bytes = writer.finalize()
[rank20]:                               ^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 661, in finalize
[rank20]:     self._build_writer(self.schema)
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 457, in _build_writer
[rank20]:     self.pa_writer = self._WRITER_CLASS(self.stream, schema)
[rank20]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/pyarrow/ipc.py", line 90, in __init__
[rank20]:     self._open(sink, schema, options=options)
[rank20]:   File "pyarrow/ipc.pxi", line 615, in pyarrow.lib._RecordBatchStreamWriter._open
[rank20]:   File "pyarrow/io.pxi", line 2209, in pyarrow.lib.get_writer
[rank20]:   File "pyarrow/io.pxi", line 231, in pyarrow.lib.NativeFile.get_output_stream
[rank20]:   File "pyarrow/io.pxi", line 245, in pyarrow.lib.NativeFile._assert_writable
[rank20]:   File "pyarrow/io.pxi", line 236, in pyarrow.lib.NativeFile._assert_open
[rank20]: ValueError: I/O operation on closed file

[rank20]: The above exception was the direct cause of the following exception:

[rank20]: Traceback (most recent call last):
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank20]:     main()
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank20]:     run_exp()
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank20]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank20]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank20]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank20]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank20]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank20]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank20]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank20]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank20]:     dataset = load_dataset(
[rank20]:               ^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank20]:     builder_instance.download_and_prepare(
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank20]:     self._download_and_prepare(
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 970, in _download_and_prepare
[rank20]:     self._prepare_split(split_generator, **prepare_split_kwargs)
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1702, in _prepare_split
[rank20]:     for job_id, done, content in self._prepare_split_single(
[rank20]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1858, in _prepare_split_single
[rank20]:     raise DatasetGenerationError("An error occurred while generating the dataset") from e
[rank20]: datasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset
[rank16]: Traceback (most recent call last):
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1823, in _prepare_split_single
[rank16]:     writer = writer_class(
[rank16]:              ^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 389, in __init__
[rank16]:     self.stream = self._fs.open(path, "wb")
[rank16]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/spec.py", line 1310, in open
[rank16]:     f = self._open(
[rank16]:         ^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 201, in _open
[rank16]:     return LocalFileOpener(path, mode, fs=self, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 365, in __init__
[rank16]:     self._open()
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 370, in _open
[rank16]:     self.f = open(self.path, mode=self.mode)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]: FileNotFoundError: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00006-of-NNNNN.arrow'

[rank16]: During handling of the above exception, another exception occurred:

[rank16]: Traceback (most recent call last):
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1847, in _prepare_split_single
[rank16]:     num_examples, num_bytes = writer.finalize()
[rank16]:                               ^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 661, in finalize
[rank16]:     self._build_writer(self.schema)
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 457, in _build_writer
[rank16]:     self.pa_writer = self._WRITER_CLASS(self.stream, schema)
[rank16]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/pyarrow/ipc.py", line 90, in __init__
[rank16]:     self._open(sink, schema, options=options)
[rank16]:   File "pyarrow/ipc.pxi", line 615, in pyarrow.lib._RecordBatchStreamWriter._open
[rank16]:   File "pyarrow/io.pxi", line 2209, in pyarrow.lib.get_writer
[rank16]:   File "pyarrow/io.pxi", line 231, in pyarrow.lib.NativeFile.get_output_stream
[rank16]:   File "pyarrow/io.pxi", line 245, in pyarrow.lib.NativeFile._assert_writable
[rank16]:   File "pyarrow/io.pxi", line 236, in pyarrow.lib.NativeFile._assert_open
[rank16]: ValueError: I/O operation on closed file

[rank16]: The above exception was the direct cause of the following exception:

[rank16]: Traceback (most recent call last):
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank16]:     main()
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank16]:     run_exp()
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank16]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank16]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank16]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank16]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank16]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank16]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank16]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank16]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank16]:     dataset = load_dataset(
[rank16]:               ^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank16]:     builder_instance.download_and_prepare(
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank16]:     self._download_and_prepare(
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 970, in _download_and_prepare
[rank16]:     self._prepare_split(split_generator, **prepare_split_kwargs)
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1702, in _prepare_split
[rank16]:     for job_id, done, content in self._prepare_split_single(
[rank16]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1858, in _prepare_split_single
[rank16]:     raise DatasetGenerationError("An error occurred while generating the dataset") from e
[rank16]: datasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset
[rank4]: Traceback (most recent call last):
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1823, in _prepare_split_single
[rank4]:     writer = writer_class(
[rank4]:              ^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 389, in __init__
[rank4]:     self.stream = self._fs.open(path, "wb")
[rank4]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/spec.py", line 1310, in open
[rank4]:     f = self._open(
[rank4]:         ^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 201, in _open
[rank4]:     return LocalFileOpener(path, mode, fs=self, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 365, in __init__
[rank4]:     self._open()
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 370, in _open
[rank4]:     self.f = open(self.path, mode=self.mode)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]: FileNotFoundError: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00006-of-NNNNN.arrow'

[rank4]: During handling of the above exception, another exception occurred:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1847, in _prepare_split_single
[rank4]:     num_examples, num_bytes = writer.finalize()
[rank4]:                               ^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 661, in finalize
[rank4]:     self._build_writer(self.schema)
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 457, in _build_writer
[rank4]:     self.pa_writer = self._WRITER_CLASS(self.stream, schema)
[rank4]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/pyarrow/ipc.py", line 90, in __init__
[rank4]:     self._open(sink, schema, options=options)
[rank4]:   File "pyarrow/ipc.pxi", line 615, in pyarrow.lib._RecordBatchStreamWriter._open
[rank4]:   File "pyarrow/io.pxi", line 2209, in pyarrow.lib.get_writer
[rank4]:   File "pyarrow/io.pxi", line 231, in pyarrow.lib.NativeFile.get_output_stream
[rank4]:   File "pyarrow/io.pxi", line 245, in pyarrow.lib.NativeFile._assert_writable
[rank4]:   File "pyarrow/io.pxi", line 236, in pyarrow.lib.NativeFile._assert_open
[rank4]: ValueError: I/O operation on closed file

[rank4]: The above exception was the direct cause of the following exception:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank4]:     main()
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank4]:     run_exp()
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank4]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank4]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank4]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank4]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank4]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank4]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank4]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank4]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank4]:     dataset = load_dataset(
[rank4]:               ^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank4]:     builder_instance.download_and_prepare(
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank4]:     self._download_and_prepare(
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 970, in _download_and_prepare
[rank4]:     self._prepare_split(split_generator, **prepare_split_kwargs)
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1702, in _prepare_split
[rank4]:     for job_id, done, content in self._prepare_split_single(
[rank4]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1858, in _prepare_split_single
[rank4]:     raise DatasetGenerationError("An error occurred while generating the dataset") from e
[rank4]: datasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset
[rank8]: Traceback (most recent call last):
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1823, in _prepare_split_single
[rank8]:     writer = writer_class(
[rank8]:              ^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 389, in __init__
[rank8]:     self.stream = self._fs.open(path, "wb")
[rank8]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/spec.py", line 1310, in open
[rank8]:     f = self._open(
[rank8]:         ^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 201, in _open
[rank8]:     return LocalFileOpener(path, mode, fs=self, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 365, in __init__
[rank8]:     self._open()
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/fsspec/implementations/local.py", line 370, in _open
[rank8]:     self.f = open(self.path, mode=self.mode)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]: FileNotFoundError: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.cache/huggingface/datasets/json/default-c1e8f5769ce7d8a8/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092.incomplete/json-train-00000-00007-of-NNNNN.arrow'

[rank8]: During handling of the above exception, another exception occurred:

[rank8]: Traceback (most recent call last):
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1847, in _prepare_split_single
[rank8]:     num_examples, num_bytes = writer.finalize()
[rank8]:                               ^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 661, in finalize
[rank8]:     self._build_writer(self.schema)
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/arrow_writer.py", line 457, in _build_writer
[rank8]:     self.pa_writer = self._WRITER_CLASS(self.stream, schema)
[rank8]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/pyarrow/ipc.py", line 90, in __init__
[rank8]:     self._open(sink, schema, options=options)
[rank8]:   File "pyarrow/ipc.pxi", line 615, in pyarrow.lib._RecordBatchStreamWriter._open
[rank8]:   File "pyarrow/io.pxi", line 2209, in pyarrow.lib.get_writer
[rank8]:   File "pyarrow/io.pxi", line 231, in pyarrow.lib.NativeFile.get_output_stream
[rank8]:   File "pyarrow/io.pxi", line 245, in pyarrow.lib.NativeFile._assert_writable
[rank8]:   File "pyarrow/io.pxi", line 236, in pyarrow.lib.NativeFile._assert_open
[rank8]: ValueError: I/O operation on closed file

[rank8]: The above exception was the direct cause of the following exception:

[rank8]: Traceback (most recent call last):
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 27, in <module>
[rank8]:     main()
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/train.py", line 18, in main
[rank8]:     run_exp()
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 110, in run_exp
[rank8]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/tuner.py", line 72, in _training_function
[rank8]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/train/sft/workflow.py", line 51, in run_sft
[rank8]:     dataset_module = get_dataset(template, model_args, data_args, training_args, stage="sft", **tokenizer_module)
[rank8]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 304, in get_dataset
[rank8]:     dataset = _get_merged_dataset(data_args.dataset, model_args, data_args, training_args, stage)
[rank8]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 182, in _get_merged_dataset
[rank8]:     datasets[dataset_name] = _load_single_dataset(dataset_attr, model_args, data_args, training_args)
[rank8]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/projects/LLaMA-Factory-new/src/llamafactory/data/loader.py", line 131, in _load_single_dataset
[rank8]:     dataset = load_dataset(
[rank8]:               ^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/load.py", line 1412, in load_dataset
[rank8]:     builder_instance.download_and_prepare(
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 894, in download_and_prepare
[rank8]:     self._download_and_prepare(
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 970, in _download_and_prepare
[rank8]:     self._prepare_split(split_generator, **prepare_split_kwargs)
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1702, in _prepare_split
[rank8]:     for job_id, done, content in self._prepare_split_single(
[rank8]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/datasets/builder.py", line 1858, in _prepare_split_single
[rank8]:     raise DatasetGenerationError("An error occurred while generating the dataset") from e
[rank8]: datasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset
Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s][rank20]:[W1003 11:36:11.685637754 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s][rank12]:[W1003 11:36:11.413441971 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 666/186688 [00:01<06:57, 445.31 examples/s]Converting format of dataset (num_proc=64):   0%|          | 660/186688 [00:01<07:01, 441.47 examples/s]Converting format of dataset (num_proc=64):   7%|         | 12167/186688 [00:01<00:16, 10377.13 examples/s]Converting format of dataset (num_proc=64):   8%|         | 14678/186688 [00:01<00:13, 12593.47 examples/s]Converting format of dataset (num_proc=64):  16%|        | 29528/186688 [00:01<00:05, 28178.33 examples/s]Converting format of dataset (num_proc=64):  18%|        | 34385/186688 [00:01<00:04, 32887.45 eConverting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Exception ignored in atexit callback: <function matmul_ext_update_autotune_table at 0x14b1360825c0>
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 480, in matmul_ext_update_autotune_table
    fp16_matmul._update_autotune_table()
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 457, in _update_autotune_table
    TritonMatmul._update_autotune_table(__class__.__name__ + "_2d_kernel", __class__._2d_kernel)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 186, in _update_autotune_table
    cache_manager.put(autotune_table)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 105, in put
    os.replace(self.file_path + ".tmp", self.file_path)
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/gpfs/yl7690/.triton/autotune/Fp16Matmul_2d_kernel.pickle.tmp' -> '/scratch/gpfs/yl7690/.triton/autotune/Fp16Matmul_2d_kernel.pickle'
xamples/s]Converting format of dataset (num_proc=64):  24%|       | 45206/186688 [00:01<00:03, 45520.84 examples/s]Converting format of dataset (num_proc=64):  28%|       | 53005/186688 [00:01<00:02, 53503.00 examples/s]Converting format of dataset (num_proc=64):  31%|       | 58147/186688 [00:01<00:02, 59033.84 examples/s]Converting format of dataset (num_proc=64):  38%|      | 70061/186688 [00:01<00:01, 72424.36 examples/s]Converting format of dataset (num_proc=64):  39%|      | 73046/186688 [00:02<00:01, 75167.40 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86314/186688 [00:02<00:01, 85866.54 examples/s]Converting format of dataset (num_proc=64):  48%|     | 89105/186688 [00:02<00:01, 91142.93 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102505/186688 [00:02<00:00, 100535.10 examples/s]Converting format of dataset (num_proc=64):  60%|    | Converting format of dataset (num_proc=64):   0%|          | 188/186688 [00:01<25:40, 121.08 examples/s]Converting format of dataset (num_proc=64):  12%|        | 23031/186688 [00:01<00:08, 19297.53 examples/s]Converting format of dataset (num_proc=64):  24%|       | 45606/186688 [00:01<00:03, 41304.90 examples/s]Converting format of dataset (num_proc=64):   0%|          | 141/186688 [00:01<41:23, 75.12 examples/s]Converting format of dataset (num_proc=64):  34%|      | 62821/186688 [00:01<00:02, 57255.96 examples/s]Converting format of dataset (num_proc=64):   3%|         | 5783/186688 [00:01<00:44, 4058.47 examples/s]Converting format of dataset (num_proc=64):  44%|     | 83075/186688 [00:01<00:01, 79772.78 examples/s]Converting format of dataset (num_proc=64):  11%|        | 21178/186688 [00:02<00:09, 17777.44 examples/s]Converting format of dataset (num_proc=64):  18%|        | 33155/186688 [00:02<00:05, 29510.09 examples/s]Converting formConverting format of dataset (num_proc=64):   0%|          | 530/186688 [00:01<08:52, 349.69 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:01<79:21:08,  1.53s/ examples]Converting format of dataset (num_proc=64):   7%|         | 13350/186688 [00:01<00:15, 11360.82 examples/s]Converting format of dataset (num_proc=64):   4%|         | 6933/186688 [00:01<00:30, 5911.43 examples/s]Converting format of dataset (num_proc=64):  17%|        | 31068/186688 [00:01<00:05, 29497.16 examples/s]Converting format of dataset (num_proc=64):   9%|         | 17697/186688 [00:01<00:10, 16866.33 examples/s]Converting format of dataset (num_proc=64):  27%|       | 49782/186688 [00:01<00:02, 50747.53 examples/s]Converting format of dataset (num_proc=64):  17%|        | 31954/186688 [00:01<00:04, 33487.55 examples/s]Converting format of dataset (num_proc=64):  27%|       | 50209/186688 [00:01<00:02, 57059.71 examples/s]Converting format of datas111933/186688 [00:02<00:00, 121144.70 examples/s]Converting format of dataset (num_proc=64):  65%|   | 122157/186688 [00:02<00:00, 121347.56 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128393/186688 [00:02<00:00, 118941.51 examples/s]Converting format of dataset (num_proc=64):  74%|  | 138871/186688 [00:02<00:00, 116719.39 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143469/186688 [00:02<00:00, 115668.52 examples/s]Converting format of dataset (num_proc=64):  82%| | 153799/186688 [00:02<00:00, 107631.40 examples/s]Converting format of dataset (num_proc=64):  84%| | 157424/186688 [00:02<00:00, 115177.84 examples/s]Converting format of dataset (num_proc=64):   0%|          | 422/186688 [00:02<19:19, 160.60 examples/s]Converting format of dataset (num_proc=64):  89%| | 166971/186688 [00:02<00:00, Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:02<140:25:33,  2.71s/ examples]Converting format of dataset (num_proc=64):   1%|         | 2485/186688 [00:02<02:28, 1244.50 examples/s][rank4]:[W1003 11:36:12.022536244 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 511/186688 [00:02<15:58, 194.28 examples/s]Converting format of dataset (num_proc=64):   1%|          | 1176/186688 [00:02<05:53, 524.90 examples/s][rank16]:[W1003 11:36:12.754122040 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Converting format of dataset (num_proc=64):   0%|          | 393/186688 [00:02<20:57, 148.16 examples/s]Converting format of dataset (num_proc=64):   0%|          | 393/186688 [00:02<20:54, 148.48 examples/s]Converting format of dataset (num_proc=64):   1%|          | 1527/186688 [00:02<04:17, 718.75 examples/s]Converting format of dataset (num_proc=64):   1%|          | 1614/186688 [00:02<04:03, 758.66 examples/s][rank0]:[W1003 11:36:12.026424688 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 234/186688 [00:02<34:44, 89.44 examples/s]Converting format of dataset (num_proc=64):   1%|          | 2277/186688 [00:02<02:41, 1140.13 examples/s]Converting format of dataset (num_proc=64):   3%|         | 5606/186688 [00:02<00:54, 3344.35 examples/s][rank8]:[W1003 11:36:12.075256406 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 0/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64):   0%|          | 476/186688 [00:02<16:57, 183.01 examples/s]Converting format of dataset (num_proc=64):   7%|         | 12394/186688 [00:02<00:27, 6362.54 examples/s]Converting format of dataset (num_proc=64):  16%|        | 29765/186688 [00:02<00:08, 17913.94 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:02<145:33:12,  2.81s/ examples]Converting format of dataset (num_proc=64):  28%|       | 51796/186688 [00:02<00:03, 35816.83 examples/s][rank24]:[W1003 11:36:12.347964693 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
101388.39 examples/s]Converting format of dataset (num_proc=64):  92%|| 170824/186688 [00:02<00:00, 114767.72 examples/s]Converting format of dataset (num_proc=64):   3%|         | 5951/186688 [00:02<01:00, 2979.55 examples/s]Converting format of dataset (num_proc=64):   8%|         | 14937/186688 [00:02<00:19, 8888.40 examples/s]Converting format of dataset (num_proc=64):  96%|| 178905/186688 [00:02<00:00, 84450.32 examples/s] Converting format of dataset (num_proc=64):  15%|        | 27612/186688 [00:02<00:08, 19268.66 examples/s]Converting format of dataset (num_proc=64):  98%|| 183490/186688 [00:03<00:00, 82595.50 examples/s] Converting format of dataset (num_proc=64):  26%|       | 48590/186688 [00:03<00:03, 40439.90 examples/s]Converting format of dataset (num_proc=64):  39%|      | 72190/186688 [00:03<00:01, 67264.86 examples/s]Converting format of dataset (num_proc=64):  Converting format of dataset (num_proc=64):   1%|          | 1423/186688 [00:02<04:30, 683.77 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:02<155:15:26,  2.99s/ examples]Converting format of dataset (num_proc=64):  41%|      | 76603/186688 [00:03<00:01, 59764.52 examples/s]Converting format of dataset (num_proc=64):   3%|         | 6394/186688 [00:03<00:47, 3832.72 examples/s]Converting format of dataset (num_proc=64):   2%|         | 3100/186688 [00:03<02:10, 1409.50 examples/s]Converting format of dataset (num_proc=64):  51%|    | 95984/186688 [00:03<00:01, 77554.20 examples/s]Converting format of dataset (num_proc=64):   8%|         | 15112/186688 [00:03<00:15, 10806.39 examples/s]Converting format of dataset (num_proc=64):   5%|         | 9356/186688 [00:03<00:34, 5136.18 examples/s]Converting format of dataset (num_proc=64):  61%|   | 114596/186688 [00:03<00:00, 90837.41 examples/s]Converting Converting format of dataset (num_proc=64):   3%|         | 5115/186688 [00:02<00:59, 3053.04 examples/s]Converting format of dataset (num_proc=64):   3%|         | 5358/186688 [00:02<00:57, 3176.14 examples/s]Converting format of dataset (num_proc=64):   5%|         | 10024/186688 [00:02<00:25, 6936.66 examples/s]Converting format of dataset (num_proc=64):   6%|         | 11331/186688 [00:02<00:21, 8075.35 examples/s]Converting format of dataset (num_proc=64):   9%|         | 16802/186688 [00:03<00:12, 13161.45 examples/s]Converting format of dataset (num_proc=64):   9%|         | 16905/186688 [00:03<00:12, 13462.30 examples/s]Converting format of dataset (num_proc=64):  14%|        | 26931/186688 [00:03<00:06, 25012.98 examples/s]Converting format of dataset (num_proc=64):  14%|        | 26614/186688 [00:03<00:06, 24523.45 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:03<167:11:49,  3.22s/ examples]Converting format of dataset (nConverting format of dataset (num_proc=64):   7%|         | 12721/186688 [00:02<00:18, 9394.64 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:03<157:54:32,  3.05s/ examples]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:03<158:17:06,  3.05s/ examples]Converting format of dataset (num_proc=64):  17%|        | 31061/186688 [00:03<00:05, 28896.20 examples/s]Converting format of dataset (num_proc=64):   2%|         | 3097/186688 [00:03<02:12, 1386.98 examples/s]Converting format of dataset (num_proc=64):   1%|          | 1752/186688 [00:03<03:56, 781.63 examples/s]Converting format of dataset (num_proc=64):  32%|      | 59927/186688 [00:03<00:01, 64787.82 examples/s]Converting format of dataset (num_proc=64):   6%|         | 10612/186688 [00:03<00:30, 5822.03 examples/s]Converting format of dataset (num_proc=64):   3%|         | 6352/186688 [00:03<00:51, 3482.83 examples/s]Converting format of dataset (num_proConverting format of dataset (num_proc=64):   3%|         | 5092/186688 [00:02<00:57, 3154.02 examples/s]Converting format of dataset (num_proc=64):   7%|         | 12557/186688 [00:02<00:18, 9406.07 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:02<152:38:13,  2.94s/ examples]Converting format of dataset (num_proc=64):  13%|        | 24584/186688 [00:03<00:07, 21672.64 examples/s]Converting format of dataset (num_proc=64):   2%|         | 3757/186688 [00:03<01:45, 1736.76 examples/s]Converting format of dataset (num_proc=64):  18%|        | 34344/186688 [00:03<00:04, 32014.41 examples/s]Converting format of dataset (num_proc=64):   0%|          | 1/186688 [00:03<165:09:31,  3.18s/ examples]Converting format of dataset (num_proc=64):   8%|         | 15056/186688 [00:03<00:20, 8568.61 examples/s]Converting format of dataset (num_proc=64):  28%|       | 52836/186688 [00:03<00:02, 56878.22 examples/s]Converting format of dataset (nu52%|    | 97488/186688 [00:03<00:00, 97690.02 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124261/186688 [00:03<00:00, 129130.93 examples/s]Converting format of dataset (num_proc=64):  78%|  | 145676/186688 [00:03<00:00, 141484.89 examples/s]Converting format of dataset (num_proc=64):  89%| | 166418/186688 [00:03<00:00, 131791.07 examples/s]Converting format of dataset (num_proc=64): 100%|| 186688/186688 [00:03<00:00, 50110.14 examples/s]
m_proc=64):   1%|          | 1940/186688 [00:03<03:42, 831.46 examples/s]Converting format of dataset (num_proc=64):  15%|        | 27529/186688 [00:03<00:08, 17926.08 examples/s]Converting format of dataset (num_proc=64):  34%|      | 63963/186688 [00:03<00:01, 64757.14 examples/s]Converting format of dataset (num_proc=64):   4%|         | 8056/186688 [00:03<00:41, 4307.38 examples/s]Converting format of dataset (num_proc=64):  21%|        | 39241/186688 [00:03<00:05, 27995.43 examples/s]Converting format of dataset (num_proc=64):  12%|        | 23099/186688 [00:03<00:10, 15422.77 examples/s]Converting format of dataset (num_proc=64):  28%|       | 51414/186688 [00:03<00:03, 39929.27 examples/s]Converting format of dataset (num_proc=64):  17%|        | 32473/186688 [00:03<00:06, 22984.31 examples/s]Converting format of dataset (num_proc=64):  22%|       | 41108/186688 [00:03<00:05, 26219.26 examples/s]Converting format of dataset (num_proc=64)Converting format of dataset (num_proc=64): 100%|| 186688/186688 [00:03<00:00, 49518.93 examples/s]
format of dataset (num_proc=64):  13%|        | 23990/186688 [00:03<00:08, 19124.93 examples/s]Converting format of dataset (num_proc=64):  10%|         | 17738/186688 [00:03<00:14, 11418.43 examples/s]Converting format of dataset (num_proc=64):  19%|        | 35204/186688 [00:03<00:04, 31284.60 examples/s]Converting format of dataset (num_proc=64):  16%|        | 29053/186688 [00:03<00:07, 21504.28 examples/s]Converting format of dataset (num_proc=64):  26%|       | 48310/186688 [00:03<00:02, 47081.32 examples/s]Converting format of dataset (num_proc=64):  20%|        | 36877/186688 [00:03<00:05, 28314.85 examples/s]Converting format of dataset (num_proc=64):  35%|      | 65565/186688 [00:03<00:01, 70148.87 examples/s]Converting format of dataset (num_proc=64):  29%|       | 53473/186688 [00:03<00:02, 48882.36 examples/s]Converting format of dataset (num_proc=64):  44%|     | 81951/186688 [00:03<00:01, 89580.04 examples/s]ConverConverting format of dataset (num_proc=64):   7%|         | 13260/186688 [00:02<00:20, 8355.21 examples/s]Converting format of dataset (num_proc=64):  21%|        | 39137/186688 [00:03<00:04, 30124.22 examples/s]Converting format of dataset (num_proc=64):  29%|       | 54855/186688 [00:03<00:02, 44128.29 examples/s]Converting format of dataset (num_proc=64):   0%|          | 71/186688 [00:03<2:19:23, 22.31 examples/s]Converting format of dataset (num_proc=64):  37%|      | 69136/186688 [00:03<00:02, 48373.68 examples/s]Converting format of dataset (num_proc=64):   2%|         | 3566/186688 [00:03<02:07, 1438.89 examples/s]Converting format of dataset (num_proc=64):   4%|         | 8221/186688 [00:03<00:45, 3904.10 examples/s]Converting format of dataset (num_proc=64):   6%|         | 10758/186688 [00:03<00:39, 4419.55 examples/s]Converting format of dataset (num_proc=64):   7%|         | 12526/186688 [00:04<00:40, 4323.36 examples/s]Converting format of dataConverting format of dataset (num_proc=64):  99%|| 184011/186688 [00:03<00:00, 111715.36 examples/s]Converting format of dataset (num_proc=64): 100%|| 186688/186688 [00:04<00:00, 44206.16 examples/s] 
srun: error: della-j17g1: task 6: Exited with exit code 1
um_proc=64):  22%|       | 41519/186688 [00:03<00:03, 44513.21 examples/s]Converting format of dataset (num_proc=64):  20%|        | 38072/186688 [00:03<00:03, 38861.44 examples/s]Converting format of dataset (num_proc=64):   1%|          | 1995/186688 [00:03<03:39, 842.38 examples/s]Converting format of dataset (num_proc=64):  28%|       | 51798/186688 [00:03<00:02, 55427.54 examples/s]Converting format of dataset (num_proc=64):  28%|       | 52883/186688 [00:03<00:02, 58973.02 examples/s]Converting format of dataset (num_proc=64):   7%|         | 13619/186688 [00:03<00:23, 7407.61 examples/s]Converting format of dataset (num_proc=64):  17%|        | 31071/186688 [00:03<00:07, 19965.13 examples/s]Converting format of dataset (num_proc=64):  34%|      | 62732/186688 [00:04<00:04, 27251.51 examples/s]Converting format of dataset (num_proc=64):  33%|      | 61097/186688 [00:04<00:07, 17032.00 examples/s]Converting format of dataset (num_srun: Terminating StepId=1159090.0
:  40%|      | 74561/186688 [00:03<00:02, 38165.72 examples/s]Converting format of dataset (num_proc=64):  33%|      | 62505/186688 [00:03<00:03, 34452.84 examples/s]Converting format of dataset (num_proc=64):  29%|       | 53927/186688 [00:03<00:03, 38956.60 examples/s]Converting format of dataset (num_proc=64):  38%|      | 70820/186688 [00:03<00:02, 40718.13 examples/s]Converting format of dataset (num_proc=64):  33%|      | 62266/186688 [00:04<00:05, 21898.93 examples/s]Converting format of dataset (num_proc=64):  44%|     | 82422/186688 [00:04<00:04, 21350.70 examples/s]Converting format of dataset (num_proc=64):  42%|     | 78745/186688 [00:05<00:07, 13721.31 examples/s]Converting format of dataset (num_proc=64):  47%|     | 88129/186688 [00:05<00:07, 12741.90 examples/s]Converting format of dataset (num_proc=64):  49%|     | 92336/186688 [00:06<00:08, 11338.34 examples/s]Convertsrun: error: della-j15g3: task 3: Exited with exit code 1
et (num_proc=64):  35%|      | 64435/186688 [00:02<00:03, 30844.16 examples/s]Converting format of dataset (num_proc=64):  34%|      | 62763/186688 [00:03<00:07, 15593.06 examples/s]Converting format of dataset (num_proc=64):  40%|      | 74463/186688 [00:03<00:06, 17077.07 examples/s]Converting format of dataset (num_proc=64):  38%|      | 71554/186688 [00:04<00:08, 14252.14 examples/s]Converting format of dataset (num_proc=64):  42%|     | 77648/186688 [00:04<00:06, 15728.61 examples/s]Converting format of dataset (num_proc=64):  44%|     | 81332/186688 [00:04<00:08, 12962.68 examples/s]Converting format of dataset (num_proc=64):  44%|     | 82660/186688 [00:05<00:08, 11819.46 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86173/186688 [00:05<00:09, 10617.24 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86284/186688 [00:06<00:09, 10370.08c=64):  41%|      | 75647/186688 [00:03<00:01, 75782.02 examples/s]Converting format of dataset (num_proc=64):  14%|        | 25985/186688 [00:03<00:09, 17513.69 examples/s]Converting format of dataset (num_proc=64):   8%|         | 15324/186688 [00:03<00:16, 10225.20 examples/s]Converting format of dataset (num_proc=64):  14%|        | 26957/186688 [00:03<00:07, 20897.84 examples/s]Converting format of dataset (num_proc=64):  19%|        | 35076/186688 [00:03<00:06, 24339.74 examples/s]Converting format of dataset (num_proc=64):  23%|       | 43336/186688 [00:04<00:10, 13824.72 examples/s]Converting format of dataset (num_proc=64):  48%|     | 90007/186688 [00:04<00:03, 25723.73 examples/s]Converting format of dataset (num_proc=64):  19%|        | 34613/186688 [00:04<00:15, 10126.63 examples/s]Converting format of dataset (num_proc=64):  22%|       | 40214/186688 [00:05<00:11, 12926.83 examples/s]Converting format of dataset (nuting format of dataset (num_proc=64):  51%|     | 95511/186688 [00:03<00:01, 68982.93 examples/s]Converting format of dataset (num_proc=64):  34%|      | 63901/186688 [00:04<00:05, 22598.01 examples/s]Converting format of dataset (num_proc=64):  70%|   | 131612/186688 [00:04<00:02, 26962.25 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106188/186688 [00:05<00:03, 25958.51 examples/s]Converting format of dataset (num_proc=64):  38%|      | 71087/186688 [00:05<00:07, 15311.48 examples/s]Converting format of dataset (num_proc=64):  61%|    | 114290/186688 [00:05<00:03, 18818.99 examples/s]Converting format of dataset (num_proc=64):  41%|      | 76864/186688 [00:06<00:07, 14554.17 examples/s]Converting format of dataset (num_proc=64):  43%|     | 80823/186688 [00:06<00:08, 12879.22 examples/s]Converting format of dataset (num_proc=64):  64%|   at of dataset (num_proc=64):  54%|    | 100597/186688 [00:02<00:00, 87273.54 examples/s]Converting format of dataset (num_proc=64):  26%|       | 49256/186688 [00:02<00:02, 47910.33 examples/s]Converting format of dataset (num_proc=64):  33%|      | 61784/186688 [00:02<00:02, 48286.91 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115835/186688 [00:02<00:01, 53751.57 examples/s]Converting format of dataset (num_proc=64):  38%|      | 71715/186688 [00:03<00:05, 20732.90 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127002/186688 [00:04<00:02, 21215.12 examples/s]Converting format of dataset (num_proc=64):  42%|     | 78425/186688 [00:04<00:07, 13760.86 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134837/186688 [00:05<00:03, 14772.27 examples/s]Converting format of dataset (num_proc=64):  45%|     | 8320set (num_proc=64):  43%|     | 80587/186688 [00:04<00:04, 21993.44 examples/s]Converting format of dataset (num_proc=64):   8%|         | 14180/186688 [00:04<00:36, 4712.33 examples/s]Converting format of dataset (num_proc=64):   8%|         | 15247/186688 [00:05<00:56, 3018.42 examples/s]Converting format of dataset (num_proc=64):  47%|     | 88591/186688 [00:05<00:06, 16308.24 examples/s]Converting format of dataset (num_proc=64):   9%|         | 16006/186688 [00:06<01:09, 2467.60 examples/s]Converting format of dataset (num_proc=64):  51%|     | 94322/186688 [00:06<00:06, 14179.58 examples/s]Converting format of dataset (num_proc=64):   9%|         | 16564/186688 [00:06<01:17, 2184.35 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98537/186688 [00:06<00:06, 13068.59 examples/s]Converting format of dataset (num_proc=64):   9%|         | 16991/186688 [00:06<01:24, 2015.48 examples/s]Converting format of m_proc=64):  26%|       | 48986/186688 [00:05<00:15, 8826.41 examples/s] Converting format of dataset (num_proc=64):  54%|    | 100115/186688 [00:06<00:05, 15759.71 examples/s]Converting format of dataset (num_proc=64):  28%|       | 53109/186688 [00:06<00:15, 8826.22 examples/s]Converting format of dataset (num_proc=64):  24%|       | 45396/186688 [00:06<00:19, 7352.31 examples/s] Converting format of dataset (num_proc=64):  30%|       | 56257/186688 [00:06<00:14, 8776.77 examples/s]Converting format of dataset (num_proc=64):  34%|      | 63473/186688 [00:06<00:09, 12998.94 examples/s]Converting format of dataset (num_proc=64):  36%|      | 68117/186688 [00:07<00:07, 15821.67 examples/s]Converting format of dataset (num_proc=64):  26%|       | 49379/186688 [00:07<00:17, 7689.70 examples/s]Converting format of dataset (num_proc=64):  42%|     | 79145/186688 [00:07<00:04, 26094.38 examples/s]Convertin| 119908/186688 [00:06<00:04, 14916.89 examples/s]Converting format of dataset (num_proc=64):  45%|     | 83829/186688 [00:07<00:09, 10995.02 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124927/186688 [00:06<00:04, 15077.51 examples/s]Converting format of dataset (num_proc=64):  49%|     | 91447/186688 [00:07<00:05, 15926.24 examples/s]Converting format of dataset (num_proc=64):  75%|  | 140063/186688 [00:07<00:01, 25086.39 examples/s]Converting format of dataset (num_proc=64):  51%|     | 95446/186688 [00:07<00:05, 17354.06 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143530/186688 [00:07<00:03, 13524.80 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147084/186688 [00:07<00:01, 26987.59 examples/s]W1003 11:36:17.316000 3121958 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3proc=64):  36%|      | 67687/186688 [00:04<00:05, 20362.65 examples/s]Converting format of dataset (num_proc=64):  37%|      | 70005/186688 [00:05<00:08, 13855.01 examples/s]Converting format of dataset (num_proc=64):  22%|       | 41501/186688 [00:05<00:15, 9263.09 examples/s] Converting format of dataset (num_proc=64):  40%|      | 73986/186688 [00:05<00:08, 12956.58 examples/s]Converting format of dataset (num_proc=64):  40%|      | 75129/186688 [00:06<00:10, 10532.38 examples/s]Converting format of dataset (num_proc=64):  42%|     | 78494/186688 [00:06<00:10, 10244.12 examples/s]Converting format of dataset (num_proc=64):  42%|     | 78849/186688 [00:07<00:12, 8642.44 examples/s] Converting format of dataset (num_proc=64):  44%|     | 81800/186688 [00:07<00:12, 8389.62 examples/s] Converting format of dataset (num_proc=64):  26%|       | 48741/186688 [00:07<00:20, 6786.49 examples/s]Conv examples/s]Converting format of dataset (num_proc=64):  48%|     | 89652/186688 [00:06<00:10, 9327.80 examples/s] Converting format of dataset (num_proc=64):  48%|     | 88991/186688 [00:06<00:10, 9240.52 examples/s] Converting format of dataset (num_proc=64):  49%|     | 92221/186688 [00:06<00:11, 8536.98 examples/s]Converting format of dataset (num_proc=64):  49%|     | 91043/186688 [00:07<00:11, 8415.50 examples/s]Converting format of dataset (num_proc=64):  50%|     | 94170/186688 [00:07<00:11, 8001.94 examples/s]Converting format of dataset (num_proc=64):  50%|     | 92634/186688 [00:07<00:12, 7755.38 examples/s]Converting format of dataset (num_proc=64):  51%|    | 95695/186688 [00:07<00:11, 7702.44 examples/s]Converting format of dataset (num_proc=64):  52%|    | 96942/186688 [00:07<00:12, 7402.29 examples/s]Converting format of dataset (num_proc=64):  50%|122031 closing signal SIGTERM
2/186688 [00:06<00:11, 9169.13 examples/s] Converting format of dataset (num_proc=64):  75%|  | 140423/186688 [00:06<00:03, 12196.94 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86676/186688 [00:06<00:12, 8010.52 examples/s]Converting format of dataset (num_proc=64):  77%|  | 144486/186688 [00:06<00:03, 10844.56 examples/s]Converting format of dataset (num_proc=64):  48%|     | 89174/186688 [00:07<00:13, 7114.24 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147510/186688 [00:07<00:03, 9885.80 examples/s] Converting format of dataset (num_proc=64):  80%|  | 149806/186688 [00:07<00:03, 9244.70 examples/s]Converting format of dataset (num_proc=64):  49%|     | 91037/186688 [00:07<00:14, 6387.69 examples/s]Converting format of dataset (num_proc=64):  50%|     | 92445/186688 [00:08<00:13, 6773.79 examples/s]Convedataset (num_proc=64):  54%|    | 101739/186688 [00:06<00:06, 12363.06 examples/s]Converting format of dataset (num_proc=64):   9%|         | 17334/186688 [00:07<01:30, 1872.81 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104259/186688 [00:07<00:06, 11836.94 examples/s]Converting format of dataset (num_proc=64):   9%|         | 17605/186688 [00:07<01:34, 1796.31 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106295/186688 [00:07<00:07, 11404.66 examples/s]Converting format of dataset (num_proc=64):  10%|         | 17843/186688 [00:07<01:39, 1699.47 examples/s]Converting format of dataset (num_proc=64):  58%|    | 107997/186688 [00:07<00:07, 11067.63 examples/s]Converting format of dataset (num_proc=64):  10%|         | 18044/186688 [00:07<01:41, 1666.92 examples/s]Converting format of dataset (num_proc=64):  59%|    | 109470/186688 [00:07<00:07, 10730.63 exampleing format of dataset (num_proc=64):  45%|     | 84355/186688 [00:06<00:10, 9866.91 examples/s] Converting format of dataset (num_proc=64):  37%|      | 68279/186688 [00:06<00:13, 8777.30 examples/s] Converting format of dataset (num_proc=64):  51%|     | 95429/186688 [00:07<00:09, 9226.47 examples/s] Converting format of dataset (num_proc=64):  47%|     | 88585/186688 [00:07<00:11, 8524.66 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98059/186688 [00:07<00:10, 8487.43 examples/s]Converting format of dataset (num_proc=64):  53%|    | 99838/186688 [00:07<00:10, 8475.39 examples/s]Converting format of dataset (num_proc=64):  39%|      | 72806/186688 [00:07<00:15, 7210.56 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101341/186688 [00:08<00:10, 7929.21 examples/s]Converting format of dataset (num_proc=64):  49%|     | 91543/1866     | 93901/186688 [00:07<00:12, 7331.89 examples/s]Converting format of dataset (num_proc=64):  52%|    | 97992/186688 [00:07<00:12, 7190.35 examples/s]Converting format of dataset (num_proc=64):  51%|     | 94956/186688 [00:07<00:13, 6928.60 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98910/186688 [00:08<00:12, 6954.85 examples/s]Converting format of dataset (num_proc=64):  51%|    | 95842/186688 [00:08<00:13, 6688.06 examples/s]Converting format of dataset (num_proc=64):  53%|    | 99724/186688 [00:08<00:12, 6717.04 examples/s]Converting format of dataset (num_proc=64):  52%|    | 96902/186688 [00:08<00:12, 7189.23 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98466/186688 [00:08<00:10, 8514.16 examples/s]Converting format of dataset (num_proc=64):  54%|    | 100465/186688 [00:08<00:13, 6612.17 examples/s]ConvertiW1003 11:36:17.318000 3121958 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3122032 closing signal SIGTERM
s/s]Converting format of dataset (num_proc=64):  10%|         | 18229/186688 [00:07<01:46, 1580.95 examples/s]Converting format of dataset (num_proc=64):  10%|         | 18399/186688 [00:07<01:47, 1563.09 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110775/186688 [00:07<00:07, 10448.25 examples/s]Converting format of dataset (num_proc=64):  10%|         | 19267/186688 [00:08<00:57, 2887.37 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111964/186688 [00:08<00:07, 10121.70 examples/s]Converting format of dataset (num_proc=64):  11%|         | 19638/186688 [00:08<00:55, 3012.05 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113063/186688 [00:08<00:07, 9892.51 examples/s] Converting format of dataset (num_proc=64):  11%|         | 20706/186688 [00:08<00:35, 4654.88 examples/s]Converting format of dataset (num_proc=64):  61%|    | 114102/186688 [00:08<00:07, 96erting format of dataset (num_proc=64):  29%|       | 53559/186688 [00:07<00:16, 8001.42 examples/s]Converting format of dataset (num_proc=64):  44%|     | 81574/186688 [00:07<00:13, 7600.29 examples/s]Converting format of dataset (num_proc=64):  45%|     | 83611/186688 [00:08<00:12, 8223.41 examples/s]Converting format of dataset (num_proc=64):  31%|       | 58217/186688 [00:08<00:14, 8996.10 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86047/186688 [00:08<00:10, 9414.32 examples/s]Converting format of dataset (num_proc=64):  35%|      | 65860/186688 [00:08<00:09, 12788.47 examples/s]Converting format of dataset (num_proc=64):  47%|     | 88128/186688 [00:08<00:12, 8031.53 examples/s]Converting format of dataset (num_proc=64):  38%|      | 70495/186688 [00:08<00:10, 11066.31 examples/s]Converting format of dataset (num_proc=64):  48%|     | 89735/186688 [00:08<00:88 [00:08<00:12, 7361.72 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102563/186688 [00:08<00:11, 7173.76 examples/s]Converting format of dataset (num_proc=64):  41%|      | 75858/186688 [00:08<00:16, 6917.03 examples/s]Converting format of dataset (num_proc=64):  56%|    | 103670/186688 [00:08<00:10, 7575.80 examples/s]Converting format of dataset (num_proc=64):  50%|     | 93728/186688 [00:08<00:12, 7243.71 examples/s]Converting format of dataset (num_proc=64):  42%|     | 78314/186688 [00:08<00:14, 7279.32 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104694/186688 [00:08<00:12, 6688.58 examples/s]Converting format of dataset (num_proc=64):  51%|    | 95950/186688 [00:08<00:11, 7761.40 examples/s]Converting format of dataset (num_proc=64):  43%|     | 80351/186688 [00:08<00:13, 7639.64 examples/s]Converting format of dataset (num_ng format of dataset (num_proc=64):  53%|    | 99632/186688 [00:08<00:09, 9089.61 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101166/186688 [00:08<00:13, 6367.95 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101239/186688 [00:08<00:08, 10384.89 examples/s]Converting format of dataset (num_proc=64):  55%|    | 101821/186688 [00:08<00:13, 6197.61 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102460/186688 [00:08<00:08, 9402.78 examples/s] Converting format of dataset (num_proc=64):  55%|    | 102456/186688 [00:08<00:14, 5833.05 examples/s]Converting format of dataset (num_proc=64):  55%|    | 103040/186688 [00:08<00:14, 5731.22 examples/s]Converting format of dataset (num_proc=64):  55%|    | 103541/186688 [00:08<00:10, 7975.51 examples/s]Converting format of dataset (num_proc=64):  55%|g format of dataset (num_proc=64):  35%|      | 65968/186688 [00:07<00:07, 16786.01 examples/s]Converting format of dataset (num_proc=64):  48%|     | 89214/186688 [00:07<00:02, 36161.10 examples/s]Converting format of dataset (num_proc=64):  44%|     | 82950/186688 [00:07<00:03, 28403.59 examples/s]Converting format of dataset (num_proc=64):  57%|    | 107275/186688 [00:07<00:07, 11180.56 examples/s]Converting format of dataset (num_proc=64):  52%|    | 96902/186688 [00:07<00:03, 28108.31 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112382/186688 [00:08<00:08, 9159.29 examples/s] Converting format of dataset (num_proc=64):  50%|     | 93083/186688 [00:09<00:06, 13567.04 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102489/186688 [00:09<00:08, 10511.32 examples/s]Converting format of dataset (num_proc=64):  62%|  W1003 11:36:17.319000 3121958 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3122033 closing signal SIGTERM
rting format of dataset (num_proc=64):  81%|  | 151596/186688 [00:08<00:03, 8791.96 examples/s]Converting format of dataset (num_proc=64):  82%| | 153053/186688 [00:08<00:03, 8459.83 examples/s]Converting format of dataset (num_proc=64):  50%|     | 93794/186688 [00:08<00:15, 6147.71 examples/s]Converting format of dataset (num_proc=64):  51%|     | 95629/186688 [00:08<00:12, 7181.52 examples/s]Converting format of dataset (num_proc=64):  83%| | 154376/186688 [00:08<00:03, 8498.11 examples/s]Converting format of dataset (num_proc=64):  54%|    | 100077/186688 [00:08<00:07, 10956.23 examples/s]Converting format of dataset (num_proc=64):  85%| | 158333/186688 [00:08<00:02, 11658.89 examples/s]W1003 11:36:18.615000 1593089 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1593152 closing signal SIGTERM
66.00 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115094/186688 [00:08<00:07, 9489.74 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116062/186688 [00:08<00:07, 9356.45 examples/s]Converting format of dataset (num_proc=64):  12%|        | 21943/186688 [00:08<00:40, 4063.90 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117010/186688 [00:08<00:07, 9208.16 examples/s]Converting format of dataset (num_proc=64):  17%|        | 31677/186688 [00:08<00:07, 20482.54 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117937/186688 [00:08<00:07, 9101.33 examples/s]Converting format of dataset (num_proc=64):  19%|        | 34863/186688 [00:08<00:06, 21751.68 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118856/186688 [00:08<00:07, 8938.37 examples/s]Converting format of dataset (num_proc=64):  27%|13, 7010.66 examples/s]Converting format of dataset (num_proc=64):  49%|     | 90985/186688 [00:09<00:15, 6360.04 examples/s]Converting format of dataset (num_proc=64):  49%|     | 91992/186688 [00:09<00:15, 6153.94 examples/s]Converting format of dataset (num_proc=64):  50%|     | 92852/186688 [00:09<00:16, 5628.67 examples/s]Converting format of dataset (num_proc=64):  40%|      | 73932/186688 [00:09<00:14, 8007.51 examples/s] Converting format of dataset (num_proc=64):  50%|     | 93574/186688 [00:09<00:17, 5389.81 examples/s]Converting format of dataset (num_proc=64):  50%|     | 94211/186688 [00:09<00:17, 5141.67 examples/s]Converting format of dataset (num_proc=64):  51%|     | 94787/186688 [00:10<00:18, 4915.39 examples/s]Converting format of dataset (num_proc=64):  51%|     | 95310/186688 [00:10<00:19, 4747.19 examples/s]Converting format of dataset (num_proc=64):  51%|proc=64):  52%|    | 97822/186688 [00:08<00:10, 8591.19 examples/s]Converting format of dataset (num_proc=64):  57%|    | 105543/186688 [00:08<00:13, 6109.16 examples/s]Converting format of dataset (num_proc=64):  44%|     | 82710/186688 [00:09<00:11, 8837.26 examples/s]Converting format of dataset (num_proc=64):  53%|    | 99696/186688 [00:08<00:09, 9592.96 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106262/186688 [00:09<00:14, 5562.61 examples/s]Converting format of dataset (num_proc=64):  46%|     | 85492/186688 [00:09<00:10, 9638.70 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101419/186688 [00:09<00:09, 9405.84 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106884/186688 [00:09<00:14, 5462.61 examples/s]Converting format of dataset (num_proc=64):  48%|     | 89519/186688 [00:09<00:07,     | 103609/186688 [00:08<00:14, 5600.13 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104193/186688 [00:09<00:14, 5625.34 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104462/186688 [00:09<00:11, 7275.45 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104756/186688 [00:09<00:14, 5593.85 examples/s]Converting format of dataset (num_proc=64):  56%|    | 105273/186688 [00:09<00:12, 6771.41 examples/s]Converting format of dataset (num_proc=64):  56%|    | 105321/186688 [00:09<00:14, 5587.55 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106012/186688 [00:09<00:12, 6486.51 examples/s]Converting format of dataset (num_proc=64):  57%|    | 105881/186688 [00:09<00:14, 5485.02 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106555/186688 [00:09<00:13, 5789.87 examples/s | 116069/186688 [00:09<00:08, 8355.32 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118803/186688 [00:09<00:08, 7895.34 examples/s]Converting format of dataset (num_proc=64):  57%|    | 107137/186688 [00:09<00:08, 9470.62 examples/s] Converting format of dataset (num_proc=64):  65%|   | 120888/186688 [00:10<00:08, 7539.28 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122518/186688 [00:10<00:08, 7248.67 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110146/186688 [00:10<00:09, 7923.09 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123832/186688 [00:10<00:08, 7024.01 examples/s]Converting format of dataset (num_proc=64):  54%|    | 100217/186688 [00:10<00:09, 8863.37 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112391/186688 [00:10<00:09, 7846.19 examplesE1003 11:36:17.422000 3121958 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 3122030) of binary: /scratch/gpfs/yl7690/.conda/envs/oss/bin/python3.1
W1003 11:36:18.617000 1593089 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1593153 closing signal SIGTERM
       | 50385/186688 [00:08<00:02, 50369.55 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119749/186688 [00:08<00:07, 8671.63 examples/s]Converting format of dataset (num_proc=64):  65%|   | 120621/186688 [00:09<00:07, 8439.44 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121466/186688 [00:09<00:07, 8250.72 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122293/186688 [00:09<00:07, 8076.84 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123103/186688 [00:09<00:08, 7857.06 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123890/186688 [00:09<00:08, 7812.31 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124680/186688 [00:09<00:08, 7727.18 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125455/186688 [00:09<00:07    | 95808/186688 [00:10<00:20, 4501.21 examples/s]Converting format of dataset (num_proc=64):  41%|      | 76434/186688 [00:10<00:16, 6580.03 examples/s]Converting format of dataset (num_proc=64):  52%|    | 96502/186688 [00:10<00:18, 4999.89 examples/s]Converting format of dataset (num_proc=64):  52%|    | 97030/186688 [00:10<00:19, 4667.85 examples/s]Converting format of dataset (num_proc=64):  52%|    | 97514/186688 [00:10<00:20, 4452.35 examples/s]Converting format of dataset (num_proc=64):  52%|    | 97972/186688 [00:10<00:20, 4324.39 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98413/186688 [00:10<00:21, 4188.09 examples/s]Converting format of dataset (num_proc=64):  42%|     | 78279/186688 [00:10<00:18, 5763.68 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98836/186688 [00:11<00:21, 4150.97 examples/s]Convert13055.67 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102870/186688 [00:09<00:08, 10043.37 examples/s]Converting format of dataset (num_proc=64):  58%|    | 107472/186688 [00:09<00:15, 5100.41 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108055/186688 [00:09<00:15, 5214.41 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104663/186688 [00:09<00:09, 8585.09 examples/s] Converting format of dataset (num_proc=64):  58%|    | 108606/186688 [00:09<00:16, 4845.64 examples/s]Converting format of dataset (num_proc=64):  58%|    | 109102/186688 [00:09<00:16, 4811.63 examples/s]Converting format of dataset (num_proc=64):  49%|     | 91898/186688 [00:09<00:09, 9624.59 examples/s] Converting format of dataset (num_proc=64):  59%|    | 109597/186688 [00:09<00:16, 4591.10 examples/s]Converting format of dataset (num_p]Converting format of dataset (num_proc=64):  57%|    | 106700/186688 [00:09<00:13, 5987.72 examples/s]Converting format of dataset (num_proc=64):  57%|    | 107141/186688 [00:09<00:13, 5794.89 examples/s]Converting format of dataset (num_proc=64):  58%|    | 107383/186688 [00:09<00:12, 6157.58 examples/s]Converting format of dataset (num_proc=64):  58%|    | 107722/186688 [00:09<00:14, 5573.99 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108020/186688 [00:09<00:13, 5955.14 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108286/186688 [00:09<00:14, 5553.91 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108630/186688 [00:09<00:13, 5891.60 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108891/186688 [00:09<00:13, 5650.12 examples/s]Converting format of dataset (num_proc=64):  59%|W1003 11:36:24.410000 3710044 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1003 11:36:24.411000 3710044 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3710108 closing signal SIGTERM
/s]Converting format of dataset (num_proc=64):  67%|   | 124923/186688 [00:10<00:09, 6755.23 examples/s]Converting format of dataset (num_proc=64):  62%|   | 114834/186688 [00:11<00:08, 8659.61 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125845/186688 [00:11<00:09, 6623.46 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126667/186688 [00:11<00:09, 6334.39 examples/s]Converting format of dataset (num_proc=64):  63%|   | 116781/186688 [00:11<00:08, 8633.26 examples/s]Converting format of dataset (num_proc=64):  56%|    | 105321/186688 [00:11<00:09, 8929.53 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127397/186688 [00:11<00:09, 6055.47 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118673/186688 [00:11<00:07, 8851.18 examples/s]Converting format of dataset (num_procTraceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
W1003 11:36:18.664000 1593089 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1593154 closing signal SIGTERM
, 7707.24 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126230/186688 [00:09<00:07, 7568.42 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126987/186688 [00:09<00:08, 7318.97 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127722/186688 [00:10<00:08, 7109.28 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128440/186688 [00:10<00:08, 6889.92 examples/s]Converting format of dataset (num_proc=64):  69%|   | 129217/186688 [00:10<00:08, 7082.85 examples/s]Converting format of dataset (num_proc=64):  70%|   | 129974/186688 [00:10<00:07, 7183.74 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130800/186688 [00:10<00:07, 7415.62 examples/s]Converting format of dataset (num_proc=64):  70%|   | 131558/186688 [00:10<00:07, 7434.41 examples/s]Converting format ing format of dataset (num_proc=64):  53%|    | 99264/186688 [00:11<00:21, 4024.12 examples/s]Converting format of dataset (num_proc=64):  53%|    | 99677/186688 [00:11<00:21, 4010.59 examples/s]Converting format of dataset (num_proc=64):  54%|    | 100429/186688 [00:11<00:17, 4969.90 examples/s]Converting format of dataset (num_proc=64):  43%|     | 79666/186688 [00:11<00:20, 5203.60 examples/s]Converting format of dataset (num_proc=64):  54%|    | 100937/186688 [00:11<00:19, 4494.77 examples/s]Converting format of dataset (num_proc=64):  43%|     | 80735/186688 [00:11<00:20, 5180.28 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101401/186688 [00:11<00:20, 4198.07 examples/s]Converting format of dataset (num_proc=64):  55%|    | 101836/186688 [00:11<00:20, 4125.84 examples/s]Converting format of dataset (num_proc=64):  55%|    roc=64):  57%|    | 105852/186688 [00:09<00:11, 6836.66 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110059/186688 [00:10<00:17, 4447.71 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110509/186688 [00:10<00:17, 4459.02 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110960/186688 [00:10<00:17, 4435.75 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106793/186688 [00:10<00:13, 5988.61 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111410/186688 [00:10<00:17, 4376.31 examples/s]Converting format of dataset (num_proc=64):  50%|     | 93717/186688 [00:10<00:12, 7156.95 examples/s]Converting format of dataset (num_proc=64):  58%|    | 107573/186688 [00:10<00:14, 5436.69 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111855/186688 [00:10<    | 109233/186688 [00:09<00:13, 5871.95 examples/s]Converting format of dataset (num_proc=64):  59%|    | 109601/186688 [00:09<00:12, 6046.23 examples/s]Converting format of dataset (num_proc=64):  59%|    | 109827/186688 [00:10<00:13, 5829.88 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110216/186688 [00:10<00:13, 5820.43 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110449/186688 [00:10<00:12, 5923.28 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110802/186688 [00:10<00:13, 5729.26 examples/s]Converting format of dataset (num_proc=64):  59%|    | 111050/186688 [00:10<00:12, 5858.75 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111380/186688 [00:10<00:13, 5654.87 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111646/186688 [00:10<00:12, 5787.49 eW1003 11:36:24.511000 3710044 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3710109 closing signal SIGTERM
W1003 11:36:24.512000 3710044 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3710110 closing signal SIGTERM
=64):  69%|   | 128055/186688 [00:11<00:10, 5789.55 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119992/186688 [00:11<00:07, 8643.72 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128659/186688 [00:11<00:10, 5496.83 examples/s]Converting format of dataset (num_proc=64):  69%|   | 129215/186688 [00:11<00:10, 5300.12 examples/s]Converting format of dataset (num_proc=64):  58%|    | 109157/186688 [00:11<00:09, 8605.78 examples/s]Converting format of dataset (num_proc=64):  69%|   | 129747/186688 [00:11<00:10, 5214.59 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121155/186688 [00:11<00:08, 7513.69 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130265/186688 [00:11<00:11, 5072.59 examples/s]Converting format of dataset (num_proc=64):  65%|   | 12210    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
E1003 11:36:18.755000 1593089 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1593151) of binary: /scratch/gpfs/yl7690/.conda/envs/oss/bin/python3.1
of dataset (num_proc=64):  71%|   | 132305/186688 [00:10<00:07, 7055.20 examples/s]Converting format of dataset (num_proc=64):  71%|  | 133018/186688 [00:10<00:07, 6876.10 examples/s]Converting format of dataset (num_proc=64):  72%|  | 133709/186688 [00:10<00:07, 6836.04 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134400/186688 [00:11<00:07, 6670.08 examples/s]Converting format of dataset (num_proc=64):  31%|       | 57099/186688 [00:11<00:14, 9238.07 examples/s] Converting format of dataset (num_proc=64):  72%|  | 135148/186688 [00:11<00:07, 6896.77 examples/s]Converting format of dataset (num_proc=64):  73%|  | 135998/186688 [00:11<00:06, 7300.41 examples/s]Converting format of dataset (num_proc=64):  73%|  | 136798/186688 [00:11<00:06, 7501.56 examples/s]Converting format of dataset (num_proc=64):  74%|| 102258/186688 [00:11<00:21, 4006.50 examples/s]Converting format of dataset (num_proc=64):  44%|     | 81638/186688 [00:11<00:21, 4813.38 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102665/186688 [00:11<00:21, 3898.37 examples/s]Converting format of dataset (num_proc=64):  55%|    | 103082/186688 [00:12<00:21, 3882.07 examples/s]Converting format of dataset (num_proc=64):  44%|     | 82369/186688 [00:12<00:22, 4581.37 examples/s]Converting format of dataset (num_proc=64):  55%|    | 103505/186688 [00:12<00:21, 3949.30 examples/s]Converting format of dataset (num_proc=64):  44%|     | 82984/186688 [00:12<00:23, 4385.28 examples/s]Converting format of dataset (num_proc=64):  56%|    | 103902/186688 [00:12<00:21, 3915.60 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104326/186688 [00:12<00:20, 3991.24 examples/s]Converting form00:17, 4286.37 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112284/186688 [00:10<00:17, 4232.61 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108233/186688 [00:10<00:15, 4996.05 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112725/186688 [00:10<00:17, 4233.73 examples/s]Converting format of dataset (num_proc=64):  51%|     | 95096/186688 [00:10<00:15, 5992.12 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113154/186688 [00:10<00:17, 4113.37 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108807/186688 [00:10<00:16, 4602.11 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113579/186688 [00:10<00:17, 4133.75 examples/s]Converting format of dataset (num_proc=64):  59%|    | 109313/186688 [00:10<00:17, 4303.35 examples/s]Converting format of dataset (nuxamples/s]Converting format of dataset (num_proc=64):  60%|    | 111948/186688 [00:10<00:13, 5620.47 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112284/186688 [00:10<00:12, 5939.53 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112741/186688 [00:10<00:11, 6253.19 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112899/186688 [00:10<00:12, 5999.45 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113370/186688 [00:10<00:11, 6247.68 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113520/186688 [00:10<00:12, 6015.08 examples/s]Converting format of dataset (num_proc=64):  61%|    | 114009/186688 [00:10<00:11, 6232.25 examples/s]Converting format of dataset (num_proc=64):  61%|    | 114136/186688 [00:10<00:11, 6054.94 examples/s]Converting format of dataset (num_proc=64):  W1003 11:36:24.575000 3710044 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3710111 closing signal SIGTERM
0/186688 [00:12<00:09, 6795.99 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130775/186688 [00:12<00:11, 4968.20 examples/s]Converting format of dataset (num_proc=64):  70%|   | 131269/186688 [00:12<00:11, 4960.82 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122902/186688 [00:12<00:10, 6174.65 examples/s]Converting format of dataset (num_proc=64):  71%|   | 131761/186688 [00:12<00:11, 4859.76 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132244/186688 [00:12<00:11, 4742.14 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123594/186688 [00:12<00:11, 5687.88 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132737/186688 [00:12<00:11, 4746.42 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112176/186688 [00:12<00:10, 7431.45 examples/s]    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
  | 137553/186688 [00:11<00:06, 7427.64 examples/s]Converting format of dataset (num_proc=64):  74%|  | 138302/186688 [00:11<00:06, 7379.85 examples/s]Converting format of dataset (num_proc=64):  74%|  | 139043/186688 [00:11<00:06, 7311.46 examples/s]Converting format of dataset (num_proc=64):  75%|  | 139780/186688 [00:11<00:06, 7168.32 examples/s]Converting format of dataset (num_proc=64):  75%|  | 140499/186688 [00:11<00:06, 6958.35 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141200/186688 [00:11<00:06, 6901.39 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141895/186688 [00:12<00:06, 6748.84 examples/s]Converting format of dataset (num_proc=64):  76%|  | 142573/186688 [00:12<00:06, 6674.19 examples/s]Converting format of dataset (num_proc=64):  77%|  | 1at of dataset (num_proc=64):  45%|     | 83530/186688 [00:12<00:24, 4250.63 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104730/186688 [00:12<00:20, 4001.30 examples/s]Converting format of dataset (num_proc=64):  45%|     | 84023/186688 [00:12<00:24, 4118.58 examples/s]Converting format of dataset (num_proc=64):  56%|    | 105349/186688 [00:12<00:17, 4605.31 examples/s]Converting format of dataset (num_proc=64):  45%|     | 84472/186688 [00:12<00:24, 4133.67 examples/s]Converting format of dataset (num_proc=64):  57%|    | 105817/186688 [00:12<00:17, 4598.14 examples/s]Converting format of dataset (num_proc=64):  45%|     | 84911/186688 [00:12<00:24, 4135.32 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106278/186688 [00:12<00:17, 4491.85 examples/s]Converting format of dataset (num_proc=64):  46%|     | 85348/186688m_proc=64):  61%|    | 114012/186688 [00:10<00:17, 4173.04 examples/s]Converting format of dataset (num_proc=64):  59%|    | 109765/186688 [00:10<00:18, 4159.06 examples/s]Converting format of dataset (num_proc=64):  61%|   | 114463/186688 [00:11<00:16, 4261.58 examples/s]Converting format of dataset (num_proc=64):  52%|    | 96160/186688 [00:11<00:17, 5310.71 examples/s]Converting format of dataset (num_proc=64):  62%|   | 114892/186688 [00:11<00:16, 4237.24 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110195/186688 [00:11<00:18, 4039.95 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115317/186688 [00:11<00:17, 4188.05 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110602/186688 [00:11<00:19, 3954.82 examples/s]Converting format of dataset (num_proc=64):  52%|    | 97007/186661%|   | 114635/186688 [00:10<00:11, 6207.15 examples/s]Converting format of dataset (num_proc=64):  61%|   | 114746/186688 [00:10<00:12, 5976.28 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115258/186688 [00:10<00:11, 6142.47 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115353/186688 [00:10<00:11, 5958.83 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115877/186688 [00:11<00:11, 6071.75 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115957/186688 [00:11<00:12, 5865.10 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116489/186688 [00:11<00:11, 5930.55 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116546/186688 [00:11<00:11, 5859.89 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117087/186Converting format of dataset (num_proc=64):  67%|   | 124207/186688 [00:12<00:11, 5440.29 examples/s]Converting format of dataset (num_proc=64):  71%|  | 133226/186688 [00:12<00:11, 4754.17 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124768/186688 [00:12<00:11, 5164.77 examples/s]Converting format of dataset (num_proc=64):  72%|  | 133708/186688 [00:12<00:11, 4675.37 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125902/186688 [00:12<00:09, 6374.83 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134182/186688 [00:12<00:11, 4603.25 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134642/186688 [00:12<00:11, 4555.95 examples/s]Converting format of dataset (num_proc=64):  61%|    | 114335/186688 [00:13<00:10, 7055.98 examples/s]Converting format of dataset (num    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-03_11:36:17
  host      : della-j17g1
  rank      : 24 (local_rank: 0)
  exitcode  : 1 (pid: 3122030)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
43245/186688 [00:12<00:06, 6633.36 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143915/186688 [00:12<00:06, 6639.08 examples/s]Converting format of dataset (num_proc=64):  77%|  | 144587/186688 [00:12<00:06, 6635.11 examples/s]Converting format of dataset (num_proc=64):  78%|  | 145252/186688 [00:12<00:06, 6599.32 examples/s]Converting format of dataset (num_proc=64):  78%|  | 145914/186688 [00:12<00:06, 6557.21 examples/s]Converting format of dataset (num_proc=64):  79%|  | 146574/186688 [00:12<00:06, 6534.62 examples/s]Converting format of dataset (num_proc=64):  33%|      | 61890/186688 [00:12<00:20, 6027.49 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147229/186688 [00:12<00:06, 6439.82 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147890/186688 [00:12<00:05, 6475.5 [00:12<00:24, 4103.48 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106729/186688 [00:12<00:18, 4294.94 examples/s]Converting format of dataset (num_proc=64):  46%|     | 85770/186688 [00:12<00:24, 4083.05 examples/s]Converting format of dataset (num_proc=64):  57%|    | 107185/186688 [00:13<00:18, 4369.63 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86190/186688 [00:13<00:25, 3991.21 examples/s]Converting format of dataset (num_proc=64):  58%|    | 107624/186688 [00:13<00:19, 4073.76 examples/s]Converting format of dataset (num_proc=64):  46%|     | 86700/186688 [00:13<00:23, 4266.53 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108043/186688 [00:13<00:19, 4105.01 examples/s]Converting format of dataset (num_proc=64):  47%|     | 87140/186688 [00:13<00:23, 4153.72 examples/s]Converting format of dataset (num88 [00:11<00:18, 4854.17 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115744/186688 [00:11<00:17, 4123.62 examples/s]Converting format of dataset (num_proc=64):  59%|    | 111002/186688 [00:11<00:20, 3757.37 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116163/186688 [00:11<00:17, 4112.78 examples/s]Converting format of dataset (num_proc=64):  52%|    | 97915/186688 [00:11<00:18, 4884.80 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111854/186688 [00:11<00:15, 4884.19 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116582/186688 [00:11<00:17, 4118.60 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112554/186688 [00:11<00:13, 5395.54 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117004/186688 [00:11<00:17, 4043.52 examples/s]Converting f688 [00:11<00:12, 5661.43 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117133/186688 [00:11<00:12, 5661.82 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117667/186688 [00:11<00:12, 5684.58 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117708/186688 [00:11<00:12, 5679.94 examples/s]Converting format of dataset (num_proc=64):  63%|   | 118241/186688 [00:11<00:12, 5671.70 examples/s]Converting format of dataset (num_proc=64):  63%|   | 118314/186688 [00:11<00:11, 5721.45 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118858/186688 [00:11<00:11, 5773.09 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118936/186688 [00:11<00:11, 5831.05 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119437/186688 [00:11<00:11, 5770.61 examples/s]Co_proc=64):  68%|   | 126603/186688 [00:13<00:10, 5809.86 examples/s]Converting format of dataset (num_proc=64):  72%|  | 135105/186688 [00:13<00:11, 4574.13 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127237/186688 [00:13<00:10, 5593.09 examples/s]Converting format of dataset (num_proc=64):  73%|  | 135646/186688 [00:13<00:10, 4786.67 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116160/186688 [00:13<00:09, 7186.11 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127824/186688 [00:13<00:10, 5468.26 examples/s]Converting format of dataset (num_proc=64):  73%|  | 136163/186688 [00:13<00:10, 4892.86 examples/s]Converting format of dataset (num_proc=64):  73%|  | 136661/186688 [00:13<00:10, 4790.10 examples/s]Converting format of dataset (num_proc=64):  69%|    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
5 examples/s]Converting format of dataset (num_proc=64):  80%|  | 148542/186688 [00:13<00:05, 6453.30 examples/s]Converting format of dataset (num_proc=64):  80%|  | 149210/186688 [00:13<00:05, 6447.09 examples/s]Converting format of dataset (num_proc=64):  80%|  | 149887/186688 [00:13<00:05, 6540.14 examples/s]Converting format of dataset (num_proc=64):  81%|  | 150545/186688 [00:13<00:05, 6519.91 examples/s]Converting format of dataset (num_proc=64):  81%|  | 151264/186688 [00:13<00:05, 6698.80 examples/s]Converting format of dataset (num_proc=64):  81%| | 151941/186688 [00:13<00:05, 6644.12 examples/s]Converting format of dataset (num_proc=64):  82%| | 152611/186688 [00:13<00:05, 6551.73 examples/s]Converting format of dataset (num_proc=64):  82%| | 153268/186688 [00:13<00:05, 6540.39 examples/s]Conv_proc=64):  59%|    | 109570/186688 [00:13<00:10, 7252.45 examples/s]Converting format of dataset (num_proc=64):  47%|     | 87634/186688 [00:13<00:22, 4329.47 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110823/186688 [00:13<00:08, 8728.98 examples/s]Converting format of dataset (num_proc=64):  47%|     | 88387/186688 [00:13<00:19, 5169.36 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111717/186688 [00:13<00:10, 7212.25 examples/s]Converting format of dataset (num_proc=64):  48%|     | 88916/186688 [00:13<00:19, 4925.83 examples/s]Converting format of dataset (num_proc=64):  52%|    | 96414/186688 [00:13<00:03, 23884.67 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112500/186688 [00:13<00:12, 5989.63 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113176/186688 [00:13<00:1ormat of dataset (num_proc=64):  53%|    | 98554/186688 [00:11<00:19, 4480.93 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113124/186688 [00:11<00:15, 4784.81 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117412/186688 [00:11<00:17, 3989.66 examples/s]Converting format of dataset (num_proc=64):  53%|    | 99095/186688 [00:11<00:20, 4218.35 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117823/186688 [00:11<00:17, 4020.25 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113633/186688 [00:11<00:16, 4541.99 examples/s]Converting format of dataset (num_proc=64):  63%|   | 118227/186688 [00:11<00:17, 3989.13 examples/s]Converting format of dataset (num_proc=64):  53%|    | 99578/186688 [00:12<00:22, 3953.00 examples/s]Converting format of dataset (num_proc=64):  61%|nverting format of dataset (num_proc=64):  64%|   | 119530/186688 [00:11<00:11, 5797.30 examples/s]Converting format of dataset (num_proc=64):  64%|   | 120089/186688 [00:11<00:11, 5951.24 examples/s]Converting format of dataset (num_proc=64):  64%|   | 120158/186688 [00:11<00:11, 5930.17 examples/s]Converting format of dataset (num_proc=64):  65%|   | 120685/186688 [00:11<00:11, 5929.64 examples/s]Converting format of dataset (num_proc=64):  65%|   | 120753/186688 [00:11<00:11, 5916.92 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121287/186688 [00:11<00:11, 5884.68 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121346/186688 [00:11<00:11, 5886.73 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121880/186688 [00:12<00:11, 5818.39 examples/s]Converting format of dataset (num_proc=64)   | 128391/186688 [00:13<00:11, 5081.04 examples/s]Converting format of dataset (num_proc=64):  73%|  | 137184/186688 [00:13<00:10, 4830.98 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128913/186688 [00:13<00:11, 4953.37 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117575/186688 [00:13<00:10, 6513.02 examples/s]Converting format of dataset (num_proc=64):  74%|  | 137675/186688 [00:13<00:10, 4843.70 examples/s]Converting format of dataset (num_proc=64):  69%|   | 129417/186688 [00:13<00:11, 4874.44 examples/s]Converting format of dataset (num_proc=64):  74%|  | 138169/186688 [00:13<00:09, 4854.47 examples/s]Converting format of dataset (num_proc=64):  70%|   | 129916/186688 [00:13<00:11, 4891.26 examples/s]Converting format of dataset (num_proc=64):  74%|  | 138670/186688 [00:13<0    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
erting format of dataset (num_proc=64):  83%| | 154087/186688 [00:13<00:04, 6998.70 examples/s]Converting format of dataset (num_proc=64):  83%| | 154879/186688 [00:14<00:04, 7208.05 examples/s]Converting format of dataset (num_proc=64):  35%|      | 65325/186688 [00:14<00:24, 4928.40 examples/s]Converting format of dataset (num_proc=64):  83%| | 155693/186688 [00:14<00:04, 7470.40 examples/s]Converting format of dataset (num_proc=64):  84%| | 156464/186688 [00:14<00:04, 7494.58 examples/s]Converting format of dataset (num_proc=64):  84%| | 157217/186688 [00:14<00:03, 7504.09 examples/s]Converting format of dataset (num_proc=64):  85%| | 157989/186688 [00:14<00:03, 7567.45 examples/s]Converting format of dataset (num_proc=64):  85%| | 158801/186688 [00:14<00:03, 7602.24 examples/s]W1003 11:36:24.406000 233, 5285.32 examples/s]Converting format of dataset (num_proc=64):  53%|    | 98917/186688 [00:14<00:06, 13629.29 examples/s]Converting format of dataset (num_proc=64):  61%|    | 113763/186688 [00:14<00:15, 4807.43 examples/s]Converting format of dataset (num_proc=64):  61%|    | 114292/186688 [00:14<00:15, 4646.96 examples/s]Converting format of dataset (num_proc=64):  61%|   | 114782/186688 [00:14<00:16, 4293.57 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101100/186688 [00:14<00:07, 10799.02 examples/s]slurmstepd: error: *** STEP 1159090.0 ON della-j12g2 CANCELLED AT 2025-10-03T11:36:24 ***
    | 114113/186688 [00:11<00:17, 4252.22 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118629/186688 [00:12<00:17, 3990.93 examples/s]Converting format of dataset (num_proc=64):  54%|    | 100704/186688 [00:12<00:16, 5157.56 examples/s]Converting format of dataset (num_proc=64):  62%|   | 114870/186688 [00:12<00:14, 5060.93 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119045/186688 [00:12<00:16, 4035.75 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115410/186688 [00:12<00:14, 4943.57 examples/s]Converting format of dataset (num_proc=64):  54%|    | 101332/186688 [00:12<00:17, 4756.63 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119481/186688 [00:12<00:16, 4058.99 examples/s]Converting format of dataset (num_proc=64):  62%|   | 115924/186688 [00:12<00:14, 4736.45 :  65%|   | 121949/186688 [00:12<00:11, 5848.59 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122464/186688 [00:12<00:11, 5790.44 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122543/186688 [00:12<00:11, 5737.41 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123047/186688 [00:12<00:11, 5527.08 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123121/186688 [00:12<00:11, 5640.88 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123628/186688 [00:12<00:11, 5601.00 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123692/186688 [00:12<00:11, 5654.15 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124193/186688 [00:12<00:11, 5573.96 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124263/0:09, 4866.09 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119449/186688 [00:13<00:09, 6820.79 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132358/186688 [00:13<00:05, 10015.33 examples/s]Converting format of dataset (num_proc=64):  75%|  | 139169/186688 [00:13<00:09, 4880.73 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124218/186688 [00:13<00:05, 10728.02 examples/s]Converting format of dataset (num_proc=64):  75%|  | 139668/186688 [00:13<00:10, 4679.25 examples/s]Converting format of dataset (num_proc=64):  71%|  | 133403/186688 [00:14<00:07, 7566.25 examples/s] Converting format of dataset (num_proc=64):  75%|  | 140163/186688 [00:14<00:09, 4711.26 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126573/186688 [00:14<00:05, 10346.94 examples/s]Co    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-03_11:36:18
  host      : della-j15g3
  rank      : 12 (local_rank: 0)
  exitcode  : 1 (pid: 1593151)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
26342 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
Converting format of dataset (num_proc=64):  62%|   | 115229/186688 [00:14<00:16, 4252.66 examples/s]W1003 11:36:24.405000 2395334 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
examples/s]Converting format of dataset (num_proc=64):  64%|   | 119906/186688 [00:12<00:16, 4109.47 examples/s]Converting format of dataset (num_proc=64):  55%|    | 101888/186688 [00:12<00:19, 4364.70 examples/s]Converting format of dataset (num_proc=64):  62%|   | 116420/186688 [00:12<00:15, 4573.74 examples/s]Converting format of dataset (num_proc=64):  64%|   | 120318/186688 [00:12<00:16, 4033.29 examples/s]Converting format of dataset (num_proc=64):  63%|   | 116893/186688 [00:12<00:15, 4477.85 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102385/186688 [00:12<00:20, 4066.65 examples/s]Converting format of dataset (num_proc=64):  65%|   | 120733/186688 [00:12<00:16, 4044.52 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117350/186688 [00:12<00:15, 4386.71 examples/s]Converting format of dataset (nu186688 [00:12<00:11, 5530.75 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124752/186688 [00:12<00:11, 5568.78 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124822/186688 [00:12<00:11, 5487.15 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125310/186688 [00:12<00:11, 5479.73 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125400/186688 [00:12<00:11, 5509.67 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125883/186688 [00:12<00:10, 5541.24 examples/s]Converting format of dataset (num_proc=64):  67%|   | 126006/186688 [00:12<00:10, 5661.86 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126516/186688 [00:12<00:10, 5753.64 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126650/186688 [00:12<00:10, 5889.41 examples/s]nverting format of dataset (num_proc=64):  75%|  | 140639/186688 [00:14<00:10, 4547.08 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134273/186688 [00:14<00:08, 6481.12 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141179/186688 [00:14<00:09, 4712.55 examples/s]Converting format of dataset (num_proc=64):  72%|  | 135023/186688 [00:14<00:08, 5833.62 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141652/186688 [00:14<00:09, 4657.77 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128337/186688 [00:14<00:07, 8262.55 examples/s] Converting format of dataset (num_proc=64):  73%|  | 135682/186688 [00:14<00:09, 5478.73 examples/s]Converting format of dataset (num_proc=64):  76%|  | 142119/186688 [00:14<00:09, 4565.08 examples/s]Converting format of dataseConverting format of dataset (num_proc=64):  86%| | 159647/186688 [00:14<00:03, 7806.47 examples/s]W1003 11:36:24.567000 2326342 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2326406 closing signal SIGTERM
W1003 11:36:24.438000 2395334 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2395400 closing signal SIGTERM
m_proc=64):  65%|   | 121142/186688 [00:12<00:16, 3994.95 examples/s]Converting format of dataset (num_proc=64):  55%|    | 102827/186688 [00:12<00:21, 3891.62 examples/s]Converting format of dataset (num_proc=64):  63%|   | 117797/186688 [00:12<00:16, 4292.75 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121557/186688 [00:12<00:16, 4028.80 examples/s]Converting format of dataset (num_proc=64):  55%|    | 103237/186688 [00:12<00:22, 3783.11 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121983/186688 [00:12<00:15, 4078.57 examples/s]Converting format of dataset (num_proc=64):  63%|   | 118241/186688 [00:12<00:15, 4289.45 examples/s]Converting format of dataset (num_proc=64):  56%|    | 103628/186688 [00:12<00:22, 3733.62 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122Converting format of dataset (num_proc=64):  68%|   | 127097/186688 [00:13<00:10, 5736.76 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127245/186688 [00:13<00:10, 5634.90 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127673/186688 [00:13<00:10, 5613.52 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127821/186688 [00:13<00:10, 5519.25 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128237/186688 [00:13<00:10, 5468.40 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128376/186688 [00:13<00:10, 5484.89 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128785/186688 [00:13<00:10, 5459.48 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128930/186688 [00:13<00:10, 5453.58 examples/s]Converting format of dataset (num_proc=W1003 11:36:24.643000 2326342 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2326407 closing signal SIGTERM
W1003 11:36:24.469000 2395334 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2395401 closing signal SIGTERM
441/186688 [00:13<00:15, 4213.31 examples/s]Converting format of dataset (num_proc=64):  64%|   | 118674/186688 [00:12<00:16, 4102.02 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104010/186688 [00:13<00:22, 3739.80 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122880/186688 [00:13<00:14, 4256.03 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119115/186688 [00:13<00:16, 4142.58 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104392/186688 [00:13<00:22, 3626.99 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123310/186688 [00:13<00:15, 4130.54 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119539/186688 [00:13<00:16, 4047.60 examples/s]Converting format of dataset (num_proc=64):  56%|    | 104764/186688 [00:13<00:23, 3501.71 examples/s]C64):  69%|   | 129335/186688 [00:13<00:10, 5364.44 examples/s]Converting format of dataset (num_proc=64):  69%|   | 129484/186688 [00:13<00:10, 5440.61 examples/s]Converting format of dataset (num_proc=64):  70%|   | 129878/186688 [00:13<00:10, 5354.16 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130033/186688 [00:13<00:10, 5443.65 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130439/186688 [00:13<00:10, 5390.55 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130579/186688 [00:13<00:10, 5424.87 examples/s]Converting format of dataset (num_proc=64):  70%|   | 131005/186688 [00:13<00:10, 5466.14 examples/s]Converting format of dataset (num_proc=64):  70%|   | 131125/186688 [00:13<00:10, 5379.79 examples/s]Converting format of dataset (num_proc=64):  70%|   | 1315Converting format of dataset (num_proc=64):  86%| | 160437/186688 [00:14<00:03, 7664.26 examples/s]W1003 11:36:24.686000 2326342 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2326408 closing signal SIGTERM
W1003 11:36:24.500000 2395334 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2395402 closing signal SIGTERM
onverting format of dataset (num_proc=64):  66%|   | 123726/186688 [00:13<00:15, 4112.94 examples/s]Converting format of dataset (num_proc=64):  64%|   | 119956/186688 [00:13<00:16, 4075.12 examples/s]Converting format of dataset (num_proc=64):  56%|    | 105135/186688 [00:13<00:23, 3529.93 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124228/186688 [00:13<00:14, 4327.74 examples/s]Converting format of dataset (num_proc=64):  65%|   | 120443/186688 [00:13<00:15, 4257.65 examples/s]Converting format of dataset (num_proc=64):  57%|    | 105491/186688 [00:13<00:23, 3497.96 examples/s]Converting format of dataset (num_proc=64):  67%|   | 124667/186688 [00:13<00:14, 4226.56 examples/s]Converting format of dataset (num_proc=64):  65%|   | 120870/186688 [00:13<00:15, 4151.41 examples/s]Converting format of dataset (num_proc=64):  72/186688 [00:13<00:10, 5506.64 examples/s]Converting format of dataset (num_proc=64):  71%|   | 131683/186688 [00:13<00:10, 5413.50 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132132/186688 [00:13<00:09, 5496.35 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132350/186688 [00:13<00:09, 5783.30 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132732/186688 [00:14<00:09, 5642.22 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132930/186688 [00:14<00:09, 5744.22 examples/s]Converting format of dataset (num_proc=64):  71%|  | 133364/186688 [00:14<00:09, 5809.97 examples/s]Converting format of dataset (num_proc=64):  72%|  | 133565/186688 [00:14<00:09, 5865.91 examples/s]Converting format of dataset (num_proc=64):  72%|  | 133952/186688 [00:14<00:09, 5793.62 exW1003 11:36:24.815000 2326342 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2326409 closing signal SIGTERM
W1003 11:36:24.608000 2395334 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2395403 closing signal SIGTERM
57%|    | 105894/186688 [00:13<00:22, 3548.63 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125094/186688 [00:13<00:14, 4214.01 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121317/186688 [00:13<00:15, 4192.30 examples/s]Converting format of dataset (num_proc=64):  57%|    | 106353/186688 [00:13<00:20, 3835.07 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125520/186688 [00:13<00:14, 4157.39 examples/s]Converting format of dataset (num_proc=64):  65%|   | 121744/186688 [00:13<00:15, 4177.07 examples/s]Converting format of dataset (num_proc=64):  58%|    | 108574/186688 [00:13<00:08, 9001.16 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125975/186688 [00:13<00:14, 4267.17 examples/s]Converting format of dataset (num_proc=64):  65%|   | 122178/186688 [0amples/s]Converting format of dataset (num_proc=64):  72%|  | 134155/186688 [00:14<00:09, 5762.41 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134537/186688 [00:14<00:09, 5712.54 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134736/186688 [00:14<00:09, 5620.73 examples/s]Converting format of dataset (num_proc=64):  72%|  | 135116/186688 [00:14<00:09, 5712.18 examples/s]Converting format of dataset (num_proc=64):  72%|  | 135312/186688 [00:14<00:09, 5628.92 examples/s]W1003 11:36:24.405000 1177146 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
0:13<00:15, 4204.90 examples/s]Converting format of dataset (num_proc=64):  59%|    | 110501/186688 [00:13<00:06, 11932.21 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126404/186688 [00:13<00:14, 4179.76 examples/s]Converting format of dataset (num_proc=64):  66%|   | 122605/186688 [00:13<00:15, 4175.67 examples/s]Converting format of dataset (num_proc=64):  68%|   | 126826/186688 [00:14<00:14, 4178.74 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123031/186688 [00:14<00:15, 4151.41 examples/s]Converting format of dataset (num_proc=64):  68%|   | 127253/186688 [00:14<00:14, 4185.17 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123449/186688 [00:14<00:15, 4114.80 examples/s]Converting format of dataset (num_proc=64):  60%|    | 111728/186688 [00:14<00:10, 7464.12 examples/s] ConvertingConverting format of dataset (num_proc=64):  73%|  | 135720/186688 [00:14<00:08, 5797.24 examples/s]Converting format of dataset (num_proc=64):  73%|  | 135876/186688 [00:14<00:09, 5631.27 examples/s]W1003 11:36:24.447000 1177146 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1177206 closing signal SIGTERM
 format of dataset (num_proc=64):  68%|   | 127678/186688 [00:14<00:14, 4179.46 examples/s]Converting format of dataset (num_proc=64):  66%|   | 123863/186688 [00:14<00:15, 4083.83 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128132/186688 [00:14<00:13, 4231.06 examples/s]Converting format of dataset (num_proc=64):  67%|   | 125229/186688 [00:14<00:08, 6861.88 examples/s]Converting format of dataset (num_proc=64):  69%|   | 128599/186688 [00:14<00:13, 4314.19 examples/s]Converting format of dataset (num_proc=64):  60%|    | 112701/186688 [00:14<00:12, 6104.60 examples/s]W1003 11:36:24.405000 2877021 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1003 11:36:24.483000 1177146 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1177207 closing signal SIGTERM
W1003 11:36:24.441000 2877021 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2877081 closing signal SIGTERM
Converting format of dataset (num_proc=64):  73%|  | 136305/186688 [00:14<00:10, 4776.32 examples/s]W1003 11:36:24.520000 1177146 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1177208 closing signal SIGTERM
Converting format of dataset (num_proc=64):  67%|   | 125926/186688 [00:14<00:10, 6009.09 examples/s]W1003 11:36:24.472000 2877021 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2877082 closing signal SIGTERM
W1003 11:36:24.656000 1177146 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1177209 closing signal SIGTERM
Converting format of dataset (num_proc=64):  61%|    | 113513/186688 [00:14<00:11, 6329.24 examples/s]W1003 11:36:24.503000 2877021 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2877083 closing signal SIGTERM
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
Converting format of dataset (num_proc=64):  68%|   | 126550/186688 [00:14<00:12, 4655.71 examples/s]W1003 11:36:24.585000 2877021 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2877084 closing signal SIGTERM
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1177146 got signal: 15
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2877021 got signal: 15
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2395334 got signal: 15
t (num_proc=64):  76%|  | 142578/186688 [00:14<00:09, 4531.23 examples/s]Converting format of dataset (num_proc=64):  73%|  | 137172/186688 [00:14<00:07, 6952.25 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143040/186688 [00:14<00:09, 4464.85 examples/s]Converting format of dataset (num_proc=64):  74%|  | 137916/186688 [00:14<00:07, 6210.59 examples/s]Converting format of dataset (num_proc=64):  69%|   | 129709/186688 [00:14<00:08, 7098.19 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143496/186688 [00:14<00:09, 4421.98 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143944/186688 [00:14<00:09, 4284.59 examples/s]Converting format of dataset (num_proc=64):  74%|  | 138577/186688 [00:15<00:08, 5520.06 examples/s]Converting format of dataset (num_proc=64):  77%|Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 3710044 got signal: 15
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2326342 got signal: 15
srun: error: della-k11g1: task 7: Exited with exit code 1
  | 144386/186688 [00:15<00:10, 4190.06 examples/s]Converting format of dataset (num_proc=64):  70%|   | 130796/186688 [00:15<00:08, 6302.85 examples/s]Converting format of dataset (num_proc=64):  75%|  | 139159/186688 [00:15<00:09, 4971.55 examples/s]Converting format of dataset (num_proc=64):  78%|  | 144806/186688 [00:15<00:10, 4052.46 examples/s]Converting format of dataset (num_proc=64):  75%|  | 139684/186688 [00:15<00:10, 4677.13 examples/s]Converting format of dataset (num_proc=64):  78%|  | 145220/186688 [00:15<00:10, 3987.23 examples/s]Converting format of dataset (num_proc=64):  71%|   | 131681/186688 [00:15<00:09, 5683.10 examples/s]Converting format of dataset (num_proc=64):  78%|  | 145624/186688 [00:15<00:10, 3960.37 examples/s]Converting format of dataset (num_proc=64):  75%|  | 140164/186688 [00:15<00:10, 4372.73 examples/s]Converting format of dataset (num_proc=64):  78%|  | 146030/186688 [00:15<00:10, 3908.55 examples/s]Converting format of dataset (num_proc=64):  75%|  | 140610/186688 [00:15<00:10, 4336.95 examples/s]Converting format of dataset (num_proc=64):  71%|   | 132415/186688 [00:15<00:10, 5179.77 examples/s]Converting format of dataset (num_proc=64):  78%|  | 146427/186688 [00:15<00:10, 3879.77 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141054/186688 [00:15<00:10, 4157.16 examples/s]Converting format of dataset (num_proc=64):  71%|  | 133035/186688 [00:15<00:10, 4968.49 examples/s]Converting format of dataset (num_proc=64):  79%|  | 146817/186688 [00:15<00:10, 3831.44 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141481/186688 [00:15<00:11, 4096.48 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147224/186688 [00:15<00:10, 3872.91 examples/s]Converting format of dataset (num_proc=64):  72%|  | 133592/186688 [00:15<00:11, 4742.90 examples/s]Converting format of dataset (num_proc=64):  76%|  | 141912/186688 [00:15<00:10, 4138.41 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147641/186688 [00:15<00:09, 3924.59 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134099/186688 [00:15<00:11, 4624.54 examples/s]Converting format of dataset (num_proc=64):  76%|  | 142332/186688 [00:16<00:11, 4013.86 examples/s]Converting format of dataset (num_proc=64):  79%|  | 148037/186688 [00:16<00:09, 3914.90 examples/s][rank9]:[W1003 11:36:25.190065745 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=53, addr=[della-j15g2]:34280, remote=[della-j12g2]:29500): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x14d573e45eb0 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694d1 (0x14d5b58c74d1 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d6a8cd (0x14d5b58c88cd in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b47a (0x14d5b58c947a in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x14d5b58c419e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x14d574da9b18 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x14d5585efbf4 in /scratch/gpfs/yl7690/.conda/envs/oss/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8a19a (0x14d5d228a19a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10f240 (0x14d5d230f240 in /lib64/libc.so.6)

[rank10]:[W1003 11:36:25.188727658 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=53, addr=[della-j15g2]:34282, remote=[della-j12g2]:29500): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x146b2d5c3eb0 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694d1 (0x146b6f0454d1 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d6a8cd (0x146b6f0468cd in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b47a (0x146b6f04747a in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x146b6f04219e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x146b2e527b18 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x146b11d6dbf4 in /scratch/gpfs/yl7690/.conda/envs/oss/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8a19a (0x146b8b88a19a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10f240 (0x146b8b90f240 in /lib64/libc.so.6)

[rank11]:[W1003 11:36:25.189445833 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=53, addr=[della-j15g2]:34278, remote=[della-j12g2]:29500): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x14ad63b15eb0 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694d1 (0x14ada55974d1 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d6a8cd (0x14ada55988cd in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b47a (0x14ada559947a in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x14ada559419e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x14ad64a79b18 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x14ad482bfbf4 in /scratch/gpfs/yl7690/.conda/envs/oss/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8a19a (0x14adc1e8a19a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10f240 (0x14adc1f0f240 in /lib64/libc.so.6)

[rank9]:[W1003 11:36:25.218338126 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 9] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[rank11]:[W1003 11:36:25.219051197 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 11] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[rank10]:[W1003 11:36:25.219445863 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 10] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
srun: error: della-j16g3: task 5: Exited with exit code 1
srun: error: della-j16g1: task 4: Exited with exit code 1
srun: error: della-j12g2: task 0: Exited with exit code 1
Converting format of dataset (num_proc=64):  76%|  | 142738/186688 [00:16<00:10, 4020.87 examples/s]Converting format of dataset (num_proc=64):  72%|  | 134581/186688 [00:16<00:11, 4476.28 examples/s]Converting format of dataset (num_proc=64):  80%|  | 148455/186688 [00:16<00:09, 3979.55 examples/s]Converting format of dataset (num_proc=64):  77%|  | 143167/186688 [00:16<00:10, 4066.43 examples/s]Converting format of dataset (num_proc=64):  72%|  | 135045/186688 [00:16<00:11, 4451.55 examples/s]Converting format of dataset (num_proc=64):  77%|  | 144545/186688 [00:16<00:06, 6804.94 examples/s]Converting format of dataset (num_proc=64):  73%|  | 135502/186688 [00:16<00:11, 4406.33 examples/s]Converting format of dataset (num_proc=64):  73%|  | 135955/186688 [00:16<00:11, 4271.37 examples/s]Converting format of dasrun: error: della-j15g1: task 1: Exited with exit code 1
taset (num_proc=64):  78%|  | 145244/186688 [00:16<00:07, 5555.22 examples/s]Converting format of dataset (num_proc=64):  73%|  | 136385/186688 [00:16<00:12, 4179.76 examples/s]Converting format of dataset (num_proc=64):  79%|  | 146596/186688 [00:16<00:05, 7464.91 examples/s]Converting format of dataset (num_proc=64):  73%|  | 136807/186688 [00:16<00:12, 4100.97 examples/s]Converting format of dataset (num_proc=64):  74%|  | 138096/186688 [00:16<00:07, 6418.32 examples/s]Converting format of dataset (num_proc=64):  79%|  | 148250/186688 [00:16<00:04, 7930.49 examples/s]Converting format of dataset (num_proc=64):  79%|  | 147756/186688 [00:16<00:01, 31180.22 examples/s]Converting format of dataset (num_proc=64):  81%|  | 151495/186688 [00:16<00:02, 13572.40 examples/s][rank9]:[W1003 11:36:26.218501346 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=53, addr=[della-j15g2]:34280, remote=[della-j12g2]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x14d573e45eb0 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694d1 (0x14d5b58c74d1 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d62 (0x14d5b58c7d62 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b86e (0x14d5b58c986e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x14d5b58c418e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x14d574da9b18 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x14d5585efbf4 in /scratch/gpfs/yl7690/.conda/envs/oss/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8a19a (0x14d5d228a19a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10f240 (0x14d5d230f240 in /lib64/libc.so.6)

[rank9]:[W1003 11:36:26.222010050 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 9] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank11]:[W1003 11:36:26.219202706 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=53, addr=[della-j15g2]:34278, remote=[della-j12g2]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x14ad63b15eb0 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694d1 (0x14ada55974d1 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d62 (0x14ada5597d62 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b86e (0x14ada559986e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x14ada559418e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x14ad64a79b18 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x14ad482bfbf4 in /scratch/gpfs/yl7690/.conda/envs/oss/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8a19a (0x14adc1e8a19a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10f240 (0x14adc1f0f240 in /lib64/libc.so.6)

[rank11]:[W1003 11:36:26.222725784 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 11] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank10]:[W1003 11:36:26.219575996 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=53, addr=[della-j15g2]:34282, remote=[della-j12g2]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x146b2d5c3eb0 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694d1 (0x146b6f0454d1 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d62 (0x146b6f045d62 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b86e (0x146b6f04786e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x146b6f04218e in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x146b2e527b18 in /scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x146b11d6dbf4 in /scratch/gpfs/yl7690/.conda/envs/oss/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8a19a (0x146b8b88a19a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10f240 (0x146b8b90f240 in /lib64/libc.so.6)

[rank10]:[W1003 11:36:26.222983760 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 10] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Converting format of dataset (num_proc=64):  81%|  | 151173/186688 [00:17<00:01, 18242.94 examples/s]Converting format of dataset (num_proc=64):  82%| | 153040/186688 [00:17<00:03, 8516.88 examples/s] Converting format of dataset (num_proc=64):  80%|  | 148859/186688 [00:17<00:37, 998.12 examples/s] W1003 11:36:24.405000 3227167 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
Converting format of dataset (num_proc=64):  82%| | 153586/186688 [00:17<00:06, 5390.87 examples/s]Converting format of dataset (num_proc=64):  82%| | 153806/186688 [00:17<00:01, 17063.31 examples/s]Converting format of dataset (num_proc=64):  83%| | 154251/186688 [00:17<00:04, 6880.59 examples/s]Converting format of dataset (num_proc=64):  83%| | 155209/186688 [00:17<00:06, 4950.15 examples/s]Converting format of dataset (num_proc=64):  83%| | 155233/186688 [00:17<00:05, 5979.53 examples/s]W1003 11:36:27.196000 3227167 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3227246 closing signal SIGTERM
Converting format of dataset (num_proc=64):  84%| | 156046/186688 [00:17<00:05, 5462.37 examples/s]Converting format of dataset (num_proc=64):  84%| | 156077/186688 [00:17<00:03, 9711.64 examples/s] W1003 11:36:27.880000 3227167 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3227247 closing signal SIGTERM
W1003 11:36:27.909000 3227167 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3227248 closing signal SIGTERM
W1003 11:36:27.981000 3227167 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3227249 closing signal SIGTERM
Traceback (most recent call last):
  File "/scratch/gpfs/yl7690/.conda/envs/oss/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 3227167 got signal: 15
srun: error: della-j15g2: task 2: Exited with exit code 1
