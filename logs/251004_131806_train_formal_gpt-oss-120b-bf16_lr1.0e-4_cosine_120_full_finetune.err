+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
++ head -n 1
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=0 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=3 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=5 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=2 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=7 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ cd /scratch/gpfs/yl7690/projects/LLaMA-Factory-new
+ export WANDB_MODE=disabled
+ WANDB_MODE=disabled
+ export DISABLE_VERSION_CHECK=1
+ DISABLE_VERSION_CHECK=1
++ head -n 1
++ scontrol show hostnames 'della-j16g1,della-j17g1,della-k11g[1,3],della-k12g[2-3],della-k13g[1-2]'
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=1 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=6 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
+ torchrun --nproc_per_node=4 --nnodes=8 --node_rank=4 --master_addr=della-j16g1 --master_port=29500 src/train.py --model_name_or_path /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16 --trust_remote_code true --stage sft --do_train --finetuning_type full --deepspeed /scratch/gpfs/yl7690/projects/LLaMA-Factory-new/examples/deepspeed/ds_z3_offload_config.json --dataset formal --template gpt --cutoff_len 64000 --max_samples 100000000 --overwrite_cache true --preprocessing_num_workers 64 --dataloader_num_workers 64 --output_dir /scratch/gpfs/CHIJ/yong/trained_models/train_formal_gpt-oss-120b-bf16_lr1.0e-4_cosine_120_full_finetune --logging_steps 10 --save_steps 500 --plot_loss true --overwrite_output_dir true --save_only_model true --per_device_train_batch_size 1 --gradient_accumulation_steps 4 --learning_rate 1.0e-4 --num_train_epochs 1.0 --lr_scheduler_type cosine --warmup_ratio 0.1 --bf16 true --ddp_timeout 180000000 --flash_attn fa2 --enable_liger_kernel true
W1004 13:18:49.129000 1664696 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.129000 1664696 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.129000 1664696 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.129000 1664696 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.129000 3465244 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.129000 3465244 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.129000 3465244 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.129000 3465244 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.130000 26197 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.130000 26197 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.130000 26197 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.130000 26197 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.130000 3308396 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.130000 3308396 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.130000 3308396 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.130000 3308396 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.148000 203240 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.148000 203240 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.148000 203240 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.148000 203240 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.148000 2490363 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.148000 2490363 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.148000 2490363 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.148000 2490363 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.172000 3444440 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.172000 3444440 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.172000 3444440 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.172000 3444440 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.801000 3546028 site-packages/torch/distributed/run.py:774] 
W1004 13:18:49.801000 3546028 site-packages/torch/distributed/run.py:774] *****************************************
W1004 13:18:49.801000 3546028 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1004 13:18:49.801000 3546028 site-packages/torch/distributed/run.py:774] *****************************************
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,556 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,556 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,556 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,556 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,557 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,557 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,559 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,559 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,559 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,559 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,559 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,559 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,560 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,560 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,560 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,560 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,560 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,560 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,561 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,561 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,561 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,561 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,561 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,561 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,564 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,564 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,564 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,564 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,564 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,564 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,579 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,579 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,579 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,579 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,579 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,579 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,595 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,595 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,595 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,595 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,595 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,595 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,599 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,599 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,599 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,599 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,599 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:16,599 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,230 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,231 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,231 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,231 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,232 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,232 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,235 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,235 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,235 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,235 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,235 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,235 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,235 >> loading file chat_template.jinja
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,235 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file tokenizer.model
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,236 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file tokenizer_config.json
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,236 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,239 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,239 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,241 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,241 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,242 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,242 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,242 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,242 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,242 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,242 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,242 >> loading file chat_template.jinja
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,243 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,244 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,244 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,244 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,244 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,244 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,244 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,245 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,246 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,252 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,252 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,252 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,252 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,252 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,252 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,252 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,266 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,266 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,267 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2025-10-04 13:19:17,268 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,268 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,269 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,269 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,269 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,269 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,269 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,269 >> loading file chat_template.jinja
[INFO|configuration_utils.py:839] 2025-10-04 13:19:17,270 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,270 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,270 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,270 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,270 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,270 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-10-04 13:19:17,270 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,939 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,940 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,945 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,952 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,953 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,966 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,967 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|tokenization_utils_base.py:2337] 2025-10-04 13:19:17,975 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187211 examples [00:01, 365.28 examples/s]            Converting format of dataset (num_proc=64): 199946 examples [00:01, 11881.41 examples/s]Converting format of dataset (num_proc=64): 230957 examples [00:01, 46087.39 examples/s]Converting format of dataset (num_proc=64): 254626 examples [00:01, 72913.23 examples/s]Converting format of dataset (num_proc=64): 278252 examples [00:01, 100255.07 examples/s]Converting format of dataset (num_proc=64): 300275 examples [00:01, 122099.61 examples/s]Converting format of dataset (num_proc=64): 322203 examples [00:02, 142893.75 examples/s]Converting format of dataset (num_proc=64): 343715 examples [00:02, 149529.69 examples/s]Converting format of dataset (num_proc=64): 363808 examples [00:02, 118504.23 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:03, 50027.53 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187080 examples [00:01, 269.55 examples/s]            Converting format of dataset (num_proc=64): 201877 examples [00:01, 13477.11 examples/s]Converting format of dataset (num_proc=64): 230175 examples [00:01, 43951.52 examples/s]Converting format of dataset (num_proc=64): 251604 examples [00:01, 67611.69 examples/s]Converting format of dataset (num_proc=64): 274874 examples [00:01, 94776.64 examples/s]Converting format of dataset (num_proc=64): 300089 examples [00:01, 124845.43 examples/s]Converting format of dataset (num_proc=64): 322216 examples [00:02, 142924.56 examples/s]Converting format of dataset (num_proc=64): 343954 examples [00:02, 152996.19 examples/s]Converting format of dataset (num_proc=64): 364439 examples [00:02, 122847.86 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 46466.52 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 186714 examples [00:01, 16.30 examples/s]             Converting format of dataset (num_proc=64): 199857 examples [00:01, 10790.11 examples/s]Converting format of dataset (num_proc=64): 228022 examples [00:01, 39127.85 examples/s]Converting format of dataset (num_proc=64): 249293 examples [00:01, 61699.76 examples/s]Converting format of dataset (num_proc=64): 272029 examples [00:02, 87416.00 examples/s]Converting format of dataset (num_proc=64): 294092 examples [00:02, 111393.74 examples/s]Converting format of dataset (num_proc=64): 316112 examples [00:02, 133520.31 examples/s]Converting format of dataset (num_proc=64): 337498 examples [00:02, 147682.86 examples/s]Converting format of dataset (num_proc=64): 357923 examples [00:02, 156099.23 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44869.80 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187157 examples [00:01, 314.88 examples/s]            Converting format of dataset (num_proc=64): 194556 examples [00:01, 6758.48 examples/s]Converting format of dataset (num_proc=64): 215243 examples [00:01, 28910.42 examples/s]Converting format of dataset (num_proc=64): 243904 examples [00:01, 63968.45 examples/s]Converting format of dataset (num_proc=64): 262959 examples [00:01, 84550.42 examples/s]Converting format of dataset (num_proc=64): 292200 examples [00:01, 123400.38 examples/s]Converting format of dataset (num_proc=64): 314536 examples [00:02, 135209.54 examples/s]Converting format of dataset (num_proc=64): 338442 examples [00:02, 156322.14 examples/s]Converting format of dataset (num_proc=64): 359744 examples [00:02, 146784.07 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44767.08 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187100 examples [00:01, 262.70 examples/s]            Converting format of dataset (num_proc=64): 203341 examples [00:01, 13783.47 examples/s]Converting format of dataset (num_proc=64): 229593 examples [00:01, 40180.60 examples/s]Converting format of dataset (num_proc=64): 252611 examples [00:01, 65140.60 examples/s]Converting format of dataset (num_proc=64): 271873 examples [00:01, 85137.40 examples/s]Converting format of dataset (num_proc=64): 296712 examples [00:02, 115023.84 examples/s]Converting format of dataset (num_proc=64): 317824 examples [00:02, 127628.31 examples/s]Converting format of dataset (num_proc=64): 339942 examples [00:02, 148022.56 examples/s]Converting format of dataset (num_proc=64): 360491 examples [00:02, 127698.66 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44298.26 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187137 examples [00:01, 302.77 examples/s]            Converting format of dataset (num_proc=64): 195199 examples [00:01, 7355.47 examples/s]Converting format of dataset (num_proc=64): 214388 examples [00:01, 27869.14 examples/s]Converting format of dataset (num_proc=64): 243212 examples [00:01, 63564.88 examples/s]Converting format of dataset (num_proc=64): 265458 examples [00:01, 89579.52 examples/s]Converting format of dataset (num_proc=64): 290268 examples [00:01, 118931.20 examples/s]Converting format of dataset (num_proc=64): 311556 examples [00:02, 133545.67 examples/s]Converting format of dataset (num_proc=64): 331769 examples [00:02, 124126.41 examples/s]Converting format of dataset (num_proc=64): 359896 examples [00:02, 155708.28 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 44124.87 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187152 examples [00:01, 292.95 examples/s]            Converting format of dataset (num_proc=64): 197983 examples [00:01, 9229.12 examples/s]Converting format of dataset (num_proc=64): 227478 examples [00:01, 39378.44 examples/s]Converting format of dataset (num_proc=64): 249553 examples [00:01, 63138.13 examples/s]Converting format of dataset (num_proc=64): 275201 examples [00:01, 93488.40 examples/s]Converting format of dataset (num_proc=64): 296519 examples [00:02, 114576.93 examples/s]Converting format of dataset (num_proc=64): 317905 examples [00:02, 134616.62 examples/s]Converting format of dataset (num_proc=64): 339942 examples [00:02, 153470.24 examples/s]Converting format of dataset (num_proc=64): 361449 examples [00:02, 136487.28 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 43046.54 examples/s] 
Converting format of dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Converting format of dataset (num_proc=64): 187202 examples [00:01, 330.77 examples/s]            Converting format of dataset (num_proc=64): 214886 examples [00:01, 23564.92 examples/s]Converting format of dataset (num_proc=64): 236531 examples [00:01, 44152.32 examples/s]Converting format of dataset (num_proc=64): 265315 examples [00:01, 76119.32 examples/s]Converting format of dataset (num_proc=64): 290940 examples [00:01, 104151.80 examples/s]Converting format of dataset (num_proc=64): 314365 examples [00:02, 125994.08 examples/s]Converting format of dataset (num_proc=64): 337156 examples [00:03, 39075.52 examples/s] Converting format of dataset (num_proc=64): 352950 examples [00:03, 39116.66 examples/s]Converting format of dataset (num_proc=64): 373376 examples [00:04, 42821.41 examples/s]
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'json' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:13, 75.04 examples/s]             Running tokenizer on dataset (num_proc=64): 188688 examples [00:14, 163.99 examples/s]Running tokenizer on dataset (num_proc=64): 189688 examples [00:14, 281.58 examples/s]Running tokenizer on dataset (num_proc=64): 191688 examples [00:15, 594.26 examples/s]Running tokenizer on dataset (num_proc=64): 193688 examples [00:15, 963.82 examples/s]Running tokenizer on dataset (num_proc=64): 194688 examples [00:16, 1093.40 examples/s]Running tokenizer on dataset (num_proc=64): 196688 examples [00:16, 1557.37 examples/s]Running tokenizer on dataset (num_proc=64): 198688 examples [00:17, 1994.01 examples/s]Running tokenizer on dataset (num_proc=64): 202688 examples [00:17, 3246.07 examples/s]Running tokenizer on dataset (num_proc=64): 203688 examples [00:18, 2947.39 examples/s]Running tokenizerRunning tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:13, 74.16 examples/s]             Running tokenizer on dataset (num_proc=64): 188688 examples [00:13, 171.46 examples/s]Running tokenizer on dataset (num_proc=64): 189688 examples [00:14, 276.98 examples/s]Running tokenizer on dataset (num_proc=64): 190688 examples [00:15, 420.79 examples/s]Running tokenizer on dataset (num_proc=64): 192688 examples [00:15, 801.64 examples/s]Running tokenizer on dataset (num_proc=64): 193688 examples [00:16, 963.72 examples/s]Running tokenizer on dataset (num_proc=64): 195688 examples [00:16, 1424.50 examples/s]Running tokenizer on dataset (num_proc=64): 196688 examples [00:17, 1557.70 examples/s]Running tokenizer on dataset (num_proc=64): 198688 examples [00:17, 2066.65 examples/s]Running tokenizer on dataset (num_proc=64): 200688 examples [00:18, 2498.54 examples/s]Running tokenizer Running tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:14, 68.93 examples/s]             Running tokenizer on dataset (num_proc=64): 190688 examples [00:14, 352.15 examples/s]Running tokenizer on dataset (num_proc=64): 191688 examples [00:15, 451.45 examples/s]Running tokenizer on dataset (num_proc=64): 194688 examples [00:16, 892.87 examples/s]Running tokenizer on dataset (num_proc=64): 198688 examples [00:16, 1624.05 examples/s]Running tokenizer on dataset (num_proc=64): 200688 examples [00:17, 1957.72 examples/s]Running tokenizer on dataset (num_proc=64): 201688 examples [00:17, 1872.51 examples/s]Running tokenizer on dataset (num_proc=64): 204688 examples [00:18, 2493.79 examples/s]Running tokenizer on dataset (num_proc=64): 205688 examples [00:18, 2274.83 examples/s]Running tokenizer on dataset (num_proc=64): 206688 examples [00:19, 2113.67 examples/s]Running tokenizeRunning tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:14, 70.21 examples/s]             Running tokenizer on dataset (num_proc=64): 189688 examples [00:15, 245.39 examples/s]Running tokenizer on dataset (num_proc=64): 191688 examples [00:15, 475.26 examples/s]Running tokenizer on dataset (num_proc=64): 195688 examples [00:16, 1081.79 examples/s]Running tokenizer on dataset (num_proc=64): 196688 examples [00:16, 1177.26 examples/s]Running tokenizer on dataset (num_proc=64): 197688 examples [00:17, 1286.64 examples/s]Running tokenizer on dataset (num_proc=64): 199688 examples [00:17, 1710.56 examples/s]Running tokenizer on dataset (num_proc=64): 202688 examples [00:18, 2498.02 examples/s]Running tokenizer on dataset (num_proc=64): 205688 examples [00:19, 2612.15 examples/s]Running tokenizer on dataset (num_proc=64): 206688 examples [00:19, 2527.21 examples/s]Running tokenizRunning tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:14, 67.38 examples/s]             Running tokenizer on dataset (num_proc=64): 188688 examples [00:15, 156.12 examples/s]Running tokenizer on dataset (num_proc=64): 190688 examples [00:16, 369.13 examples/s]Running tokenizer on dataset (num_proc=64): 197688 examples [00:16, 1402.82 examples/s]Running tokenizer on dataset (num_proc=64): 201688 examples [00:17, 2045.22 examples/s]Running tokenizer on dataset (num_proc=64): 202688 examples [00:17, 2022.25 examples/s]Running tokenizer on dataset (num_proc=64): 204688 examples [00:18, 2306.54 examples/s]Running tokenizer on dataset (num_proc=64): 207688 examples [00:18, 2934.58 examples/s]Running tokenizer on dataset (num_proc=64): 208688 examples [00:19, 2944.67 examples/s]Running tokenizer on dataset (num_proc=64): 209688 examples [00:20, 2226.87 examples/s]Running tokenizRunning tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:13, 74.29 examples/s]             Running tokenizer on dataset (num_proc=64): 188688 examples [00:13, 171.34 examples/s]Running tokenizer on dataset (num_proc=64): 189688 examples [00:15, 273.53 examples/s]Running tokenizer on dataset (num_proc=64): 191688 examples [00:16, 493.19 examples/s]Running tokenizer on dataset (num_proc=64): 193688 examples [00:17, 809.55 examples/s]Running tokenizer on dataset (num_proc=64): 196688 examples [00:18, 1245.93 examples/s]Running tokenizer on dataset (num_proc=64): 198688 examples [00:18, 1583.16 examples/s]Running tokenizer on dataset (num_proc=64): 200688 examples [00:19, 1936.94 examples/s]Running tokenizer on dataset (num_proc=64): 207688 examples [00:19, 4061.96 examples/s]Running tokenizer on dataset (num_proc=64): 208688 examples [00:20, 3628.09 examples/s]Running tokenizerRunning tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:13, 72.93 examples/s]             Running tokenizer on dataset (num_proc=64): 188688 examples [00:14, 167.76 examples/s]Running tokenizer on dataset (num_proc=64): 189688 examples [00:16, 242.00 examples/s]Running tokenizer on dataset (num_proc=64): 195688 examples [00:17, 1023.23 examples/s]Running tokenizer on dataset (num_proc=64): 196688 examples [00:17, 1110.26 examples/s]Running tokenizer on dataset (num_proc=64): 198688 examples [00:18, 1430.00 examples/s]Running tokenizer on dataset (num_proc=64): 203688 examples [00:18, 2629.56 examples/s]Running tokenizer on dataset (num_proc=64): 205688 examples [00:19, 2829.99 examples/s]Running tokenizer on dataset (num_proc=64): 208688 examples [00:19, 3403.54 examples/s]Running tokenizer on dataset (num_proc=64): 212688 examples [00:20, 4362.64 examples/s]Running tokenizRunning tokenizer on dataset (num_proc=64): 100%|██████████| 186688/186688 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=64): 187688 examples [00:15, 66.44 examples/s]             Running tokenizer on dataset (num_proc=64): 188688 examples [00:15, 153.56 examples/s]Running tokenizer on dataset (num_proc=64): 189688 examples [00:16, 265.03 examples/s]Running tokenizer on dataset (num_proc=64): 194688 examples [00:16, 1034.11 examples/s]Running tokenizer on dataset (num_proc=64): 198688 examples [00:17, 1733.44 examples/s]Running tokenizer on dataset (num_proc=64): 199688 examples [00:17, 1754.44 examples/s]Running tokenizer on dataset (num_proc=64): 201688 examples [00:18, 1789.52 examples/s]Running tokenizer on dataset (num_proc=64): 204688 examples [00:19, 2424.40 examples/s]Running tokenizer on dataset (num_proc=64): 207688 examples [00:19, 3065.39 examples/s]Running tokenizer on dataset (num_proc=64): 210688 examples [00:20, 3610.42 examples/s]Running tokeniz on dataset (num_proc=64): 204688 examples [00:18, 2724.38 examples/s]Running tokenizer on dataset (num_proc=64): 206688 examples [00:19, 3050.26 examples/s]Running tokenizer on dataset (num_proc=64): 210688 examples [00:19, 4395.64 examples/s]Running tokenizer on dataset (num_proc=64): 211688 examples [00:20, 3715.23 examples/s]Running tokenizer on dataset (num_proc=64): 215688 examples [00:21, 3853.03 examples/s]Running tokenizer on dataset (num_proc=64): 216688 examples [00:21, 3421.44 examples/s]Running tokenizer on dataset (num_proc=64): 217688 examples [00:22, 2660.16 examples/s]Running tokenizer on dataset (num_proc=64): 218688 examples [00:23, 2559.81 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:24, 1948.73 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:24, 1840.40 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:28, 779.55 examples/s] Running tokenizer on dataset (num_proc=64): 222688 examples [00:28, 1017.on dataset (num_proc=64): 203688 examples [00:18, 3341.48 examples/s]Running tokenizer on dataset (num_proc=64): 204688 examples [00:19, 2891.93 examples/s]Running tokenizer on dataset (num_proc=64): 208688 examples [00:19, 4247.69 examples/s]Running tokenizer on dataset (num_proc=64): 209688 examples [00:20, 3653.72 examples/s]Running tokenizer on dataset (num_proc=64): 212688 examples [00:21, 4240.27 examples/s]Running tokenizer on dataset (num_proc=64): 214688 examples [00:21, 4202.86 examples/s]Running tokenizer on dataset (num_proc=64): 215688 examples [00:22, 3493.11 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:22, 4161.70 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:24, 2208.02 examples/s]Running tokenizer on dataset (num_proc=64): 222688 examples [00:24, 2628.10 examples/s]Running tokenizer on dataset (num_proc=64): 223688 examples [00:29, 945.87 examples/s] Running tokenizer on dataset (num_proc=64): 224688 examples [00:29, 1131.6er on dataset (num_proc=64): 213688 examples [00:20, 4111.48 examples/s]Running tokenizer on dataset (num_proc=64): 216688 examples [00:21, 4506.86 examples/s]Running tokenizer on dataset (num_proc=64): 217688 examples [00:21, 3810.23 examples/s]Running tokenizer on dataset (num_proc=64): 218688 examples [00:22, 3300.44 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:22, 2887.58 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:24, 2331.49 examples/s]Running tokenizer on dataset (num_proc=64): 222688 examples [00:27, 948.21 examples/s] Running tokenizer on dataset (num_proc=64): 223688 examples [00:28, 1093.12 examples/s]Running tokenizer on dataset (num_proc=64): 224688 examples [00:28, 1190.76 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:29, 1328.42 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:29, 1626.83 examples/s]Running tokenizer on dataset (num_proc=64): 227688 examples [00:29, 178r on dataset (num_proc=64): 211688 examples [00:20, 3938.84 examples/s]Running tokenizer on dataset (num_proc=64): 214688 examples [00:20, 4175.82 examples/s]Running tokenizer on dataset (num_proc=64): 215688 examples [00:21, 3562.92 examples/s]Running tokenizer on dataset (num_proc=64): 217688 examples [00:22, 2555.19 examples/s]Running tokenizer on dataset (num_proc=64): 218688 examples [00:23, 2261.46 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:24, 1684.09 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:25, 1618.83 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:25, 1789.26 examples/s]Running tokenizer on dataset (num_proc=64): 223688 examples [00:26, 1788.02 examples/s]Running tokenizer on dataset (num_proc=64): 224688 examples [00:27, 1643.43 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:28, 1423.75 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:29, 1098er on dataset (num_proc=64): 211688 examples [00:20, 2732.43 examples/s]Running tokenizer on dataset (num_proc=64): 212688 examples [00:20, 2813.67 examples/s]Running tokenizer on dataset (num_proc=64): 215688 examples [00:21, 3715.59 examples/s]Running tokenizer on dataset (num_proc=64): 217688 examples [00:21, 3767.08 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:23, 2920.89 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:24, 2530.43 examples/s]Running tokenizer on dataset (num_proc=64): 222688 examples [00:24, 2678.53 examples/s]Running tokenizer on dataset (num_proc=64): 223688 examples [00:28, 874.21 examples/s] Running tokenizer on dataset (num_proc=64): 224688 examples [00:28, 1026.55 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:28, 1297.31 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:29, 1278.68 examples/s]Running tokenizer on dataset (num_proc=64): 227688 examples [00:30, 122 on dataset (num_proc=64): 211688 examples [00:20, 4103.28 examples/s]Running tokenizer on dataset (num_proc=64): 213688 examples [00:21, 3269.34 examples/s]Running tokenizer on dataset (num_proc=64): 217688 examples [00:22, 4260.15 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:22, 4146.38 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:23, 3581.61 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:23, 2944.19 examples/s]Running tokenizer on dataset (num_proc=64): 222688 examples [00:24, 2519.94 examples/s]Running tokenizer on dataset (num_proc=64): 223688 examples [00:27, 1186.50 examples/s]Running tokenizer on dataset (num_proc=64): 224688 examples [00:27, 1488.55 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:28, 1179.46 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:30, 936.88 examples/s] Running tokenizer on dataset (num_proc=64): 227688 examples [00:31, 974.0er on dataset (num_proc=64): 208688 examples [00:20, 2845.10 examples/s]Running tokenizer on dataset (num_proc=64): 210688 examples [00:20, 3113.69 examples/s]Running tokenizer on dataset (num_proc=64): 212688 examples [00:21, 3234.80 examples/s]Running tokenizer on dataset (num_proc=64): 213688 examples [00:21, 3602.59 examples/s]Running tokenizer on dataset (num_proc=64): 214688 examples [00:21, 3262.96 examples/s]Running tokenizer on dataset (num_proc=64): 217688 examples [00:22, 3854.47 examples/s]Running tokenizer on dataset (num_proc=64): 218688 examples [00:23, 2212.54 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:26, 1033.30 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:27, 1004.23 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:30, 703.49 examples/s] Running tokenizer on dataset (num_proc=64): 222688 examples [00:30, 904.32 examples/s]Running tokenizer on dataset (num_proc=64): 224688 examples [00:31, 1247er on dataset (num_proc=64): 213688 examples [00:20, 3773.15 examples/s]Running tokenizer on dataset (num_proc=64): 216688 examples [00:21, 4321.16 examples/s]Running tokenizer on dataset (num_proc=64): 219688 examples [00:21, 4772.80 examples/s]Running tokenizer on dataset (num_proc=64): 220688 examples [00:22, 2949.03 examples/s]Running tokenizer on dataset (num_proc=64): 221688 examples [00:28, 872.96 examples/s] Running tokenizer on dataset (num_proc=64): 223688 examples [00:28, 1149.59 examples/s]Running tokenizer on dataset (num_proc=64): 224688 examples [00:29, 1201.78 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:31, 996.67 examples/s] Running tokenizer on dataset (num_proc=64): 226688 examples [00:32, 1031.62 examples/s]Running tokenizer on dataset (num_proc=64): 227688 examples [00:32, 1316.95 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:32, 1550.33 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:32, 177.99 examples/s]Running tokenizer on dataset (num_proc=64): 227688 examples [00:30, 1395.12 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:30, 1742.76 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:30, 1864.98 examples/s]Running tokenizer on dataset (num_proc=64): 230688 examples [00:31, 2106.97 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:31, 2044.17 examples/s]Running tokenizer on dataset (num_proc=64): 232688 examples [00:31, 2581.46 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:32, 2804.18 examples/s]Running tokenizer on dataset (num_proc=64): 235688 examples [00:32, 4611.38 examples/s]Running tokenizer on dataset (num_proc=64): 236688 examples [00:32, 5193.42 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:33, 2618.69 examples/s]Running tokenizer on dataset (num_proc=64): 239688 examples [00:33, 3016.09 examples/s]Running tokenizer on dataset (num_proc=6.64 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:31, 1450.99 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:32, 1467.85 examples/s]Running tokenizer on dataset (num_proc=64): 227688 examples [00:32, 1743.19 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:32, 2223.24 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:33, 2665.48 examples/s]Running tokenizer on dataset (num_proc=64): 230688 examples [00:33, 3371.17 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:34, 1734.43 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:34, 2709.63 examples/s]Running tokenizer on dataset (num_proc=64): 235688 examples [00:35, 3547.92 examples/s]Running tokenizer on dataset (num_proc=64): 236688 examples [00:35, 3747.51 examples/s]Running tokenizer on dataset (num_proc=64): 237688 examples [00:35, 3301.31 examples/s]Running tokenizer on dataset (num_proc=623 examples/s]Running tokenizer on dataset (num_proc=64): 223688 examples [00:28, 1176.04 examples/s]Running tokenizer on dataset (num_proc=64): 224688 examples [00:29, 1300.82 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:30, 1169.78 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:30, 1360.92 examples/s]Running tokenizer on dataset (num_proc=64): 227688 examples [00:31, 1629.59 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:31, 1895.70 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:32, 1795.30 examples/s]Running tokenizer on dataset (num_proc=64): 230688 examples [00:33, 1243.85 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:34, 1177.92 examples/s]Running tokenizer on dataset (num_proc=64): 232688 examples [00:35, 1213.69 examples/s]Running tokenizer on dataset (num_proc=64): 234688 examples [00:35, 1795.37 examples/s]Running tokenizer on dataset (num_proc=642.64 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:31, 1228.94 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:31, 1446.65 examples/s]Running tokenizer on dataset (num_proc=64): 230688 examples [00:32, 1459.13 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:32, 1738.07 examples/s]Running tokenizer on dataset (num_proc=64): 232688 examples [00:33, 1558.27 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:33, 2001.55 examples/s]Running tokenizer on dataset (num_proc=64): 234688 examples [00:34, 2067.13 examples/s]Running tokenizer on dataset (num_proc=64): 235688 examples [00:34, 1851.93 examples/s]Running tokenizer on dataset (num_proc=64): 236688 examples [00:34, 2372.04 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:35, 3562.30 examples/s]Running tokenizer on dataset (num_proc=64): 239688 examples [00:35, 3760.24 examples/s]Running tokenizer on dataset (num_proc=8 examples/s]Running tokenizer on dataset (num_proc=64): 225688 examples [00:30, 1070.60 examples/s]Running tokenizer on dataset (num_proc=64): 226688 examples [00:32, 863.45 examples/s] Running tokenizer on dataset (num_proc=64): 227688 examples [00:32, 1019.04 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:34, 955.04 examples/s] Running tokenizer on dataset (num_proc=64): 229688 examples [00:34, 1021.32 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:35, 1674.90 examples/s]Running tokenizer on dataset (num_proc=64): 232688 examples [00:35, 2077.27 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:35, 2385.75 examples/s]Running tokenizer on dataset (num_proc=64): 235688 examples [00:36, 2659.23 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:36, 4549.63 examples/s]Running tokenizer on dataset (num_proc=64): 240688 examples [00:36, 5751.44 examples/s]Running tokenizer on dataset (num_proc=64)6 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:31, 1111.28 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:32, 1005.68 examples/s]Running tokenizer on dataset (num_proc=64): 230688 examples [00:34, 984.81 examples/s] Running tokenizer on dataset (num_proc=64): 231688 examples [00:34, 1238.75 examples/s]Running tokenizer on dataset (num_proc=64): 232688 examples [00:34, 1570.66 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:34, 2068.26 examples/s]Running tokenizer on dataset (num_proc=64): 234688 examples [00:35, 2096.54 examples/s]Running tokenizer on dataset (num_proc=64): 235688 examples [00:35, 2475.12 examples/s]Running tokenizer on dataset (num_proc=64): 236688 examples [00:36, 2040.73 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:36, 2389.92 examples/s]Running tokenizer on dataset (num_proc=64): 239688 examples [00:37, 1718.19 examples/s]Running tokenizer on dataset (num_proc=64)5.58 examples/s]Running tokenizer on dataset (num_proc=64): 228688 examples [00:31, 1136.21 examples/s]Running tokenizer on dataset (num_proc=64): 229688 examples [00:32, 1273.56 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:34, 1028.32 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:34, 1539.12 examples/s]Running tokenizer on dataset (num_proc=64): 234688 examples [00:35, 1815.04 examples/s]Running tokenizer on dataset (num_proc=64): 235688 examples [00:35, 2163.65 examples/s]Running tokenizer on dataset (num_proc=64): 236688 examples [00:35, 2553.84 examples/s]Running tokenizer on dataset (num_proc=64): 237688 examples [00:36, 1703.87 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:36, 2048.39 examples/s]Running tokenizer on dataset (num_proc=64): 239688 examples [00:37, 2333.44 examples/s]Running tokenizer on dataset (num_proc=64): 240688 examples [00:37, 2345.50 examples/s]Running tokenizer on dataset (num_proc=4): 240688 examples [00:34, 2048.52 examples/s]Running tokenizer on dataset (num_proc=64): 241688 examples [00:35, 2196.87 examples/s]Running tokenizer on dataset (num_proc=64): 242688 examples [00:35, 2283.53 examples/s]Running tokenizer on dataset (num_proc=64): 243688 examples [00:35, 2786.22 examples/s]Running tokenizer on dataset (num_proc=64): 244688 examples [00:36, 2729.10 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:36, 3041.14 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:36, 3025.07 examples/s]Running tokenizer on dataset (num_proc=64): 247688 examples [00:36, 2868.68 examples/s]Running tokenizer on dataset (num_proc=64): 248688 examples [00:37, 3399.28 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:38, 3006.83 examples/s]Running tokenizer on dataset (num_proc=64): 252688 examples [00:38, 3426.78 examples/s]Running tokenizer on dataset (num_proc=64): 253688 examples [00:38, 3826.96 examples/s]Running 0.40 examples/s]Running tokenizer on dataset (num_proc=64): 230688 examples [00:33, 1369.06 examples/s]Running tokenizer on dataset (num_proc=64): 231688 examples [00:34, 1722.05 examples/s]Running tokenizer on dataset (num_proc=64): 232688 examples [00:34, 1805.25 examples/s]Running tokenizer on dataset (num_proc=64): 233688 examples [00:34, 2278.61 examples/s]Running tokenizer on dataset (num_proc=64): 234688 examples [00:34, 2877.00 examples/s]Running tokenizer on dataset (num_proc=64): 236688 examples [00:35, 3617.34 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:35, 4217.10 examples/s]Running tokenizer on dataset (num_proc=64): 240688 examples [00:36, 3555.04 examples/s]Running tokenizer on dataset (num_proc=64): 241688 examples [00:36, 3807.72 examples/s]Running tokenizer on dataset (num_proc=64): 242688 examples [00:39, 1297.82 examples/s]Running tokenizer on dataset (num_proc=64): 243688 examples [00:40, 1224.91 examples/s]Running tokenizer on dataset (num_proc=4): 238688 examples [00:35, 3322.04 examples/s]Running tokenizer on dataset (num_proc=64): 240688 examples [00:36, 3991.47 examples/s]Running tokenizer on dataset (num_proc=64): 242688 examples [00:36, 3895.33 examples/s]Running tokenizer on dataset (num_proc=64): 244688 examples [00:37, 4825.76 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:37, 3815.37 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:37, 3717.12 examples/s]Running tokenizer on dataset (num_proc=64): 248688 examples [00:38, 3489.21 examples/s]Running tokenizer on dataset (num_proc=64): 249688 examples [00:39, 2290.28 examples/s]Running tokenizer on dataset (num_proc=64): 250688 examples [00:39, 2486.48 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:39, 2864.08 examples/s]Running tokenizer on dataset (num_proc=64): 253688 examples [00:40, 4159.82 examples/s]Running tokenizer on dataset (num_proc=64): 254688 examples [00:40, 3227.67 examples/s]Running ): 235688 examples [00:36, 1990.79 examples/s]Running tokenizer on dataset (num_proc=64): 237688 examples [00:36, 2616.21 examples/s]Running tokenizer on dataset (num_proc=64): 238688 examples [00:37, 1915.94 examples/s]Running tokenizer on dataset (num_proc=64): 240688 examples [00:39, 1628.80 examples/s]Running tokenizer on dataset (num_proc=64): 241688 examples [00:39, 1966.43 examples/s]Running tokenizer on dataset (num_proc=64): 243688 examples [00:39, 2733.98 examples/s]Running tokenizer on dataset (num_proc=64): 244688 examples [00:39, 2601.31 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:40, 2381.34 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:40, 2843.47 examples/s]Running tokenizer on dataset (num_proc=64): 247688 examples [00:40, 3505.44 examples/s]Running tokenizer on dataset (num_proc=64): 250688 examples [00:40, 6568.65 examples/s]Running tokenizer on dataset (num_proc=64): 252688 examples [00:41, 5515.18 examples/s]Running t: 242688 examples [00:36, 5850.25 examples/s]Running tokenizer on dataset (num_proc=64): 244688 examples [00:37, 3534.48 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:37, 3559.20 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:38, 3500.34 examples/s]Running tokenizer on dataset (num_proc=64): 247688 examples [00:38, 3767.80 examples/s]Running tokenizer on dataset (num_proc=64): 248688 examples [00:38, 4154.26 examples/s]Running tokenizer on dataset (num_proc=64): 249688 examples [00:38, 4489.98 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:39, 5434.03 examples/s]Running tokenizer on dataset (num_proc=64): 253688 examples [00:39, 5725.17 examples/s]Running tokenizer on dataset (num_proc=64): 255688 examples [00:39, 6737.55 examples/s]Running tokenizer on dataset (num_proc=64): 257688 examples [00:39, 6392.60 examples/s]Running tokenizer on dataset (num_proc=64): 259688 examples [00:40, 7101.63 examples/s]Running to64): 241688 examples [00:38, 2059.01 examples/s]Running tokenizer on dataset (num_proc=64): 242688 examples [00:38, 2634.23 examples/s]Running tokenizer on dataset (num_proc=64): 243688 examples [00:38, 3163.15 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:38, 5025.09 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:39, 3898.00 examples/s]Running tokenizer on dataset (num_proc=64): 249688 examples [00:40, 3480.69 examples/s]Running tokenizer on dataset (num_proc=64): 250688 examples [00:40, 3023.74 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:40, 3158.65 examples/s]Running tokenizer on dataset (num_proc=64): 252688 examples [00:41, 3231.80 examples/s]Running tokenizer on dataset (num_proc=64): 253688 examples [00:41, 2269.79 examples/s]Running tokenizer on dataset (num_proc=64): 255688 examples [00:42, 3518.95 examples/s]Running tokenizer on dataset (num_proc=64): 256688 examples [00:42, 3614.87 examples/s]Running: 240688 examples [00:38, 2132.65 examples/s]Running tokenizer on dataset (num_proc=64): 241688 examples [00:38, 2201.83 examples/s]Running tokenizer on dataset (num_proc=64): 243688 examples [00:39, 2594.19 examples/s]Running tokenizer on dataset (num_proc=64): 244688 examples [00:39, 2727.67 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:39, 3284.67 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:39, 2704.29 examples/s]Running tokenizer on dataset (num_proc=64): 250688 examples [00:40, 4155.01 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:41, 3186.39 examples/s]Running tokenizer on dataset (num_proc=64): 253688 examples [00:41, 3923.24 examples/s]Running tokenizer on dataset (num_proc=64): 254688 examples [00:42, 3274.03 examples/s]Running tokenizer on dataset (num_proc=64): 255688 examples [00:42, 2917.04 examples/s]Running tokenizer on dataset (num_proc=64): 257688 examples [00:42, 3993.13 examples/s]Running totokenizer on dataset (num_proc=64): 255688 examples [00:38, 4958.92 examples/s]Running tokenizer on dataset (num_proc=64): 257688 examples [00:39, 3796.30 examples/s]Running tokenizer on dataset (num_proc=64): 258688 examples [00:39, 4305.92 examples/s]Running tokenizer on dataset (num_proc=64): 259688 examples [00:39, 4388.98 examples/s]Running tokenizer on dataset (num_proc=64): 260688 examples [00:39, 4950.54 examples/s]Running tokenizer on dataset (num_proc=64): 261688 examples [00:40, 2984.73 examples/s]Running tokenizer on dataset (num_proc=64): 263688 examples [00:41, 3382.43 examples/s]Running tokenizer on dataset (num_proc=64): 264688 examples [00:41, 3397.70 examples/s]Running tokenizer on dataset (num_proc=64): 266688 examples [00:41, 4953.39 examples/s]Running tokenizer on dataset (num_proc=64): 267688 examples [00:41, 5129.04 examples/s]Running tokenizer on dataset (num_proc=64): 269688 examples [00:42, 5415.69 examples/s]Running tokenizer on dataset (num_proc=64): 270688 examples [00:64): 240688 examples [00:36, 2482.54 examples/s]Running tokenizer on dataset (num_proc=64): 241688 examples [00:36, 2065.16 examples/s]Running tokenizer on dataset (num_proc=64): 242688 examples [00:38, 1490.47 examples/s]Running tokenizer on dataset (num_proc=64): 245688 examples [00:38, 2730.69 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:38, 2524.85 examples/s]Running tokenizer on dataset (num_proc=64): 247688 examples [00:39, 2632.67 examples/s]Running tokenizer on dataset (num_proc=64): 248688 examples [00:39, 2878.33 examples/s]Running tokenizer on dataset (num_proc=64): 249688 examples [00:40, 1609.58 examples/s]Running tokenizer on dataset (num_proc=64): 250688 examples [00:41, 1778.56 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:41, 1875.17 examples/s]Running tokenizer on dataset (num_proc=64): 252688 examples [00:42, 1577.36 examples/s]Running tokenizer on dataset (num_proc=64): 253688 examples [00:43, 1685.39 examples/s]Running64): 244688 examples [00:40, 1505.14 examples/s]Running tokenizer on dataset (num_proc=64): 246688 examples [00:40, 2110.86 examples/s]Running tokenizer on dataset (num_proc=64): 249688 examples [00:40, 3412.53 examples/s]Running tokenizer on dataset (num_proc=64): 250688 examples [00:41, 3090.65 examples/s]Running tokenizer on dataset (num_proc=64): 251688 examples [00:42, 2178.34 examples/s]Running tokenizer on dataset (num_proc=64): 252688 examples [00:42, 2639.35 examples/s]Running tokenizer on dataset (num_proc=64): 254688 examples [00:42, 3728.39 examples/s]Running tokenizer on dataset (num_proc=64): 257688 examples [00:42, 6231.73 examples/s]Running tokenizer on dataset (num_proc=64): 259605 examples [00:43, 4763.99 examples/s]Running tokenizer on dataset (num_proc=64): 261605 examples [00:43, 5004.32 examples/s]Running tokenizer on dataset (num_proc=64): 263605 examples [00:43, 6032.31 examples/s]Running tokenizer on dataset (num_proc=64): 265605 examples [00:44, 6082.51 examples/s]Runningokenizer on dataset (num_proc=64): 254688 examples [00:41, 6993.53 examples/s]Running tokenizer on dataset (num_proc=64): 256688 examples [00:42, 5008.48 examples/s]Running tokenizer on dataset (num_proc=64): 257688 examples [00:42, 4660.56 examples/s]Running tokenizer on dataset (num_proc=64): 259605 examples [00:42, 4977.18 examples/s]Running tokenizer on dataset (num_proc=64): 263522 examples [00:43, 6162.41 examples/s]Running tokenizer on dataset (num_proc=64): 264522 examples [00:43, 6127.94 examples/s]Running tokenizer on dataset (num_proc=64): 265522 examples [00:43, 4828.33 examples/s]Running tokenizer on dataset (num_proc=64): 266439 examples [00:43, 4783.05 examples/s]Running tokenizer on dataset (num_proc=64): 267439 examples [00:44, 3761.63 examples/s]Running tokenizer on dataset (num_proc=64): 268439 examples [00:45, 2771.52 examples/s]Running tokenizer on dataset (num_proc=64): 269439 examples [00:45, 3352.31 examples/s]Running tokenizer on dataset (num_proc=64): 270439 examples [00:4 tokenizer on dataset (num_proc=64): 257688 examples [00:42, 3387.05 examples/s]Running tokenizer on dataset (num_proc=64): 258688 examples [00:42, 3579.00 examples/s]Running tokenizer on dataset (num_proc=64): 259688 examples [00:42, 4282.37 examples/s]Running tokenizer on dataset (num_proc=64): 260688 examples [00:43, 3260.02 examples/s]Running tokenizer on dataset (num_proc=64): 263688 examples [00:43, 6062.43 examples/s]Running tokenizer on dataset (num_proc=64): 264688 examples [00:44, 3588.68 examples/s]Running tokenizer on dataset (num_proc=64): 265605 examples [00:44, 3428.92 examples/s]Running tokenizer on dataset (num_proc=64): 266522 examples [00:45, 3171.60 examples/s]Running tokenizer on dataset (num_proc=64): 267522 examples [00:45, 3262.72 examples/s]Running tokenizer on dataset (num_proc=64): 268522 examples [00:45, 3632.49 examples/s]Running tokenizer on dataset (num_proc=64): 269522 examples [00:45, 3832.54 examples/s]Running tokenizer on dataset (num_proc=64): 270522 examples [00 tokenizer on dataset (num_proc=64): 254688 examples [00:43, 2153.17 examples/s]Running tokenizer on dataset (num_proc=64): 256688 examples [00:43, 3145.66 examples/s]Running tokenizer on dataset (num_proc=64): 258688 examples [00:43, 4565.92 examples/s]Running tokenizer on dataset (num_proc=64): 260688 examples [00:43, 5492.52 examples/s]Running tokenizer on dataset (num_proc=64): 261688 examples [00:44, 5256.17 examples/s]Running tokenizer on dataset (num_proc=64): 262688 examples [00:44, 4500.56 examples/s]Running tokenizer on dataset (num_proc=64): 263688 examples [00:45, 2830.97 examples/s]Running tokenizer on dataset (num_proc=64): 265688 examples [00:45, 4078.84 examples/s]Running tokenizer on dataset (num_proc=64): 266688 examples [00:45, 4174.45 examples/s]Running tokenizer on dataset (num_proc=64): 268688 examples [00:45, 5336.01 examples/s]Running tokenizer on dataset (num_proc=64): 269605 examples [00:46, 3345.77 examples/s]Running tokenizer on dataset (num_proc=64): 270605 examples [00tokenizer on dataset (num_proc=64): 255688 examples [00:41, 2885.17 examples/s]Running tokenizer on dataset (num_proc=64): 257688 examples [00:41, 3356.48 examples/s]Running tokenizer on dataset (num_proc=64): 258688 examples [00:41, 3953.63 examples/s]Running tokenizer on dataset (num_proc=64): 259688 examples [00:43, 1872.13 examples/s]Running tokenizer on dataset (num_proc=64): 260605 examples [00:43, 2033.54 examples/s]Running tokenizer on dataset (num_proc=64): 262605 examples [00:43, 3283.53 examples/s]Running tokenizer on dataset (num_proc=64): 264605 examples [00:44, 3475.84 examples/s]Running tokenizer on dataset (num_proc=64): 265522 examples [00:44, 3094.32 examples/s]Running tokenizer on dataset (num_proc=64): 266522 examples [00:44, 3074.11 examples/s]Running tokenizer on dataset (num_proc=64): 267522 examples [00:45, 2601.55 examples/s]Running tokenizer on dataset (num_proc=64): 268439 examples [00:46, 2056.78 examples/s]Running tokenizer on dataset (num_proc=64): 270439 examples [00:kenizer on dataset (num_proc=64): 260688 examples [00:41, 2444.90 examples/s]Running tokenizer on dataset (num_proc=64): 261688 examples [00:41, 2801.32 examples/s]Running tokenizer on dataset (num_proc=64): 262688 examples [00:42, 2994.67 examples/s]Running tokenizer on dataset (num_proc=64): 264605 examples [00:42, 3886.60 examples/s]Running tokenizer on dataset (num_proc=64): 265605 examples [00:43, 2618.66 examples/s]Running tokenizer on dataset (num_proc=64): 266605 examples [00:43, 3104.48 examples/s]Running tokenizer on dataset (num_proc=64): 267605 examples [00:44, 1639.19 examples/s]Running tokenizer on dataset (num_proc=64): 269605 examples [00:45, 2535.82 examples/s]Running tokenizer on dataset (num_proc=64): 270605 examples [00:45, 2119.88 examples/s]Running tokenizer on dataset (num_proc=64): 272522 examples [00:45, 3077.80 examples/s]Running tokenizer on dataset (num_proc=64): 273522 examples [00:46, 2221.41 examples/s]Running tokenizer on dataset (num_proc=64): 274522 examples [00:48kenizer on dataset (num_proc=64): 259688 examples [00:42, 4972.98 examples/s]Running tokenizer on dataset (num_proc=64): 261688 examples [00:43, 6297.35 examples/s]Running tokenizer on dataset (num_proc=64): 262688 examples [00:43, 6371.35 examples/s]Running tokenizer on dataset (num_proc=64): 263605 examples [00:44, 3364.65 examples/s]Running tokenizer on dataset (num_proc=64): 264605 examples [00:44, 3765.36 examples/s]Running tokenizer on dataset (num_proc=64): 266605 examples [00:44, 5255.70 examples/s]Running tokenizer on dataset (num_proc=64): 267605 examples [00:44, 3984.89 examples/s]Running tokenizer on dataset (num_proc=64): 269605 examples [00:45, 4411.44 examples/s]Running tokenizer on dataset (num_proc=64): 270605 examples [00:45, 4944.44 examples/s]Running tokenizer on dataset (num_proc=64): 271605 examples [00:46, 2651.58 examples/s]Running tokenizer on dataset (num_proc=64): 273605 examples [00:47, 1771.63 examples/s]Running tokenizer on dataset (num_proc=64): 274605 examples [00:48 tokenizer on dataset (num_proc=64): 266605 examples [00:44, 4649.90 examples/s]Running tokenizer on dataset (num_proc=64): 267605 examples [00:44, 5057.16 examples/s]Running tokenizer on dataset (num_proc=64): 268605 examples [00:45, 5588.72 examples/s]Running tokenizer on dataset (num_proc=64): 269605 examples [00:45, 5971.73 examples/s]Running tokenizer on dataset (num_proc=64): 270605 examples [00:45, 5249.59 examples/s]Running tokenizer on dataset (num_proc=64): 271522 examples [00:45, 4010.96 examples/s]Running tokenizer on dataset (num_proc=64): 272522 examples [00:46, 2632.85 examples/s]Running tokenizer on dataset (num_proc=64): 273522 examples [00:46, 2650.91 examples/s]Running tokenizer on dataset (num_proc=64): 274439 examples [00:47, 2700.30 examples/s]Running tokenizer on dataset (num_proc=64): 275439 examples [00:47, 2545.96 examples/s]Running tokenizer on dataset (num_proc=64): 276356 examples [00:48, 1942.74 examples/s]Running tokenizer on dataset (num_proc=64): 277356 examples [0043, 2477.72 examples/s]Running tokenizer on dataset (num_proc=64): 271688 examples [00:45, 1317.78 examples/s]Running tokenizer on dataset (num_proc=64): 272605 examples [00:46, 1008.39 examples/s]Running tokenizer on dataset (num_proc=64): 273522 examples [00:47, 1231.04 examples/s]Running tokenizer on dataset (num_proc=64): 274522 examples [00:47, 1471.87 examples/s]Running tokenizer on dataset (num_proc=64): 275439 examples [00:47, 1715.26 examples/s]Running tokenizer on dataset (num_proc=64): 276356 examples [00:48, 1316.02 examples/s]Running tokenizer on dataset (num_proc=64): 277356 examples [00:48, 1674.08 examples/s]Running tokenizer on dataset (num_proc=64): 278356 examples [00:49, 1773.50 examples/s]Running tokenizer on dataset (num_proc=64): 280356 examples [00:50, 2280.85 examples/s]Running tokenizer on dataset (num_proc=64): 281356 examples [00:51, 1493.41 examples/s]Running tokenizer on dataset (num_proc=64): 283356 examples [00:51, 2036.44 examples/s]Running tokenizer on dataset (nu47, 1476.60 examples/s]Running tokenizer on dataset (num_proc=64): 271439 examples [00:48, 1746.83 examples/s]Running tokenizer on dataset (num_proc=64): 272356 examples [00:48, 1985.66 examples/s]Running tokenizer on dataset (num_proc=64): 273356 examples [00:49, 1608.51 examples/s]Running tokenizer on dataset (num_proc=64): 274356 examples [00:49, 1807.62 examples/s]Running tokenizer on dataset (num_proc=64): 275273 examples [00:50, 1874.27 examples/s]Running tokenizer on dataset (num_proc=64): 276273 examples [00:50, 1867.98 examples/s]Running tokenizer on dataset (num_proc=64): 277273 examples [00:51, 1743.68 examples/s]Running tokenizer on dataset (num_proc=64): 278273 examples [00:51, 1974.21 examples/s]Running tokenizer on dataset (num_proc=64): 279273 examples [00:51, 2421.83 examples/s]Running tokenizer on dataset (num_proc=64): 280190 examples [00:52, 2839.84 examples/s]Running tokenizer on dataset (num_proc=64): 283107 examples [00:52, 3983.34 examples/s]Running tokenizer on dataset (nu:46, 2413.77 examples/s]Running tokenizer on dataset (num_proc=64): 271522 examples [00:46, 2722.35 examples/s]Running tokenizer on dataset (num_proc=64): 272522 examples [00:47, 2920.98 examples/s]Running tokenizer on dataset (num_proc=64): 274522 examples [00:47, 3285.84 examples/s]Running tokenizer on dataset (num_proc=64): 275522 examples [00:48, 2640.84 examples/s]Running tokenizer on dataset (num_proc=64): 276522 examples [00:50, 1311.51 examples/s]Running tokenizer on dataset (num_proc=64): 277439 examples [00:50, 1275.13 examples/s]Running tokenizer on dataset (num_proc=64): 279439 examples [00:50, 2170.36 examples/s]Running tokenizer on dataset (num_proc=64): 280439 examples [00:51, 2565.91 examples/s]Running tokenizer on dataset (num_proc=64): 281356 examples [00:51, 2880.03 examples/s]Running tokenizer on dataset (num_proc=64): 282356 examples [00:51, 3260.10 examples/s]Running tokenizer on dataset (num_proc=64): 283356 examples [00:51, 3067.00 examples/s]Running tokenizer on dataset (n6, 2048.00 examples/s]Running tokenizer on dataset (num_proc=64): 271439 examples [00:46, 2596.33 examples/s]Running tokenizer on dataset (num_proc=64): 272439 examples [00:46, 3086.82 examples/s]Running tokenizer on dataset (num_proc=64): 274439 examples [00:46, 4938.62 examples/s]Running tokenizer on dataset (num_proc=64): 276356 examples [00:47, 3561.04 examples/s]Running tokenizer on dataset (num_proc=64): 277273 examples [00:47, 3236.38 examples/s]Running tokenizer on dataset (num_proc=64): 278273 examples [00:48, 2083.76 examples/s]Running tokenizer on dataset (num_proc=64): 279190 examples [00:50, 1223.91 examples/s]Running tokenizer on dataset (num_proc=64): 281190 examples [00:51, 1654.95 examples/s]Running tokenizer on dataset (num_proc=64): 282190 examples [00:52, 1354.25 examples/s]Running tokenizer on dataset (num_proc=64): 283107 examples [00:52, 1501.74 examples/s]Running tokenizer on dataset (num_proc=64): 285024 examples [00:53, 2032.88 examples/s]Running tokenizer on dataset (num:46, 3589.48 examples/s]Running tokenizer on dataset (num_proc=64): 271605 examples [00:46, 3978.85 examples/s]Running tokenizer on dataset (num_proc=64): 273522 examples [00:47, 5186.64 examples/s]Running tokenizer on dataset (num_proc=64): 275522 examples [00:47, 5803.67 examples/s]Running tokenizer on dataset (num_proc=64): 276522 examples [00:48, 3232.72 examples/s]Running tokenizer on dataset (num_proc=64): 277522 examples [00:49, 2002.46 examples/s]Running tokenizer on dataset (num_proc=64): 278522 examples [00:49, 2344.13 examples/s]Running tokenizer on dataset (num_proc=64): 279522 examples [00:49, 2425.20 examples/s]Running tokenizer on dataset (num_proc=64): 281439 examples [00:52, 1430.15 examples/s]Running tokenizer on dataset (num_proc=64): 282356 examples [00:52, 1687.14 examples/s]Running tokenizer on dataset (num_proc=64): 283273 examples [00:52, 1956.50 examples/s]Running tokenizer on dataset (num_proc=64): 284273 examples [00:52, 2197.81 examples/s]Running tokenizer on dataset (n, 1384.51 examples/s]Running tokenizer on dataset (num_proc=64): 275522 examples [00:49, 1281.26 examples/s]Running tokenizer on dataset (num_proc=64): 276439 examples [00:50, 1208.18 examples/s]Running tokenizer on dataset (num_proc=64): 277356 examples [00:50, 1295.84 examples/s]Running tokenizer on dataset (num_proc=64): 278356 examples [00:51, 1378.32 examples/s]Running tokenizer on dataset (num_proc=64): 279273 examples [00:51, 1463.25 examples/s]Running tokenizer on dataset (num_proc=64): 280273 examples [00:52, 1719.52 examples/s]Running tokenizer on dataset (num_proc=64): 281190 examples [00:52, 1884.71 examples/s]Running tokenizer on dataset (num_proc=64): 282107 examples [00:52, 2087.32 examples/s]Running tokenizer on dataset (num_proc=64): 283024 examples [00:53, 2276.86 examples/s]Running tokenizer on dataset (num_proc=64): 284024 examples [00:54, 1670.69 examples/s]Running tokenizer on dataset (num_proc=64): 284941 examples [00:54, 1708.47 examples/s]Running tokenizer on dataset (num_m_proc=64): 284273 examples [00:52, 1981.47 examples/s]Running tokenizer on dataset (num_proc=64): 285190 examples [00:52, 2150.02 examples/s]Running tokenizer on dataset (num_proc=64): 286107 examples [00:53, 2192.21 examples/s]Running tokenizer on dataset (num_proc=64): 288107 examples [00:53, 3254.44 examples/s]Running tokenizer on dataset (num_proc=64): 289107 examples [00:53, 3603.40 examples/s]Running tokenizer on dataset (num_proc=64): 290024 examples [00:53, 4112.69 examples/s]Running tokenizer on dataset (num_proc=64): 291858 examples [00:54, 4162.04 examples/s]Running tokenizer on dataset (num_proc=64): 293692 examples [00:54, 5668.13 examples/s]Running tokenizer on dataset (num_proc=64): 294609 examples [00:54, 5525.30 examples/s]Running tokenizer on dataset (num_proc=64): 295526 examples [00:54, 4089.52 examples/s]Running tokenizer on dataset (num_proc=64): 296443 examples [00:55, 3346.38 examples/s]Running tokenizer on dataset (num_proc=64): 297360 examples [00:55, 3999.64 examples/s], 1719.43 examples/s]Running tokenizer on dataset (num_proc=64): 275605 examples [00:48, 1867.89 examples/s]Running tokenizer on dataset (num_proc=64): 277522 examples [00:49, 2610.26 examples/s]Running tokenizer on dataset (num_proc=64): 278439 examples [00:50, 1564.63 examples/s]Running tokenizer on dataset (num_proc=64): 280439 examples [00:51, 1639.33 examples/s]Running tokenizer on dataset (num_proc=64): 281356 examples [00:52, 1920.42 examples/s]Running tokenizer on dataset (num_proc=64): 282273 examples [00:53, 1507.98 examples/s]Running tokenizer on dataset (num_proc=64): 283273 examples [00:53, 1793.23 examples/s]Running tokenizer on dataset (num_proc=64): 284190 examples [00:54, 1219.36 examples/s]Running tokenizer on dataset (num_proc=64): 285190 examples [00:55, 1417.96 examples/s]Running tokenizer on dataset (num_proc=64): 286107 examples [00:55, 1642.67 examples/s]Running tokenizer on dataset (num_proc=64): 287024 examples [00:55, 2011.76 examples/s]Running tokenizer on dataset (num_:49, 1780.93 examples/s]Running tokenizer on dataset (num_proc=64): 278356 examples [00:50, 1446.76 examples/s]Running tokenizer on dataset (num_proc=64): 279356 examples [00:51, 1223.45 examples/s]Running tokenizer on dataset (num_proc=64): 280273 examples [00:51, 1287.20 examples/s]Running tokenizer on dataset (num_proc=64): 281190 examples [00:52, 1589.67 examples/s]Running tokenizer on dataset (num_proc=64): 282107 examples [00:52, 1513.53 examples/s]Running tokenizer on dataset (num_proc=64): 283024 examples [00:54, 949.96 examples/s] Running tokenizer on dataset (num_proc=64): 284941 examples [00:55, 1348.62 examples/s]Running tokenizer on dataset (num_proc=64): 285941 examples [00:55, 1606.38 examples/s]Running tokenizer on dataset (num_proc=64): 286858 examples [00:55, 1921.72 examples/s]Running tokenizer on dataset (num_proc=64): 288775 examples [00:55, 2823.02 examples/s]Running tokenizer on dataset (num_proc=64): 289775 examples [00:56, 2831.58 examples/s]Running tokenizer on dataset (num_proc=64): 285190 examples [00:54, 1086.34 examples/s]Running tokenizer on dataset (num_proc=64): 286107 examples [00:54, 1399.85 examples/s]Running tokenizer on dataset (num_proc=64): 287024 examples [00:55, 1759.76 examples/s]Running tokenizer on dataset (num_proc=64): 288941 examples [00:55, 2780.63 examples/s]Running tokenizer on dataset (num_proc=64): 289858 examples [00:55, 3269.74 examples/s]Running tokenizer on dataset (num_proc=64): 290775 examples [00:55, 3549.21 examples/s]Running tokenizer on dataset (num_proc=64): 292609 examples [00:56, 2522.69 examples/s]Running tokenizer on dataset (num_proc=64): 295526 examples [00:57, 3321.88 examples/s]Running tokenizer on dataset (num_proc=64): 296443 examples [00:58, 2466.53 examples/s]Running tokenizer on dataset (num_proc=64): 297443 examples [00:58, 2927.16 examples/s]Running tokenizer on dataset (num_proc=64): 298443 examples [00:58, 3415.41 examples/s]Running tokenizer on dataset (num_proc=64): 299443 examples [00:58, 4087.47 examples/s]m_proc=64): 286107 examples [00:52, 5173.50 examples/s]Running tokenizer on dataset (num_proc=64): 287024 examples [00:54, 2440.39 examples/s]Running tokenizer on dataset (num_proc=64): 287941 examples [00:54, 2246.95 examples/s]Running tokenizer on dataset (num_proc=64): 288858 examples [00:55, 1797.44 examples/s]Running tokenizer on dataset (num_proc=64): 289775 examples [00:55, 2191.85 examples/s]Running tokenizer on dataset (num_proc=64): 290692 examples [00:56, 1911.78 examples/s]Running tokenizer on dataset (num_proc=64): 292609 examples [00:57, 2139.49 examples/s]Running tokenizer on dataset (num_proc=64): 293609 examples [00:57, 2366.72 examples/s]Running tokenizer on dataset (num_proc=64): 295443 examples [00:57, 3106.63 examples/s]Running tokenizer on dataset (num_proc=64): 297360 examples [00:58, 4464.71 examples/s]Running tokenizer on dataset (num_proc=64): 298360 examples [00:58, 4916.67 examples/s]Running tokenizer on dataset (num_proc=64): 299277 examples [00:58, 4815.51 examples/s]proc=64): 285941 examples [00:55, 1743.85 examples/s]Running tokenizer on dataset (num_proc=64): 287941 examples [00:55, 3055.52 examples/s]Running tokenizer on dataset (num_proc=64): 289858 examples [00:55, 3990.69 examples/s]Running tokenizer on dataset (num_proc=64): 290775 examples [00:55, 3847.87 examples/s]Running tokenizer on dataset (num_proc=64): 291692 examples [00:56, 4348.19 examples/s]Running tokenizer on dataset (num_proc=64): 292609 examples [00:56, 4247.75 examples/s]Running tokenizer on dataset (num_proc=64): 293526 examples [00:56, 3883.28 examples/s]Running tokenizer on dataset (num_proc=64): 294526 examples [00:57, 2999.26 examples/s]Running tokenizer on dataset (num_proc=64): 295526 examples [00:57, 2831.10 examples/s]Running tokenizer on dataset (num_proc=64): 297360 examples [00:57, 3786.44 examples/s]Running tokenizer on dataset (num_proc=64): 299277 examples [00:57, 4727.46 examples/s]Running tokenizer on dataset (num_proc=64): 302111 examples [00:58, 4344.02 examples/s]RuRunning tokenizer on dataset (num_proc=64): 298277 examples [00:55, 4277.05 examples/s]Running tokenizer on dataset (num_proc=64): 299277 examples [00:55, 4840.51 examples/s]Running tokenizer on dataset (num_proc=64): 300277 examples [00:55, 5044.08 examples/s]Running tokenizer on dataset (num_proc=64): 301277 examples [00:55, 5873.80 examples/s]Running tokenizer on dataset (num_proc=64): 302194 examples [00:56, 2925.94 examples/s]Running tokenizer on dataset (num_proc=64): 304194 examples [00:56, 3967.79 examples/s]Running tokenizer on dataset (num_proc=64): 305111 examples [00:57, 3924.90 examples/s]Running tokenizer on dataset (num_proc=64): 306945 examples [00:57, 3955.27 examples/s]Running tokenizer on dataset (num_proc=64): 307862 examples [00:57, 4048.09 examples/s]Running tokenizer on dataset (num_proc=64): 308779 examples [00:58, 3101.61 examples/s]Running tokenizer on dataset (num_proc=64): 309696 examples [00:58, 3070.43 examples/s]Running tokenizer on dataset (num_proc=64): 311613 examp_proc=64): 285941 examples [00:53, 1735.99 examples/s]Running tokenizer on dataset (num_proc=64): 286858 examples [00:54, 1816.10 examples/s]Running tokenizer on dataset (num_proc=64): 288692 examples [00:54, 2618.78 examples/s]Running tokenizer on dataset (num_proc=64): 290609 examples [00:54, 3532.89 examples/s]Running tokenizer on dataset (num_proc=64): 291526 examples [00:55, 3139.26 examples/s]Running tokenizer on dataset (num_proc=64): 293443 examples [00:55, 4007.38 examples/s]Running tokenizer on dataset (num_proc=64): 295360 examples [00:56, 4046.13 examples/s]Running tokenizer on dataset (num_proc=64): 296360 examples [00:56, 3386.01 examples/s]Running tokenizer on dataset (num_proc=64): 297360 examples [00:57, 2502.41 examples/s]Running tokenizer on dataset (num_proc=64): 298360 examples [00:58, 1714.12 examples/s]Running tokenizer on dataset (num_proc=64): 299277 examples [00:58, 1927.64 examples/s]Running tokenizer on dataset (num_proc=64): 300194 examples [00:58, 2271.87 examples/s]Rum_proc=64): 284356 examples [00:53, 1503.99 examples/s]Running tokenizer on dataset (num_proc=64): 285273 examples [00:54, 1116.81 examples/s]Running tokenizer on dataset (num_proc=64): 286273 examples [00:55, 1382.81 examples/s]Running tokenizer on dataset (num_proc=64): 287190 examples [00:56, 1198.36 examples/s]Running tokenizer on dataset (num_proc=64): 288107 examples [00:57, 1005.53 examples/s]Running tokenizer on dataset (num_proc=64): 289024 examples [00:57, 1292.80 examples/s]Running tokenizer on dataset (num_proc=64): 290941 examples [00:57, 1966.92 examples/s]Running tokenizer on dataset (num_proc=64): 292775 examples [00:58, 2527.68 examples/s]Running tokenizer on dataset (num_proc=64): 293692 examples [00:58, 2394.04 examples/s]Running tokenizer on dataset (num_proc=64): 294692 examples [00:58, 2923.11 examples/s]Running tokenizer on dataset (num_proc=64): 296609 examples [00:59, 3735.99 examples/s]Running tokenizer on dataset (num_proc=64): 298443 examples [00:59, 4838.50 examples/s]proc=64): 287941 examples [00:55, 2356.59 examples/s]Running tokenizer on dataset (num_proc=64): 288858 examples [00:56, 2912.74 examples/s]Running tokenizer on dataset (num_proc=64): 289775 examples [00:56, 1969.24 examples/s]Running tokenizer on dataset (num_proc=64): 290692 examples [00:57, 2434.78 examples/s]Running tokenizer on dataset (num_proc=64): 292692 examples [00:57, 2505.05 examples/s]Running tokenizer on dataset (num_proc=64): 293692 examples [00:58, 2605.68 examples/s]Running tokenizer on dataset (num_proc=64): 296443 examples [00:59, 2637.65 examples/s]Running tokenizer on dataset (num_proc=64): 297360 examples [00:59, 2614.44 examples/s]Running tokenizer on dataset (num_proc=64): 298277 examples [00:59, 2919.15 examples/s]Running tokenizer on dataset (num_proc=64): 299194 examples [00:59, 3458.08 examples/s]Running tokenizer on dataset (num_proc=64): 301028 examples [01:00, 3641.92 examples/s]Running tokenizer on dataset (num_proc=64): 302945 examples [01:00, 4057.26 examples/s]Ruum_proc=64): 290692 examples [00:56, 3321.03 examples/s]Running tokenizer on dataset (num_proc=64): 292692 examples [00:56, 4703.42 examples/s]Running tokenizer on dataset (num_proc=64): 294526 examples [00:57, 4491.88 examples/s]Running tokenizer on dataset (num_proc=64): 295526 examples [00:57, 3137.75 examples/s]Running tokenizer on dataset (num_proc=64): 296443 examples [00:58, 2706.72 examples/s]Running tokenizer on dataset (num_proc=64): 297360 examples [00:58, 3048.61 examples/s]Running tokenizer on dataset (num_proc=64): 298360 examples [00:58, 3020.44 examples/s]Running tokenizer on dataset (num_proc=64): 299277 examples [00:59, 2428.19 examples/s]Running tokenizer on dataset (num_proc=64): 300194 examples [00:59, 2779.19 examples/s]Running tokenizer on dataset (num_proc=64): 302028 examples [01:00, 2105.57 examples/s]Running tokenizer on dataset (num_proc=64): 304862 examples [01:01, 3317.49 examples/s]Running tokenizer on dataset (num_proc=64): 305779 examples [01:01, 2948.52 examples/s]Running tokenizer on dataset (num_proc=64): 300360 examples [00:58, 3055.54 examples/s]Running tokenizer on dataset (num_proc=64): 301277 examples [00:59, 3124.47 examples/s]Running tokenizer on dataset (num_proc=64): 302194 examples [00:59, 2895.99 examples/s]Running tokenizer on dataset (num_proc=64): 303194 examples [00:59, 2877.66 examples/s]Running tokenizer on dataset (num_proc=64): 304111 examples [01:00, 3108.48 examples/s]Running tokenizer on dataset (num_proc=64): 305945 examples [01:00, 2712.86 examples/s]Running tokenizer on dataset (num_proc=64): 306862 examples [01:01, 2724.07 examples/s]Running tokenizer on dataset (num_proc=64): 307779 examples [01:01, 3122.38 examples/s]Running tokenizer on dataset (num_proc=64): 308696 examples [01:01, 3473.28 examples/s]Running tokenizer on dataset (num_proc=64): 309613 examples [01:01, 4034.82 examples/s]Running tokenizer on dataset (num_proc=64): 310613 examples [01:02, 3202.54 examples/s]Running tokenizer on dataset (num_proc=64): 312613 examnning tokenizer on dataset (num_proc=64): 303028 examples [00:58, 4774.63 examples/s]Running tokenizer on dataset (num_proc=64): 305862 examples [00:58, 7194.59 examples/s]Running tokenizer on dataset (num_proc=64): 307862 examples [00:59, 4319.21 examples/s]Running tokenizer on dataset (num_proc=64): 308779 examples [00:59, 4493.09 examples/s]Running tokenizer on dataset (num_proc=64): 309779 examples [01:00, 4011.09 examples/s]Running tokenizer on dataset (num_proc=64): 310696 examples [01:00, 4298.25 examples/s]Running tokenizer on dataset (num_proc=64): 311613 examples [01:00, 4664.91 examples/s]Running tokenizer on dataset (num_proc=64): 313530 examples [01:00, 6358.40 examples/s]Running tokenizer on dataset (num_proc=64): 314530 examples [01:01, 5160.33 examples/s]Running tokenizer on dataset (num_proc=64): 317281 examples [01:01, 7689.08 examples/s]Running tokenizer on dataset (num_proc=64): 319115 examples [01:01, 8257.63 examples/s]Running tokenizer on dataset (num_proc=64): 320949 exampleRunning tokenizer on dataset (num_proc=64): 300277 examples [00:58, 4182.41 examples/s]Running tokenizer on dataset (num_proc=64): 301194 examples [00:58, 3880.16 examples/s]Running tokenizer on dataset (num_proc=64): 303111 examples [00:59, 4684.80 examples/s]Running tokenizer on dataset (num_proc=64): 304028 examples [00:59, 3364.20 examples/s]Running tokenizer on dataset (num_proc=64): 305945 examples [01:00, 4269.74 examples/s]Running tokenizer on dataset (num_proc=64): 307945 examples [01:01, 3062.12 examples/s]Running tokenizer on dataset (num_proc=64): 308862 examples [01:01, 3191.28 examples/s]Running tokenizer on dataset (num_proc=64): 309779 examples [01:01, 3225.76 examples/s]Running tokenizer on dataset (num_proc=64): 312530 examples [01:01, 5559.67 examples/s]Running tokenizer on dataset (num_proc=64): 315364 examples [01:01, 7483.48 examples/s]Running tokenizer on dataset (num_proc=64): 317281 examples [01:02, 6021.26 examples/s]Running tokenizer on dataset (num_proc=64): 318198 exampunning tokenizer on dataset (num_proc=64): 301194 examples [00:59, 2416.46 examples/s]Running tokenizer on dataset (num_proc=64): 302111 examples [00:59, 2339.36 examples/s]Running tokenizer on dataset (num_proc=64): 304111 examples [00:59, 3425.30 examples/s]Running tokenizer on dataset (num_proc=64): 305945 examples [01:00, 4481.21 examples/s]Running tokenizer on dataset (num_proc=64): 306862 examples [01:00, 4574.90 examples/s]Running tokenizer on dataset (num_proc=64): 308696 examples [01:00, 4303.10 examples/s]Running tokenizer on dataset (num_proc=64): 309696 examples [01:00, 4425.37 examples/s]Running tokenizer on dataset (num_proc=64): 310696 examples [01:01, 3323.60 examples/s]Running tokenizer on dataset (num_proc=64): 311613 examples [01:01, 3787.25 examples/s]Running tokenizer on dataset (num_proc=64): 312530 examples [01:02, 2896.48 examples/s]Running tokenizer on dataset (num_proc=64): 314530 examples [01:02, 3967.23 examples/s]Running tokenizer on dataset (num_proc=64): 315447 examplRunning tokenizer on dataset (num_proc=64): 299443 examples [01:00, 2576.29 examples/s]Running tokenizer on dataset (num_proc=64): 300360 examples [01:00, 2807.62 examples/s]Running tokenizer on dataset (num_proc=64): 301277 examples [01:00, 2877.56 examples/s]Running tokenizer on dataset (num_proc=64): 302194 examples [01:01, 2929.61 examples/s]Running tokenizer on dataset (num_proc=64): 303111 examples [01:01, 3388.25 examples/s]Running tokenizer on dataset (num_proc=64): 304028 examples [01:01, 2584.33 examples/s]Running tokenizer on dataset (num_proc=64): 304945 examples [01:02, 2981.76 examples/s]Running tokenizer on dataset (num_proc=64): 305862 examples [01:02, 2992.41 examples/s]Running tokenizer on dataset (num_proc=64): 307696 examples [01:02, 4126.05 examples/s]Running tokenizer on dataset (num_proc=64): 308696 examples [01:02, 4767.40 examples/s]Running tokenizer on dataset (num_proc=64): 313447 examples [01:02, 10839.58 examples/s]Running tokenizer on dataset (num_proc=64): 315447 exales [00:58, 4266.23 examples/s]Running tokenizer on dataset (num_proc=64): 312530 examples [00:59, 4036.61 examples/s]Running tokenizer on dataset (num_proc=64): 313447 examples [00:59, 3660.32 examples/s]Running tokenizer on dataset (num_proc=64): 315281 examples [01:00, 3126.23 examples/s]Running tokenizer on dataset (num_proc=64): 316198 examples [01:00, 3420.24 examples/s]Running tokenizer on dataset (num_proc=64): 317115 examples [01:00, 3778.39 examples/s]Running tokenizer on dataset (num_proc=64): 318032 examples [01:00, 3842.33 examples/s]Running tokenizer on dataset (num_proc=64): 319866 examples [01:00, 5177.24 examples/s]Running tokenizer on dataset (num_proc=64): 320866 examples [01:01, 2784.21 examples/s]Running tokenizer on dataset (num_proc=64): 323617 examples [01:02, 3543.66 examples/s]Running tokenizer on dataset (num_proc=64): 325534 examples [01:03, 3103.77 examples/s]Running tokenizer on dataset (num_proc=64): 326534 examples [01:03, 3453.98 examples/s]Running tokenizer on datnning tokenizer on dataset (num_proc=64): 303945 examples [01:00, 4552.26 examples/s]Running tokenizer on dataset (num_proc=64): 305779 examples [01:01, 5059.96 examples/s]Running tokenizer on dataset (num_proc=64): 308613 examples [01:01, 6927.48 examples/s]Running tokenizer on dataset (num_proc=64): 309530 examples [01:01, 6667.90 examples/s]Running tokenizer on dataset (num_proc=64): 310447 examples [01:01, 6851.65 examples/s]Running tokenizer on dataset (num_proc=64): 311447 examples [01:02, 4453.41 examples/s]Running tokenizer on dataset (num_proc=64): 313281 examples [01:02, 5777.66 examples/s]Running tokenizer on dataset (num_proc=64): 314198 examples [01:02, 5257.15 examples/s]Running tokenizer on dataset (num_proc=64): 315198 examples [01:02, 4076.83 examples/s]Running tokenizer on dataset (num_proc=64): 317198 examples [01:03, 5469.89 examples/s]Running tokenizer on dataset (num_proc=64): 318115 examples [01:03, 4670.53 examples/s]Running tokenizer on dataset (num_proc=64): 320032 exampleRunning tokenizer on dataset (num_proc=64): 306779 examples [01:02, 2694.87 examples/s]Running tokenizer on dataset (num_proc=64): 307696 examples [01:02, 2684.64 examples/s]Running tokenizer on dataset (num_proc=64): 308613 examples [01:02, 3143.08 examples/s]Running tokenizer on dataset (num_proc=64): 310613 examples [01:02, 4307.18 examples/s]Running tokenizer on dataset (num_proc=64): 314364 examples [01:02, 7759.92 examples/s]Running tokenizer on dataset (num_proc=64): 316281 examples [01:03, 8934.18 examples/s]Running tokenizer on dataset (num_proc=64): 318198 examples [01:03, 8629.95 examples/s]Running tokenizer on dataset (num_proc=64): 320198 examples [01:03, 8123.23 examples/s]Running tokenizer on dataset (num_proc=64): 322032 examples [01:04, 4215.86 examples/s]Running tokenizer on dataset (num_proc=64): 322949 examples [01:04, 4170.22 examples/s]Running tokenizer on dataset (num_proc=64): 323949 examples [01:04, 4698.85 examples/s]Running tokenizer on dataset (num_proc=64): 324866 examples [01:02, 4653.78 examples/s]Running tokenizer on dataset (num_proc=64): 314447 examples [01:02, 4424.31 examples/s]Running tokenizer on dataset (num_proc=64): 315364 examples [01:03, 3069.35 examples/s]Running tokenizer on dataset (num_proc=64): 316281 examples [01:03, 3553.70 examples/s]Running tokenizer on dataset (num_proc=64): 317281 examples [01:03, 3998.41 examples/s]Running tokenizer on dataset (num_proc=64): 318198 examples [01:03, 4502.48 examples/s]Running tokenizer on dataset (num_proc=64): 319115 examples [01:04, 4298.06 examples/s]Running tokenizer on dataset (num_proc=64): 320949 examples [01:04, 3947.52 examples/s]Running tokenizer on dataset (num_proc=64): 321866 examples [01:05, 3010.82 examples/s]Running tokenizer on dataset (num_proc=64): 325617 examples [01:05, 5817.92 examples/s]Running tokenizer on dataset (num_proc=64): 326534 examples [01:05, 5993.67 examples/s]Running tokenizer on dataset (num_proc=64): 327451 examples [01:06, 3961.46 examples/s]Running tokenizer on daes [01:02, 4190.92 examples/s]Running tokenizer on dataset (num_proc=64): 317281 examples [01:02, 5137.89 examples/s]Running tokenizer on dataset (num_proc=64): 318198 examples [01:02, 5655.20 examples/s]Running tokenizer on dataset (num_proc=64): 319115 examples [01:03, 5476.08 examples/s]Running tokenizer on dataset (num_proc=64): 320949 examples [01:03, 4392.00 examples/s]Running tokenizer on dataset (num_proc=64): 321866 examples [01:03, 4915.67 examples/s]Running tokenizer on dataset (num_proc=64): 323700 examples [01:05, 2500.35 examples/s]Running tokenizer on dataset (num_proc=64): 324700 examples [01:05, 2829.44 examples/s]Running tokenizer on dataset (num_proc=64): 326534 examples [01:05, 3911.21 examples/s]Running tokenizer on dataset (num_proc=64): 327534 examples [01:05, 3876.58 examples/s]Running tokenizer on dataset (num_proc=64): 328451 examples [01:05, 3819.00 examples/s]Running tokenizer on dataset (num_proc=64): 329368 examples [01:06, 3341.15 examples/s]Running tokenizer on datamples [01:03, 10517.46 examples/s]Running tokenizer on dataset (num_proc=64): 318198 examples [01:03, 12516.31 examples/s]Running tokenizer on dataset (num_proc=64): 320115 examples [01:03, 8432.51 examples/s] Running tokenizer on dataset (num_proc=64): 322032 examples [01:03, 8605.26 examples/s]Running tokenizer on dataset (num_proc=64): 323866 examples [01:04, 7241.16 examples/s]Running tokenizer on dataset (num_proc=64): 325700 examples [01:04, 6359.65 examples/s]Running tokenizer on dataset (num_proc=64): 327534 examples [01:05, 5826.74 examples/s]Running tokenizer on dataset (num_proc=64): 328451 examples [01:05, 3518.16 examples/s]Running tokenizer on dataset (num_proc=64): 329451 examples [01:06, 3615.60 examples/s]Running tokenizer on dataset (num_proc=64): 330451 examples [01:06, 4008.13 examples/s]Running tokenizer on dataset (num_proc=64): 331368 examples [01:06, 4057.26 examples/s]Running tokenizer on dataset (num_proc=64): 333285 examples [01:06, 5571.61 examples/s]Running tokenizer oaset (num_proc=64): 327451 examples [01:03, 3813.56 examples/s]Running tokenizer on dataset (num_proc=64): 329368 examples [01:03, 5235.96 examples/s]Running tokenizer on dataset (num_proc=64): 330368 examples [01:03, 4444.14 examples/s]Running tokenizer on dataset (num_proc=64): 331285 examples [01:04, 3613.49 examples/s]Running tokenizer on dataset (num_proc=64): 332285 examples [01:04, 3198.45 examples/s]Running tokenizer on dataset (num_proc=64): 334202 examples [01:05, 3769.14 examples/s]Running tokenizer on dataset (num_proc=64): 336119 examples [01:05, 4243.07 examples/s]Running tokenizer on dataset (num_proc=64): 337036 examples [01:05, 3786.80 examples/s]Running tokenizer on dataset (num_proc=64): 338036 examples [01:06, 4055.07 examples/s]Running tokenizer on dataset (num_proc=64): 338953 examples [01:06, 3627.80 examples/s]Running tokenizer on dataset (num_proc=64): 341704 examples [01:06, 4260.90 examples/s]Running tokenizer on dataset (num_proc=64): 342621 examples [01:07, 4089.31 examles [01:02, 6183.19 examples/s]Running tokenizer on dataset (num_proc=64): 319115 examples [01:02, 5107.28 examples/s]Running tokenizer on dataset (num_proc=64): 320032 examples [01:03, 2681.73 examples/s]Running tokenizer on dataset (num_proc=64): 320949 examples [01:03, 2984.34 examples/s]Running tokenizer on dataset (num_proc=64): 321866 examples [01:04, 3071.26 examples/s]Running tokenizer on dataset (num_proc=64): 322866 examples [01:04, 3620.42 examples/s]Running tokenizer on dataset (num_proc=64): 324783 examples [01:05, 2319.07 examples/s]Running tokenizer on dataset (num_proc=64): 325700 examples [01:06, 1974.23 examples/s]Running tokenizer on dataset (num_proc=64): 326617 examples [01:06, 2321.50 examples/s]Running tokenizer on dataset (num_proc=64): 328534 examples [01:06, 3670.53 examples/s]Running tokenizer on dataset (num_proc=64): 329451 examples [01:07, 2878.49 examples/s]Running tokenizer on dataset (num_proc=64): 330451 examples [01:07, 3366.74 examples/s]Running tokenizer on dats [01:02, 3918.42 examples/s]Running tokenizer on dataset (num_proc=64): 321949 examples [01:02, 3614.07 examples/s]Running tokenizer on dataset (num_proc=64): 322866 examples [01:03, 3117.93 examples/s]Running tokenizer on dataset (num_proc=64): 324700 examples [01:05, 1539.36 examples/s]Running tokenizer on dataset (num_proc=64): 325617 examples [01:05, 1823.24 examples/s]Running tokenizer on dataset (num_proc=64): 326534 examples [01:06, 1847.42 examples/s]Running tokenizer on dataset (num_proc=64): 327451 examples [01:06, 2281.41 examples/s]Running tokenizer on dataset (num_proc=64): 328368 examples [01:06, 2679.08 examples/s]Running tokenizer on dataset (num_proc=64): 330202 examples [01:06, 3720.91 examples/s]Running tokenizer on dataset (num_proc=64): 331202 examples [01:07, 2245.52 examples/s]Running tokenizer on dataset (num_proc=64): 332202 examples [01:08, 1617.42 examples/s]Running tokenizer on dataset (num_proc=64): 333119 examples [01:09, 1794.04 examples/s]Running tokenizer on datass [01:03, 4907.00 examples/s]Running tokenizer on dataset (num_proc=64): 320949 examples [01:03, 4575.88 examples/s]Running tokenizer on dataset (num_proc=64): 323783 examples [01:04, 7664.30 examples/s]Running tokenizer on dataset (num_proc=64): 325617 examples [01:05, 3713.15 examples/s]Running tokenizer on dataset (num_proc=64): 326534 examples [01:05, 3239.38 examples/s]Running tokenizer on dataset (num_proc=64): 327451 examples [01:05, 3585.99 examples/s]Running tokenizer on dataset (num_proc=64): 328368 examples [01:06, 2596.67 examples/s]Running tokenizer on dataset (num_proc=64): 329285 examples [01:07, 2163.18 examples/s]Running tokenizer on dataset (num_proc=64): 330202 examples [01:08, 1188.67 examples/s]Running tokenizer on dataset (num_proc=64): 331119 examples [01:09, 1296.91 examples/s]Running tokenizer on dataset (num_proc=64): 332036 examples [01:09, 1428.87 examples/s]Running tokenizer on dataset (num_proc=64): 333953 examples [01:10, 2312.93 examples/s]Running tokenizer on datasset (num_proc=64): 330368 examples [01:06, 3549.38 examples/s]Running tokenizer on dataset (num_proc=64): 332202 examples [01:07, 3402.92 examples/s]Running tokenizer on dataset (num_proc=64): 333202 examples [01:07, 2508.13 examples/s]Running tokenizer on dataset (num_proc=64): 334202 examples [01:08, 2104.10 examples/s]Running tokenizer on dataset (num_proc=64): 335202 examples [01:08, 2361.89 examples/s]Running tokenizer on dataset (num_proc=64): 336119 examples [01:09, 2428.50 examples/s]Running tokenizer on dataset (num_proc=64): 337036 examples [01:10, 1731.35 examples/s]Running tokenizer on dataset (num_proc=64): 337953 examples [01:10, 1879.29 examples/s]Running tokenizer on dataset (num_proc=64): 338870 examples [01:10, 2318.87 examples/s]Running tokenizer on dataset (num_proc=64): 339870 examples [01:11, 1672.50 examples/s]Running tokenizer on dataset (num_proc=64): 340787 examples [01:11, 2154.45 examples/s]Running tokenizer on dataset (num_proc=64): 342704 examples [01:11, 3492.65 examptaset (num_proc=64): 329285 examples [01:06, 4539.39 examples/s]Running tokenizer on dataset (num_proc=64): 330202 examples [01:06, 3516.41 examples/s]Running tokenizer on dataset (num_proc=64): 331119 examples [01:08, 1694.77 examples/s]Running tokenizer on dataset (num_proc=64): 332036 examples [01:09, 1590.14 examples/s]Running tokenizer on dataset (num_proc=64): 333036 examples [01:09, 1968.88 examples/s]Running tokenizer on dataset (num_proc=64): 334870 examples [01:09, 3094.55 examples/s]Running tokenizer on dataset (num_proc=64): 335870 examples [01:09, 2970.03 examples/s]Running tokenizer on dataset (num_proc=64): 337704 examples [01:10, 4016.07 examples/s]Running tokenizer on dataset (num_proc=64): 339704 examples [01:11, 2828.32 examples/s]Running tokenizer on dataset (num_proc=64): 340704 examples [01:11, 2931.41 examples/s]Running tokenizer on dataset (num_proc=64): 341621 examples [01:11, 3338.27 examples/s]Running tokenizer on dataset (num_proc=64): 342538 examples [01:12, 1769.93 exaples [01:05, 4457.87 examples/s]Running tokenizer on dataset (num_proc=64): 325783 examples [01:05, 3881.58 examples/s]Running tokenizer on dataset (num_proc=64): 327700 examples [01:05, 5009.04 examples/s]Running tokenizer on dataset (num_proc=64): 328617 examples [01:07, 2038.58 examples/s]Running tokenizer on dataset (num_proc=64): 330451 examples [01:07, 2814.36 examples/s]Running tokenizer on dataset (num_proc=64): 331368 examples [01:07, 3077.05 examples/s]Running tokenizer on dataset (num_proc=64): 332285 examples [01:07, 3442.13 examples/s]Running tokenizer on dataset (num_proc=64): 333285 examples [01:09, 1316.43 examples/s]Running tokenizer on dataset (num_proc=64): 334202 examples [01:09, 1576.02 examples/s]Running tokenizer on dataset (num_proc=64): 336036 examples [01:10, 2047.04 examples/s]Running tokenizer on dataset (num_proc=64): 336953 examples [01:10, 2368.59 examples/s]Running tokenizer on dataset (num_proc=64): 337953 examples [01:12, 1160.97 examples/s]Running tokenizer on daaset (num_proc=64): 331368 examples [01:07, 2504.34 examples/s]Running tokenizer on dataset (num_proc=64): 333202 examples [01:08, 3025.20 examples/s]Running tokenizer on dataset (num_proc=64): 335119 examples [01:08, 3120.33 examples/s]Running tokenizer on dataset (num_proc=64): 336119 examples [01:09, 2887.34 examples/s]Running tokenizer on dataset (num_proc=64): 337036 examples [01:09, 2961.38 examples/s]Running tokenizer on dataset (num_proc=64): 337953 examples [01:09, 2873.73 examples/s]Running tokenizer on dataset (num_proc=64): 338870 examples [01:10, 3257.42 examples/s]Running tokenizer on dataset (num_proc=64): 339787 examples [01:10, 3088.65 examples/s]Running tokenizer on dataset (num_proc=64): 340704 examples [01:11, 1659.85 examples/s]Running tokenizer on dataset (num_proc=64): 342538 examples [01:12, 2354.72 examples/s]Running tokenizer on dataset (num_proc=64): 343538 examples [01:12, 2294.60 examples/s]Running tokenizer on dataset (num_proc=64): 344538 examples [01:15, 913.48 exampn dataset (num_proc=64): 335119 examples [01:06, 5499.86 examples/s]Running tokenizer on dataset (num_proc=64): 336119 examples [01:07, 3612.46 examples/s]Running tokenizer on dataset (num_proc=64): 337036 examples [01:08, 1873.44 examples/s]Running tokenizer on dataset (num_proc=64): 338036 examples [01:09, 2044.22 examples/s]Running tokenizer on dataset (num_proc=64): 338953 examples [01:10, 1627.33 examples/s]Running tokenizer on dataset (num_proc=64): 339870 examples [01:11, 1264.16 examples/s]Running tokenizer on dataset (num_proc=64): 340870 examples [01:11, 1412.41 examples/s]Running tokenizer on dataset (num_proc=64): 341870 examples [01:12, 1693.56 examples/s]Running tokenizer on dataset (num_proc=64): 342787 examples [01:13, 1278.42 examples/s]Running tokenizer on dataset (num_proc=64): 343704 examples [01:13, 1547.53 examples/s]Running tokenizer on dataset (num_proc=64): 345621 examples [01:13, 2470.00 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:15, 1205.85et (num_proc=64): 334036 examples [01:09, 2206.63 examples/s]Running tokenizer on dataset (num_proc=64): 335036 examples [01:09, 2831.49 examples/s]Running tokenizer on dataset (num_proc=64): 336953 examples [01:09, 3378.99 examples/s]Running tokenizer on dataset (num_proc=64): 338870 examples [01:10, 3090.50 examples/s]Running tokenizer on dataset (num_proc=64): 340704 examples [01:10, 3443.51 examples/s]Running tokenizer on dataset (num_proc=64): 341621 examples [01:11, 3785.44 examples/s]Running tokenizer on dataset (num_proc=64): 342538 examples [01:11, 3641.55 examples/s]Running tokenizer on dataset (num_proc=64): 343538 examples [01:13, 1232.57 examples/s]Running tokenizer on dataset (num_proc=64): 344538 examples [01:14, 1448.95 examples/s]Running tokenizer on dataset (num_proc=64): 345538 examples [01:15, 1270.87 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:15, 1350.36 examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:17, 864.92 exampleet (num_proc=64): 334953 examples [01:10, 2287.04 examples/s]Running tokenizer on dataset (num_proc=64): 335870 examples [01:11, 1586.68 examples/s]Running tokenizer on dataset (num_proc=64): 336787 examples [01:12, 1684.55 examples/s]Running tokenizer on dataset (num_proc=64): 337787 examples [01:12, 2104.62 examples/s]Running tokenizer on dataset (num_proc=64): 338704 examples [01:12, 2665.14 examples/s]Running tokenizer on dataset (num_proc=64): 340704 examples [01:13, 2541.41 examples/s]Running tokenizer on dataset (num_proc=64): 342704 examples [01:13, 3109.17 examples/s]Running tokenizer on dataset (num_proc=64): 344621 examples [01:14, 3438.95 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:14, 3649.71 examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:18, 973.20 examples/s] Running tokenizer on dataset (num_proc=64): 348538 examples [01:28, 341.33 examples/s]Running tokenizer on dataset (num_proc=64): 349538 examples [01:29, 383.26 examplesples/s]Running tokenizer on dataset (num_proc=64): 343538 examples [01:07, 4574.13 examples/s]Running tokenizer on dataset (num_proc=64): 344538 examples [01:09, 1436.96 examples/s]Running tokenizer on dataset (num_proc=64): 345538 examples [01:10, 1305.18 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:11, 1140.68 examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:11, 1328.49 examples/s]Running tokenizer on dataset (num_proc=64): 348455 examples [01:19, 363.04 examples/s] Running tokenizer on dataset (num_proc=64): 349455 examples [01:23, 308.73 examples/s]Running tokenizer on dataset (num_proc=64): 350455 examples [01:25, 378.71 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:29, 322.84 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:30, 373.03 examples/s]Running tokenizer on dataset (num_proc=64): 353455 examples [01:31, 497.68 examples/s]Running tokenizer on dataset (num_proc=64): 354455 extaset (num_proc=64): 339787 examples [01:13, 1714.63 examples/s]Running tokenizer on dataset (num_proc=64): 340704 examples [01:13, 1765.01 examples/s]Running tokenizer on dataset (num_proc=64): 341621 examples [01:13, 2199.92 examples/s]Running tokenizer on dataset (num_proc=64): 342538 examples [01:13, 2378.36 examples/s]Running tokenizer on dataset (num_proc=64): 343538 examples [01:14, 2931.44 examples/s]Running tokenizer on dataset (num_proc=64): 345538 examples [01:14, 3486.07 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:14, 3487.92 examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:17, 1018.27 examples/s]Running tokenizer on dataset (num_proc=64): 348538 examples [01:27, 293.21 examples/s] Running tokenizer on dataset (num_proc=64): 349538 examples [01:29, 328.40 examples/s]Running tokenizer on dataset (num_proc=64): 350538 examples [01:31, 383.73 examples/s]Running tokenizer on dataset (num_proc=64): 351538 examples [01:33, 429.02 examplles/s]Running tokenizer on dataset (num_proc=64): 343621 examples [01:12, 2950.87 examples/s]Running tokenizer on dataset (num_proc=64): 344538 examples [01:13, 2273.83 examples/s]Running tokenizer on dataset (num_proc=64): 345538 examples [01:14, 1350.65 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:19, 535.80 examples/s] Running tokenizer on dataset (num_proc=64): 347538 examples [01:19, 702.19 examples/s]Running tokenizer on dataset (num_proc=64): 348455 examples [01:20, 754.43 examples/s]Running tokenizer on dataset (num_proc=64): 349455 examples [01:26, 370.59 examples/s]Running tokenizer on dataset (num_proc=64): 350455 examples [01:30, 334.07 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:33, 335.41 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:33, 449.55 examples/s]Running tokenizer on dataset (num_proc=64): 353455 examples [01:34, 554.87 examples/s]Running tokenizer on dataset (num_proc=64): 354455 exampmples/s]Running tokenizer on dataset (num_proc=64): 343538 examples [01:14, 1207.41 examples/s]Running tokenizer on dataset (num_proc=64): 344538 examples [01:15, 1066.56 examples/s]Running tokenizer on dataset (num_proc=64): 345538 examples [01:18, 713.35 examples/s] Running tokenizer on dataset (num_proc=64): 346538 examples [01:19, 658.45 examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:21, 634.89 examples/s]Running tokenizer on dataset (num_proc=64): 348455 examples [01:26, 385.95 examples/s]Running tokenizer on dataset (num_proc=64): 349455 examples [01:27, 473.26 examples/s]Running tokenizer on dataset (num_proc=64): 350455 examples [01:28, 532.48 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:35, 299.72 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:36, 363.48 examples/s]Running tokenizer on dataset (num_proc=64): 353455 examples [01:39, 358.54 examples/s]Running tokenizer on dataset (num_proc=64): 354455 exam examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:16, 1192.87 examples/s]Running tokenizer on dataset (num_proc=64): 348538 examples [01:27, 270.83 examples/s] Running tokenizer on dataset (num_proc=64): 349538 examples [01:29, 331.26 examples/s]Running tokenizer on dataset (num_proc=64): 350538 examples [01:31, 363.38 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:32, 411.61 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:33, 504.72 examples/s]Running tokenizer on dataset (num_proc=64): 353455 examples [01:35, 546.38 examples/s]Running tokenizer on dataset (num_proc=64): 354455 examples [01:35, 708.19 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:36, 797.63 examples/s]Running tokenizer on dataset (num_proc=64): 356455 examples [01:36, 1041.09 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:38, 777.60 examples/s] Running tokenizer on dataset (num_proc=64): 358455les/s] Running tokenizer on dataset (num_proc=64): 345538 examples [01:15, 1114.58 examples/s]Running tokenizer on dataset (num_proc=64): 346538 examples [01:16, 1261.38 examples/s]Running tokenizer on dataset (num_proc=64): 347538 examples [01:17, 1237.30 examples/s]Running tokenizer on dataset (num_proc=64): 348455 examples [01:26, 292.84 examples/s] Running tokenizer on dataset (num_proc=64): 349455 examples [01:28, 338.39 examples/s]Running tokenizer on dataset (num_proc=64): 350455 examples [01:31, 323.90 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:32, 447.04 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:33, 538.17 examples/s]Running tokenizer on dataset (num_proc=64): 353455 examples [01:33, 721.18 examples/s]Running tokenizer on dataset (num_proc=64): 354455 examples [01:34, 734.35 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:37, 538.33 examples/s]Running tokenizer on dataset (num_proc=64): 356455 exams/s] Running tokenizer on dataset (num_proc=64): 348538 examples [01:26, 311.62 examples/s]Running tokenizer on dataset (num_proc=64): 349538 examples [01:26, 399.41 examples/s]Running tokenizer on dataset (num_proc=64): 350455 examples [01:30, 352.19 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:33, 354.86 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:33, 495.60 examples/s]Running tokenizer on dataset (num_proc=64): 353455 examples [01:34, 548.31 examples/s]Running tokenizer on dataset (num_proc=64): 354455 examples [01:38, 387.87 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:39, 544.90 examples/s]Running tokenizer on dataset (num_proc=64): 356455 examples [01:40, 558.30 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:41, 618.53 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:44, 553.82 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [/s]Running tokenizer on dataset (num_proc=64): 350455 examples [01:33, 333.94 examples/s]Running tokenizer on dataset (num_proc=64): 351455 examples [01:34, 434.17 examples/s]Running tokenizer on dataset (num_proc=64): 352455 examples [01:36, 448.58 examples/s]Running tokenizer on dataset (num_proc=64): 354455 examples [01:38, 537.71 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:42, 427.12 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:45, 532.73 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:45, 638.21 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [01:46, 771.07 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:46, 927.17 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:48, 735.87 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:51, 533.04 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01es/s]Running tokenizer on dataset (num_proc=64): 352538 examples [01:34, 504.86 examples/s]Running tokenizer on dataset (num_proc=64): 353538 examples [01:34, 643.63 examples/s]Running tokenizer on dataset (num_proc=64): 354455 examples [01:35, 788.31 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:37, 613.37 examples/s]Running tokenizer on dataset (num_proc=64): 356455 examples [01:38, 782.27 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:39, 743.70 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:46, 328.57 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [01:47, 420.93 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:47, 564.02 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:48, 751.40 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:50, 577.60 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [amples [01:31, 641.02 examples/s]Running tokenizer on dataset (num_proc=64): 356455 examples [01:33, 868.81 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:33, 1080.85 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:34, 967.35 examples/s] Running tokenizer on dataset (num_proc=64): 359455 examples [01:37, 740.69 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:37, 961.24 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:42, 460.64 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:45, 379.37 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01:46, 508.40 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [01:54, 254.37 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [01:55, 405.80 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [01:56, 453.77 examples/s]Running tokenizer on dataset (nples [01:41, 435.28 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:41, 563.25 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:45, 412.46 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [01:47, 430.59 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:47, 591.49 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:48, 728.08 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:51, 522.26 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01:58, 281.78 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [02:00, 313.99 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [02:01, 415.49 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [02:02, 442.08 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [02:03, 569.54 examples/s]Running tokenizer on dataset (num_p examples [01:41, 625.72 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [01:41, 757.22 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:46, 446.56 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:49, 383.93 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:50, 461.85 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01:52, 481.79 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [01:53, 552.98 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [02:03, 224.40 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [02:04, 280.22 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [02:05, 343.61 examples/s]Running tokenizer on dataset (num_proc=64): 367874 examples [02:06, 416.48 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:07, 527.78 examples/s]Running tokenizer on dataset (ples [01:40, 496.20 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:40, 610.34 examples/s]Running tokenizer on dataset (num_proc=64): 356455 examples [01:41, 781.13 examples/s]Running tokenizer on dataset (num_proc=64): 357455 examples [01:43, 585.80 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:48, 389.13 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [01:49, 493.59 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:50, 590.47 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:53, 574.00 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01:58, 386.44 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [01:58, 489.79 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [02:01, 454.64 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [02:04, 405.91 examples/s]Running tokenizer on dataset (num_pum_proc=64): 367874 examples [01:56, 587.70 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [01:58, 601.99 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:00, 534.72 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:01, 596.79 examples/s]Running tokenizer on dataset (num_proc=64): 371542 examples [02:02, 690.54 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:05, 530.22 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:08, 422.40 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:09, 1445.56 examples/s]
les [01:35, 567.40 examples/s]Running tokenizer on dataset (num_proc=64): 355455 examples [01:39, 437.53 examples/s]Running tokenizer on dataset (num_proc=64): 356455 examples [01:41, 471.16 examples/s]Running tokenizer on dataset (num_proc=64): 358455 examples [01:43, 569.45 examples/s]Running tokenizer on dataset (num_proc=64): 359455 examples [01:46, 484.07 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:49, 475.28 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:51, 485.14 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:53, 466.43 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01:56, 394.62 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [01:57, 622.51 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [02:02, 400.33 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [02:02, 502.81 examples/s]Running tokenizer on dataset (num_pr01:45, 635.96 examples/s]Running tokenizer on dataset (num_proc=64): 360455 examples [01:47, 523.49 examples/s]Running tokenizer on dataset (num_proc=64): 361455 examples [01:49, 571.43 examples/s]Running tokenizer on dataset (num_proc=64): 362372 examples [01:49, 717.53 examples/s]Running tokenizer on dataset (num_proc=64): 363289 examples [01:50, 821.14 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [02:02, 208.03 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [02:02, 291.59 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [02:03, 390.37 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [02:07, 334.26 examples/s]Running tokenizer on dataset (num_proc=64): 367874 examples [02:07, 462.96 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:07, 607.85 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:09, 553.68 examples/s]Running tokenizer on dataset (num_proc=6401:53, 449.51 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [01:59, 293.08 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [02:00, 386.36 examples/s]Running tokenizer on dataset (num_proc=64): 366040 examples [02:04, 315.45 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [02:05, 403.58 examples/s]Running tokenizer on dataset (num_proc=64): 367874 examples [02:05, 563.80 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:05, 760.11 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:06, 763.49 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:13, 326.18 examples/s]Running tokenizer on dataset (num_proc=64): 371542 examples [02:14, 383.83 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:15, 488.51 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:15, 633.21 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:16, 1367.68 examples/s]
): 370625 examples [02:12, 434.99 examples/s]Running tokenizer on dataset (num_proc=64): 371542 examples [02:13, 605.27 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:14, 570.31 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:15, 658.42 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:16, 1367.27 examples/s]
roc=64): 367874 examples [02:03, 734.18 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:06, 565.61 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:11, 338.86 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:13, 357.28 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:15, 520.95 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:15, 649.55 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:16, 1367.22 examples/s]
oc=64): 367874 examples [02:09, 291.25 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:09, 382.80 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:10, 487.05 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:11, 545.03 examples/s]Running tokenizer on dataset (num_proc=64): 371542 examples [02:14, 459.11 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:16, 484.46 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:16, 660.94 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:17, 1362.61 examples/s]
num_proc=64): 369708 examples [02:07, 676.06 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:08, 736.33 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:11, 752.32 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:16, 422.15 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:17, 1360.63 examples/s]
:53, 547.97 examples/s]Running tokenizer on dataset (num_proc=64): 364206 examples [01:59, 315.71 examples/s]Running tokenizer on dataset (num_proc=64): 365123 examples [02:05, 232.83 examples/s]Running tokenizer on dataset (num_proc=64): 366957 examples [02:06, 403.30 examples/s]Running tokenizer on dataset (num_proc=64): 367874 examples [02:10, 331.23 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:12, 364.94 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:13, 458.69 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:13, 568.98 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:14, 852.09 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:16, 651.43 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:17, 1354.64 examples/s]
roc=64): 366957 examples [02:08, 335.79 examples/s]Running tokenizer on dataset (num_proc=64): 367874 examples [02:11, 306.07 examples/s]Running tokenizer on dataset (num_proc=64): 368791 examples [02:12, 407.51 examples/s]Running tokenizer on dataset (num_proc=64): 369708 examples [02:12, 539.21 examples/s]Running tokenizer on dataset (num_proc=64): 370625 examples [02:16, 416.60 examples/s]Running tokenizer on dataset (num_proc=64): 371542 examples [02:16, 574.24 examples/s]Running tokenizer on dataset (num_proc=64): 372459 examples [02:17, 613.16 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:19, 585.51 examples/s]Running tokenizer on dataset (num_proc=64): 373376 examples [02:19, 1333.97 examples/s]
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,359 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,359 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,359 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,359 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,359 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,359 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,360 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,360 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|configuration_utils.py:763] 2025-10-04 13:21:43,361 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/config.json
[INFO|configuration_utils.py:839] 2025-10-04 13:21:43,363 >> Model config GptOssConfig {
  "architectures": [
    "GptOssForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "dtype": "bfloat16",
  "eos_token_id": 200002,
  "experts_per_token": 4,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2880,
  "initial_context_length": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 2880,
  "layer_types": [
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention",
    "sliding_attention",
    "full_attention"
  ],
  "max_position_embeddings": 131072,
  "model_type": "gpt_oss",
  "num_attention_heads": 64,
  "num_experts_per_tok": 4,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "num_local_experts": 128,
  "output_router_logits": false,
  "pad_token_id": 199999,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "factor": 32.0,
    "original_max_position_embeddings": 4096,
    "rope_type": "yarn",
    "truncate": false
  },
  "rope_theta": 150000,
  "router_aux_loss_coef": 0.9,
  "sliding_window": 128,
  "swiglu_limit": 7.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.56.2",
  "use_cache": true,
  "vocab_size": 201088
}

[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,944 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,945 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,945 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,945 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,946 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,946 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,946 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,946 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,946 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,947 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,947 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,948 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|modeling_utils.py:1277] 2025-10-04 13:21:43,953 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:43,954 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,955 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,956 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,956 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,957 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,957 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,964 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:21:43,975 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

[INFO|modeling_utils.py:1277] 2025-10-04 13:21:44,007 >> loading weights file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/model.safetensors.index.json
[INFO|modeling_utils.py:4492] 2025-10-04 13:21:44,008 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[INFO|configuration_utils.py:1055] 2025-10-04 13:21:44,028 >> Generate config GenerationConfig {
  "eos_token_id": 200002,
  "pad_token_id": 199999,
  "use_cache": false
}

Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:29,  1.25s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:29,  1.25s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:32,  1.28s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:27,  2.92s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.53s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.53s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.22s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.22s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.22s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.22s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.87s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.23s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.23s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.22s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.22s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.20s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.51s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:26,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:27,  1.21s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:23,  2.87s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.51s/it]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/73 [00:00<?, ?it/s]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.24s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.23s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.23s/it]Loading checkpoint shards:   1%|▏         | 1/73 [00:01<01:28,  1.23s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   3%|▎         | 2/73 [00:05<03:24,  2.88s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.51s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:55,  2.51s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:56,  2.52s/it]Loading checkpoint shards:   4%|▍         | 3/73 [00:07<02:57,  2.53s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:32,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:32,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.09s/it]Loading checkpoint shards:   5%|▌         | 4/73 [00:11<03:33,  3.10s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.73s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.73s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:04,  2.72s/it]Loading checkpoint shards:   7%|▋         | 5/73 [00:13<03:05,  2.72s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.13s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:   8%|▊         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.20s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.20s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.45s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.45s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03         | 6/73 [00:17<03:30,  3.14s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  10%|▉         | 7/73 [00:20<03:30,  3.19s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  11%|█         | 8/73 [00:24<03:44,  3.46s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  12%|█▏        | 9/73 [00:26<03:13,  3.02s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.30s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.30s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.28s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.28s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:31,  3.47s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:31,  3.47s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.05s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:22,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  14%|█▎        | 10/73 [00:30<03:28,  3.31s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  15%|█▌        | 11/73 [00:33<03:23,  3.27s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  16%|█▋        | 12/73 [00:37<03:32,  3.48s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.05s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.31s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.31s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:17,  3.47s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:17,  3.47s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:47<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  18%|█▊        | 13/73 [00:39<03:02,  3.04s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  19%|█▉        | 14/73 [00:43<03:15,  3.32s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  21%|██        | 15/73 [00:46<03:10,  3.28s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shard73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  22%|██▏       | 16/73 [00:50<03:18,  3.48s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:52<02:50,  3.05s/it]Loading checkpoint shards:  23%|██▎       | 17/73 [00:53<02:50,  3.05s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.31s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.31s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  25%|██▍       | 18/73 [00:56<03:02,  3.32s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.29s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.29s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.50s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33ss:  26%|██▌       | 19/73 [01:00<02:57,  3.28s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:04,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:04,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  27%|██▋       | 20/73 [01:04<03:05,  3.49s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  29%|██▉       | 21/73 [01:06<02:39,  3.07s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  30%|███       | 22/73 [01:10<02:49,  3.33s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.95s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.95s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.95s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.89s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.89s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shar/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  32%|███▏      | 23/73 [01:12<02:27,  2.94s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  33%|███▎      | 24/73 [01:16<02:38,  3.24s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  34%|███▍      | 25/73 [01:18<02:18,  2.88s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.19s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.19s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:28,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:28,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      |ds:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  36%|███▌      | 26/73 [01:22<02:30,  3.20s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  37%|███▋      | 27/73 [01:25<02:27,  3.22s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  38%|███▊      | 28/73 [01:29<02:36,  3.48s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.44s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.44s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:33,  3.58s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:33,  3.58s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.58s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:40<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:2 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  40%|███▉      | 29/73 [01:32<02:31,  3.43s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  41%|████      | 30/73 [01:36<02:34,  3.59s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  42%|████▏     | 31/73 [01:39<02:26,  3.49s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.62s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.62s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.16s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.16s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:46<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.38s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.38s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  8,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  44%|████▍     | 32/73 [01:43<02:28,  3.63s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  45%|████▌     | 33/73 [01:45<02:06,  3.15s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  47%|████▋     | 34/73 [01:49<02:12,  3.39s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.58s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.58s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  48%|████▊     | 35/73 [01:53<02:07,  3.35s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  49%|████▉     | 36/73 [01:57<02:12,  3.59s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  51%|█████     | 37/73 [01:59<01:53,  3.15s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.38s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.38s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:47,  3.27s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:47,  3.27s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  52%|█████▏    | 38/73 [02:03<01:58,  3.39s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  53%|█████▎    | 39/73 [02:05<01:41,  2.99s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  55%|█████▍    | 40/73 [02:09<01:48,  3.28s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.46s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.46s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.05s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.05s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  56%|█████▌    | 41/73 [02:12<01:44,  3.26s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  58%|█████▊    | 42/73 [02:16<01:47,  3.47s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  59%|█████▉    | 43/73 [02:18<01:31,  3.04s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.33s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.33s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.30s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.30s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loa███    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  60%|██████    | 44/73 [02:22<01:36,  3.34s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  62%|██████▏   | 45/73 [02:25<01:32,  3.29s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  63%|██████▎   | 46/73 [02:29<01:34,  3.49s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:37<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:37<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:37<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:37<01:29,  3.59s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|█████ding checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.44s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.44s/it]Loading checkpoint shards:  64%|██████▍   | 47/73 [02:33<01:29,  3.43s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.58s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:36<01:29,  3.59s/it]Loading checkpoint shards:  66%|██████▌   | 48/73 [02:37<01:29,  3.58s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:15,  3.13s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:15,  3.13s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Load▋   | 49/73 [02:39<01:14,  3.12s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.36s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:42<01:17,  3.37s/it]Loading checkpoint shards:  68%|██████▊   | 50/73 [02:43<01:17,  3.37s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  70%|██████▉   | 51/73 [02:46<01:13,  3.35s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:13,  3.52s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:13,  3.52s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:12,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:12,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:54<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.70s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.70s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:58<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:58,  3.23s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:58,  3.23s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  7ing checkpoint shards:  71%|███████   | 52/73 [02:50<01:14,  3.53s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  73%|███████▎  | 53/73 [02:53<01:11,  3.60s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  74%|███████▍  | 54/73 [02:57<01:10,  3.71s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:58,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|██████5%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  75%|███████▌  | 55/73 [03:00<00:57,  3.22s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  77%|███████▋  | 56/73 [03:04<00:58,  3.45s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  78%|███████▊  | 57/73 [03:07<00:54,  3.40s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.46s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.46s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  79%|███████▉  | 58/73 [03:11<00:53,  3.56s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  81%|████████  | 59/73 [03:14<00:48,  3.45s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  82%|████████▏ | 60/73 [03:18<00:46,  3.60s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73  [03:21<00:41,  3.50s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  84%|████████▎ | 61/73 [03:21<00:41,  3.49s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  85%|████████▍ | 62/73 [03:25<00:39,  3.63s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.19s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.19s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  86%|████████▋ | 63/73 [03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:30,  3.44s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:30,  3.44s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [[03:27<00:31,  3.18s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  88%|████████▊ | 64/73 [03:31<00:31,  3.45s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  89%|████████▉ | 65/73 [03:33<00:24,  3.03s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.43s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:44<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|██████03:37<00:23,  3.30s/it]Loading checkpoint shards:  90%|█████████ | 66/73 [03:37<00:23,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  92%|█████████▏| 67/73 [03:41<00:19,  3.30s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  93%|█████████▎| 68/73 [03:45<00:17,  3.49s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.43s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.52s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%██▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  95%|█████████▍| 69/73 [03:48<00:13,  3.42s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  96%|█████████▌| 70/73 [03:52<00:10,  3.62s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  97%|█████████▋| 71/73 [03:55<00:07,  3.51s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.67s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.67s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,162 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,163 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,163 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,163 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,163 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,164 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,165 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,165 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,166 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,166 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,166 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,166 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,169 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,169 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,171 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,172 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards:  99%|█████████▊| 72/73 [03:59<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]


Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,172 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,173 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,172 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,173 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,173 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,173 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,175 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,175 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,175 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,175 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,175 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,176 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|trainer.py:757] 2025-10-04 13:25:53,191 >> Using auto half precision backend
[INFO|trainer.py:757] 2025-10-04 13:25:53,191 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,191 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,192 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 13:25:53,194 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,194 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 13:25:53,197 >> Using auto half precision backend
[INFO|trainer.py:757] 2025-10-04 13:25:53,197 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|trainer.py:757] 2025-10-04 13:25:53,198 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,198 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,198 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,198 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 73/73 [04:03<00:00,  3.33s/it]
[INFO|trainer.py:757] 2025-10-04 13:25:53,202 >> Using auto half precision backend
[INFO|modeling_utils.py:5724] 2025-10-04 13:25:53,202 >> All model checkpoint weights were used when initializing GptOssForCausalLM.

[INFO|modeling_utils.py:5732] 2025-10-04 13:25:53,202 >> All the weights of GptOssForCausalLM were initialized from the model checkpoint at /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GptOssForCausalLM for predictions without further training.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[WARNING|trainer.py:985] 2025-10-04 13:25:53,203 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
[INFO|configuration_utils.py:1008] 2025-10-04 13:25:53,204 >> loading configuration file /scratch/gpfs/PLI/yong/gpt-oss-120b-bf16/generation_config.json
[INFO|configuration_utils.py:1055] 2025-10-04 13:25:53,204 >> Generate config GenerationConfig {
  "bos_token_id": 199998,
  "do_sample": true,
  "eos_token_id": [
    200002,
    199999
  ],
  "pad_token_id": 199999
}

[INFO|trainer.py:757] 2025-10-04 13:25:53,224 >> Using auto half precision backend
[WARNING|trainer.py:985] 2025-10-04 13:25:53,226 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,497 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,499 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,506 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,510 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,513 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,517 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 4. Using DeepSpeed's value.
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,523 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|deepspeed.py:380] 2025-10-04 13:25:53,537 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
[rank12]:W1004 13:25:57.145000 203288 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank12]:W1004 13:25:57.145000 203288 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank13]:W1004 13:25:57.203000 203289 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank13]:W1004 13:25:57.203000 203289 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank16]:W1004 13:25:57.228000 2490411 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank16]:W1004 13:25:57.228000 2490411 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank6]:W1004 13:25:57.256000 3546083 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank6]:W1004 13:25:57.256000 3546083 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[rank5]:W1004 13:25:57.275000 3546082 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank5]:W1004 13:25:57.275000 3546082 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[INFO|trainer.py:2523] 2025-10-04 13:26:42,282 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 13:26:42,282 >>   Num examples = 186,688
[INFO|trainer.py:2523] 2025-10-04 13:26:42,284 >> ***** Running training *****
[INFO|trainer.py:2523] 2025-10-04 13:26:42,284 >> ***** Running training *****
[INFO|trainer.py:2523] 2025-10-04 13:26:42,284 >> ***** Running training *****
[INFO|trainer.py:2523] 2025-10-04 13:26:42,284 >> ***** Running training *****
[INFO|trainer.py:2523] 2025-10-04 13:26:42,284 >> ***** Running training *****
[INFO|trainer.py:2525] 2025-10-04 13:26:42,282 >>   Num Epochs = 1
[INFO|trainer.py:2524] 2025-10-04 13:26:42,284 >>   Num examples = 186,688
[INFO|trainer.py:2524] 2025-10-04 13:26:42,284 >>   Num examples = 186,688
[INFO|trainer.py:2524] 2025-10-04 13:26:42,284 >>   Num examples = 186,688
[INFO|trainer.py:2523] 2025-10-04 13:26:42,284 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 13:26:42,284 >>   Num examples = 186,688
[INFO|trainer.py:2524] 2025-10-04 13:26:42,284 >>   Num examples = 186,688
[INFO|trainer.py:2526] 2025-10-04 13:26:42,282 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2525] 2025-10-04 13:26:42,284 >>   Num Epochs = 1
[INFO|trainer.py:2525] 2025-10-04 13:26:42,284 >>   Num Epochs = 1
[INFO|trainer.py:2525] 2025-10-04 13:26:42,284 >>   Num Epochs = 1
[INFO|trainer.py:2524] 2025-10-04 13:26:42,284 >>   Num examples = 186,688
[INFO|trainer.py:2525] 2025-10-04 13:26:42,284 >>   Num Epochs = 1
[INFO|trainer.py:2525] 2025-10-04 13:26:42,284 >>   Num Epochs = 1
[INFO|trainer.py:2529] 2025-10-04 13:26:42,282 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2526] 2025-10-04 13:26:42,284 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2526] 2025-10-04 13:26:42,284 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2526] 2025-10-04 13:26:42,284 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2525] 2025-10-04 13:26:42,285 >>   Num Epochs = 1
[INFO|trainer.py:2526] 2025-10-04 13:26:42,284 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2526] 2025-10-04 13:26:42,284 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2530] 2025-10-04 13:26:42,282 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2529] 2025-10-04 13:26:42,284 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2529] 2025-10-04 13:26:42,284 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2529] 2025-10-04 13:26:42,284 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2526] 2025-10-04 13:26:42,285 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 13:26:42,284 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2529] 2025-10-04 13:26:42,284 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2531] 2025-10-04 13:26:42,282 >>   Total optimization steps = 1,459
[INFO|trainer.py:2530] 2025-10-04 13:26:42,284 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2530] 2025-10-04 13:26:42,284 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2530] 2025-10-04 13:26:42,284 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2529] 2025-10-04 13:26:42,285 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 13:26:42,284 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2530] 2025-10-04 13:26:42,284 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2532] 2025-10-04 13:26:42,283 >>   Number of trainable parameters = 116,829,156,672
[INFO|trainer.py:2531] 2025-10-04 13:26:42,284 >>   Total optimization steps = 1,459
[INFO|trainer.py:2531] 2025-10-04 13:26:42,284 >>   Total optimization steps = 1,459
[INFO|trainer.py:2531] 2025-10-04 13:26:42,284 >>   Total optimization steps = 1,459
[INFO|trainer.py:2530] 2025-10-04 13:26:42,285 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 13:26:42,284 >>   Total optimization steps = 1,459
[INFO|trainer.py:2531] 2025-10-04 13:26:42,284 >>   Total optimization steps = 1,459
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|trainer.py:2532] 2025-10-04 13:26:42,285 >>   Number of trainable parameters = 116,829,156,672
[INFO|trainer.py:2532] 2025-10-04 13:26:42,285 >>   Number of trainable parameters = 116,829,156,672
[INFO|trainer.py:2532] 2025-10-04 13:26:42,285 >>   Number of trainable parameters = 116,829,156,672
[INFO|trainer.py:2531] 2025-10-04 13:26:42,285 >>   Total optimization steps = 1,459
[INFO|trainer.py:2532] 2025-10-04 13:26:42,285 >>   Number of trainable parameters = 116,829,156,672
[INFO|trainer.py:2532] 2025-10-04 13:26:42,285 >>   Number of trainable parameters = 116,829,156,672
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|trainer.py:2532] 2025-10-04 13:26:42,286 >>   Number of trainable parameters = 116,829,156,672
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/scratch/gpfs/yl7690/.conda/envs/oss/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[INFO|trainer.py:2523] 2025-10-04 13:26:42,602 >> ***** Running training *****
[INFO|trainer.py:2524] 2025-10-04 13:26:42,602 >>   Num examples = 186,688
[INFO|trainer.py:2525] 2025-10-04 13:26:42,602 >>   Num Epochs = 1
[INFO|trainer.py:2526] 2025-10-04 13:26:42,602 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2529] 2025-10-04 13:26:42,602 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2530] 2025-10-04 13:26:42,602 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2531] 2025-10-04 13:26:42,602 >>   Total optimization steps = 1,459
[INFO|trainer.py:2532] 2025-10-04 13:26:42,604 >>   Number of trainable parameters = 116,829,156,672
